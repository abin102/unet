{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81cee2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")  # to import from parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5ab4316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import REGISTRY\n",
    "train_ds, test_ds = REGISTRY[\"cifar100_imb\"](data_dir=\"./data\", mode=\"even\", downsample_frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4c4dc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR100\n",
       "    Number of datapoints: 50000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=224, interpolation=bilinear, max_size=None, antialias=True)\n",
       "               RandomCrop(size=(224, 224), padding=4)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46a49af5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CIFAR100' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m counts\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# use train_ds instead of train_subset\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m counts \u001b[38;5;241m=\u001b[39m \u001b[43msubset_class_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal samples:\u001b[39m\u001b[38;5;124m\"\u001b[39m, counts\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):  \u001b[38;5;66;03m# print first 10 classes as an example\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m, in \u001b[0;36msubset_class_counts\u001b[0;34m(subset, num_classes)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msubset_class_counts\u001b[39m(subset, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m----> 5\u001b[0m     full_targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43msubset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(subset\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(subset\u001b[38;5;241m.\u001b[39mindices) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(subset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(subset)))\n\u001b[1;32m      7\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [full_targets[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CIFAR100' object has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def subset_class_counts(subset, num_classes=100):\n",
    "    full_targets = getattr(subset.dataset, \"targets\", None) or getattr(subset.dataset, \"labels\")\n",
    "    indices = list(subset.indices) if hasattr(subset, \"indices\") else list(range(len(subset)))\n",
    "    labels = [full_targets[i] for i in indices]\n",
    "    cnt = Counter(labels)\n",
    "    counts = np.zeros(num_classes, dtype=int)\n",
    "    for cls, c in cnt.items():\n",
    "        counts[cls] = c\n",
    "    return counts\n",
    "\n",
    "# use train_ds instead of train_subset\n",
    "counts = subset_class_counts(train_ds, num_classes=100)\n",
    "\n",
    "print(\"Total samples:\", counts.sum())\n",
    "for cls in range(10):  # print first 10 classes as an example\n",
    "    print(f\"class {cls:02d}: {counts[cls]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f9119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dadc9984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered model keys: ['densenet121', 'efficientnet_v2_s', 'resltresnet32', 'resnet18', 'resnet34', 'resnet50', 'resnet50_cbam', 'resnet_cifar_classifier']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "proj = Path(\"/home/user/abin_ref_papers/project_structure_demo/dnn_template\")\n",
    "if str(proj) not in sys.path:\n",
    "    sys.path.insert(0, str(proj))\n",
    "\n",
    "# ensure any backbone registration file runs\n",
    "try:\n",
    "    import models.backbone\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "from models import REGISTRY\n",
    "print(\"Registered model keys:\", sorted(REGISTRY.keys())[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "844edeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100]) torch.Size([4, 100]) torch.Size([4, 512, 4, 4]) torch.Size([4, 512, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")  # to import from parent dir\n",
    "import torch\n",
    "import models.backbone   # ensure registrations executed\n",
    "from models import REGISTRY\n",
    "\n",
    "# instantiate DAIIC ResNet34 for CIFAR-100 imbalanced experiments:\n",
    "net = REGISTRY['daiic_resnet34'](num_classes=100, pretrained=True, cifar_stem=True, fusion='concat')\n",
    "out = net(torch.randn(4,3,32,32))\n",
    "print(out['logits'].shape, out['W'].shape, out['F'].shape, out['Fprime'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe7a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "070c4619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import REGISTRY as MODEL_REG\n",
    "import models.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f0e57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialise model\n",
    "model = MODEL_REG[\"daiic_resnet34\"](num_classes=100, pretrained=False, cifar_stem=True, in_channel=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d47bde1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     19\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput logits:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)   \u001b[38;5;66;03m# should be (4, 100)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 4. If you also want intermediate shapes:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdebug_forward\u001b[39m(m, x, name):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "\n",
    "# 1. Initialise the model\n",
    "# model = daiic_resnet34(\n",
    "#     num_classes=100,\n",
    "#     pretrained=False,     # turn off pretrained first to avoid mismatch\n",
    "#     in_channels=3,\n",
    "#     cifar_stem=True\n",
    "# )\n",
    "\n",
    "# 2. Create dummy CIFAR-100 input: (batch=4, channels=3, height=32, width=32)\n",
    "x = torch.randn(4, 3, 32, 32)\n",
    "\n",
    "# 3. Run forward and check shapes\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "    print(\"Output logits:\", out.shape)   # should be (4, 100)\n",
    "\n",
    "# 4. If you also want intermediate shapes:\n",
    "def debug_forward(m, x, name):\n",
    "    def hook(_, inp, out):\n",
    "        print(f\"{name}: {out.shape}\")\n",
    "    m.register_forward_hook(hook)\n",
    "\n",
    "# Example: attach hooks to feature extractor layers\n",
    "for name, layer in model.feature_extractor.named_children():\n",
    "    debug_forward(model.feature_extractor._modules[name], x, name)\n",
    "\n",
    "# Now run again\n",
    "out = model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72df595e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['logits', 'probs', 'W', 'F', 'Fprime'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dbd2308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512, 4, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['Fprime'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f41a524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn_stdp_poisson (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
