{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ce1dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0828cdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet50_CBAM(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): Identity()\n",
       "  (layer1): Sequential(\n",
       "    (0): BottleneckCBAM(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cbam): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BottleneckCBAM(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (cbam): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): BottleneckCBAM(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (cbam): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BottleneckCBAM(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cbam): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BottleneckCBAM(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (cbam): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): BottleneckCBAM(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (cbam): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): BottleneckCBAM(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (cbam): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BottleneckCBAM(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cbam): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BottleneckCBAM(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (cbam): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): BottleneckCBAM(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (cbam): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): BottleneckCBAM(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (cbam): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): BottleneckCBAM(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (cbam): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): BottleneckCBAM(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (cbam): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BottleneckCBAM(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cbam): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): BottleneckCBAM(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (cbam): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): BottleneckCBAM(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (cbam): CBAM(\n",
       "        (ca): ChannelAttention(\n",
       "          (mlp): Sequential(\n",
       "            (0): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (sa): SpatialAttention(\n",
       "          (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "          (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from models.resnet50_cbam import build_resnet50_cbam\n",
    "\n",
    "x = torch.randn(4, 3, 32, 32)\n",
    "model = build_resnet50_cbam(num_classes=10, use_cbam=True, cifar_stem=True)\n",
    "# model = build_resnet50_cbam(num_classes=10, use_cbam=False, cifar_stem=True)\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c2419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b3c061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c06d58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                                                         Type                      Output Shape                   Params       Trainable   \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "conv1                                                        Conv2d                    (4, 64, 32, 32)                       1,728        1,728\n",
      "bn1                                                          BatchNorm2d               (4, 64, 32, 32)                         128          128\n",
      "relu                                                         ReLU                      (4, 64, 32, 32)                           0            0\n",
      "maxpool                                                      Identity                  (4, 64, 32, 32)                           0            0\n",
      "layer1.0.conv1                                               Conv2d                    (4, 64, 32, 32)                       4,096        4,096\n",
      "layer1.0.bn1                                                 BatchNorm2d               (4, 64, 32, 32)                         128          128\n",
      "layer1.0.relu                                                ReLU                      (4, 256, 32, 32)                          0            0\n",
      "layer1.0.conv2                                               Conv2d                    (4, 64, 32, 32)                      36,864       36,864\n",
      "layer1.0.bn2                                                 BatchNorm2d               (4, 64, 32, 32)                         128          128\n",
      "layer1.0.conv3                                               Conv2d                    (4, 256, 32, 32)                     16,384       16,384\n",
      "layer1.0.bn3                                                 BatchNorm2d               (4, 256, 32, 32)                        512          512\n",
      "layer1.0.downsample.0                                        Conv2d                    (4, 256, 32, 32)                     16,384       16,384\n",
      "layer1.0.downsample.1                                        BatchNorm2d               (4, 256, 32, 32)                        512          512\n",
      "layer1.0.downsample                                          Sequential                (4, 256, 32, 32)                     16,896       16,896\n",
      "layer1.0.cbam.ca.mlp.0                                       Conv2d                    (4, 16, 1, 1)                         4,112        4,112\n",
      "layer1.0.cbam.ca.mlp.1                                       ReLU                      (4, 16, 1, 1)                             0            0\n",
      "layer1.0.cbam.ca.mlp.2                                       Conv2d                    (4, 256, 1, 1)                        4,352        4,352\n",
      "layer1.0.cbam.ca.mlp                                         Sequential                (4, 256, 1, 1)                        8,464        8,464\n",
      "layer1.0.cbam.ca                                             ChannelAttention          (4, 256, 32, 32)                      8,464        8,464\n",
      "layer1.0.cbam.sa.conv                                        Conv2d                    (4, 1, 32, 32)                           98           98\n",
      "layer1.0.cbam.sa.bn                                          BatchNorm2d               (4, 1, 32, 32)                            2            2\n",
      "layer1.0.cbam.sa                                             SpatialAttention          (4, 256, 32, 32)                        100          100\n",
      "layer1.0.cbam                                                CBAM                      (4, 256, 32, 32)                      8,564        8,564\n",
      "layer1.0                                                     BottleneckCBAM            (4, 256, 32, 32)                     83,572       83,572\n",
      "layer1.1.conv1                                               Conv2d                    (4, 64, 32, 32)                      16,384       16,384\n",
      "layer1.1.bn1                                                 BatchNorm2d               (4, 64, 32, 32)                         128          128\n",
      "layer1.1.relu                                                ReLU                      (4, 256, 32, 32)                          0            0\n",
      "layer1.1.conv2                                               Conv2d                    (4, 64, 32, 32)                      36,864       36,864\n",
      "layer1.1.bn2                                                 BatchNorm2d               (4, 64, 32, 32)                         128          128\n",
      "layer1.1.conv3                                               Conv2d                    (4, 256, 32, 32)                     16,384       16,384\n",
      "layer1.1.bn3                                                 BatchNorm2d               (4, 256, 32, 32)                        512          512\n",
      "layer1.1.cbam.ca.mlp.0                                       Conv2d                    (4, 16, 1, 1)                         4,112        4,112\n",
      "layer1.1.cbam.ca.mlp.1                                       ReLU                      (4, 16, 1, 1)                             0            0\n",
      "layer1.1.cbam.ca.mlp.2                                       Conv2d                    (4, 256, 1, 1)                        4,352        4,352\n",
      "layer1.1.cbam.ca.mlp                                         Sequential                (4, 256, 1, 1)                        8,464        8,464\n",
      "layer1.1.cbam.ca                                             ChannelAttention          (4, 256, 32, 32)                      8,464        8,464\n",
      "layer1.1.cbam.sa.conv                                        Conv2d                    (4, 1, 32, 32)                           98           98\n",
      "layer1.1.cbam.sa.bn                                          BatchNorm2d               (4, 1, 32, 32)                            2            2\n",
      "layer1.1.cbam.sa                                             SpatialAttention          (4, 256, 32, 32)                        100          100\n",
      "layer1.1.cbam                                                CBAM                      (4, 256, 32, 32)                      8,564        8,564\n",
      "layer1.1                                                     BottleneckCBAM            (4, 256, 32, 32)                     78,964       78,964\n",
      "layer1.2.conv1                                               Conv2d                    (4, 64, 32, 32)                      16,384       16,384\n",
      "layer1.2.bn1                                                 BatchNorm2d               (4, 64, 32, 32)                         128          128\n",
      "layer1.2.relu                                                ReLU                      (4, 256, 32, 32)                          0            0\n",
      "layer1.2.conv2                                               Conv2d                    (4, 64, 32, 32)                      36,864       36,864\n",
      "layer1.2.bn2                                                 BatchNorm2d               (4, 64, 32, 32)                         128          128\n",
      "layer1.2.conv3                                               Conv2d                    (4, 256, 32, 32)                     16,384       16,384\n",
      "layer1.2.bn3                                                 BatchNorm2d               (4, 256, 32, 32)                        512          512\n",
      "layer1.2.cbam.ca.mlp.0                                       Conv2d                    (4, 16, 1, 1)                         4,112        4,112\n",
      "layer1.2.cbam.ca.mlp.1                                       ReLU                      (4, 16, 1, 1)                             0            0\n",
      "layer1.2.cbam.ca.mlp.2                                       Conv2d                    (4, 256, 1, 1)                        4,352        4,352\n",
      "layer1.2.cbam.ca.mlp                                         Sequential                (4, 256, 1, 1)                        8,464        8,464\n",
      "layer1.2.cbam.ca                                             ChannelAttention          (4, 256, 32, 32)                      8,464        8,464\n",
      "layer1.2.cbam.sa.conv                                        Conv2d                    (4, 1, 32, 32)                           98           98\n",
      "layer1.2.cbam.sa.bn                                          BatchNorm2d               (4, 1, 32, 32)                            2            2\n",
      "layer1.2.cbam.sa                                             SpatialAttention          (4, 256, 32, 32)                        100          100\n",
      "layer1.2.cbam                                                CBAM                      (4, 256, 32, 32)                      8,564        8,564\n",
      "layer1.2                                                     BottleneckCBAM            (4, 256, 32, 32)                     78,964       78,964\n",
      "layer1                                                       Sequential                (4, 256, 32, 32)                    241,500      241,500\n",
      "layer2.0.conv1                                               Conv2d                    (4, 128, 32, 32)                     32,768       32,768\n",
      "layer2.0.bn1                                                 BatchNorm2d               (4, 128, 32, 32)                        256          256\n",
      "layer2.0.relu                                                ReLU                      (4, 512, 16, 16)                          0            0\n",
      "layer2.0.conv2                                               Conv2d                    (4, 128, 16, 16)                    147,456      147,456\n",
      "layer2.0.bn2                                                 BatchNorm2d               (4, 128, 16, 16)                        256          256\n",
      "layer2.0.conv3                                               Conv2d                    (4, 512, 16, 16)                     65,536       65,536\n",
      "layer2.0.bn3                                                 BatchNorm2d               (4, 512, 16, 16)                      1,024        1,024\n",
      "layer2.0.downsample.0                                        Conv2d                    (4, 512, 16, 16)                    131,072      131,072\n",
      "layer2.0.downsample.1                                        BatchNorm2d               (4, 512, 16, 16)                      1,024        1,024\n",
      "layer2.0.downsample                                          Sequential                (4, 512, 16, 16)                    132,096      132,096\n",
      "layer2.0.cbam.ca.mlp.0                                       Conv2d                    (4, 32, 1, 1)                        16,416       16,416\n",
      "layer2.0.cbam.ca.mlp.1                                       ReLU                      (4, 32, 1, 1)                             0            0\n",
      "layer2.0.cbam.ca.mlp.2                                       Conv2d                    (4, 512, 1, 1)                       16,896       16,896\n",
      "layer2.0.cbam.ca.mlp                                         Sequential                (4, 512, 1, 1)                       33,312       33,312\n",
      "layer2.0.cbam.ca                                             ChannelAttention          (4, 512, 16, 16)                     33,312       33,312\n",
      "layer2.0.cbam.sa.conv                                        Conv2d                    (4, 1, 16, 16)                           98           98\n",
      "layer2.0.cbam.sa.bn                                          BatchNorm2d               (4, 1, 16, 16)                            2            2\n",
      "layer2.0.cbam.sa                                             SpatialAttention          (4, 512, 16, 16)                        100          100\n",
      "layer2.0.cbam                                                CBAM                      (4, 512, 16, 16)                     33,412       33,412\n",
      "layer2.0                                                     BottleneckCBAM            (4, 512, 16, 16)                    412,804      412,804\n",
      "layer2.1.conv1                                               Conv2d                    (4, 128, 16, 16)                     65,536       65,536\n",
      "layer2.1.bn1                                                 BatchNorm2d               (4, 128, 16, 16)                        256          256\n",
      "layer2.1.relu                                                ReLU                      (4, 512, 16, 16)                          0            0\n",
      "layer2.1.conv2                                               Conv2d                    (4, 128, 16, 16)                    147,456      147,456\n",
      "layer2.1.bn2                                                 BatchNorm2d               (4, 128, 16, 16)                        256          256\n",
      "layer2.1.conv3                                               Conv2d                    (4, 512, 16, 16)                     65,536       65,536\n",
      "layer2.1.bn3                                                 BatchNorm2d               (4, 512, 16, 16)                      1,024        1,024\n",
      "layer2.1.cbam.ca.mlp.0                                       Conv2d                    (4, 32, 1, 1)                        16,416       16,416\n",
      "layer2.1.cbam.ca.mlp.1                                       ReLU                      (4, 32, 1, 1)                             0            0\n",
      "layer2.1.cbam.ca.mlp.2                                       Conv2d                    (4, 512, 1, 1)                       16,896       16,896\n",
      "layer2.1.cbam.ca.mlp                                         Sequential                (4, 512, 1, 1)                       33,312       33,312\n",
      "layer2.1.cbam.ca                                             ChannelAttention          (4, 512, 16, 16)                     33,312       33,312\n",
      "layer2.1.cbam.sa.conv                                        Conv2d                    (4, 1, 16, 16)                           98           98\n",
      "layer2.1.cbam.sa.bn                                          BatchNorm2d               (4, 1, 16, 16)                            2            2\n",
      "layer2.1.cbam.sa                                             SpatialAttention          (4, 512, 16, 16)                        100          100\n",
      "layer2.1.cbam                                                CBAM                      (4, 512, 16, 16)                     33,412       33,412\n",
      "layer2.1                                                     BottleneckCBAM            (4, 512, 16, 16)                    313,476      313,476\n",
      "layer2.2.conv1                                               Conv2d                    (4, 128, 16, 16)                     65,536       65,536\n",
      "layer2.2.bn1                                                 BatchNorm2d               (4, 128, 16, 16)                        256          256\n",
      "layer2.2.relu                                                ReLU                      (4, 512, 16, 16)                          0            0\n",
      "layer2.2.conv2                                               Conv2d                    (4, 128, 16, 16)                    147,456      147,456\n",
      "layer2.2.bn2                                                 BatchNorm2d               (4, 128, 16, 16)                        256          256\n",
      "layer2.2.conv3                                               Conv2d                    (4, 512, 16, 16)                     65,536       65,536\n",
      "layer2.2.bn3                                                 BatchNorm2d               (4, 512, 16, 16)                      1,024        1,024\n",
      "layer2.2.cbam.ca.mlp.0                                       Conv2d                    (4, 32, 1, 1)                        16,416       16,416\n",
      "layer2.2.cbam.ca.mlp.1                                       ReLU                      (4, 32, 1, 1)                             0            0\n",
      "layer2.2.cbam.ca.mlp.2                                       Conv2d                    (4, 512, 1, 1)                       16,896       16,896\n",
      "layer2.2.cbam.ca.mlp                                         Sequential                (4, 512, 1, 1)                       33,312       33,312\n",
      "layer2.2.cbam.ca                                             ChannelAttention          (4, 512, 16, 16)                     33,312       33,312\n",
      "layer2.2.cbam.sa.conv                                        Conv2d                    (4, 1, 16, 16)                           98           98\n",
      "layer2.2.cbam.sa.bn                                          BatchNorm2d               (4, 1, 16, 16)                            2            2\n",
      "layer2.2.cbam.sa                                             SpatialAttention          (4, 512, 16, 16)                        100          100\n",
      "layer2.2.cbam                                                CBAM                      (4, 512, 16, 16)                     33,412       33,412\n",
      "layer2.2                                                     BottleneckCBAM            (4, 512, 16, 16)                    313,476      313,476\n",
      "layer2.3.conv1                                               Conv2d                    (4, 128, 16, 16)                     65,536       65,536\n",
      "layer2.3.bn1                                                 BatchNorm2d               (4, 128, 16, 16)                        256          256\n",
      "layer2.3.relu                                                ReLU                      (4, 512, 16, 16)                          0            0\n",
      "layer2.3.conv2                                               Conv2d                    (4, 128, 16, 16)                    147,456      147,456\n",
      "layer2.3.bn2                                                 BatchNorm2d               (4, 128, 16, 16)                        256          256\n",
      "layer2.3.conv3                                               Conv2d                    (4, 512, 16, 16)                     65,536       65,536\n",
      "layer2.3.bn3                                                 BatchNorm2d               (4, 512, 16, 16)                      1,024        1,024\n",
      "layer2.3.cbam.ca.mlp.0                                       Conv2d                    (4, 32, 1, 1)                        16,416       16,416\n",
      "layer2.3.cbam.ca.mlp.1                                       ReLU                      (4, 32, 1, 1)                             0            0\n",
      "layer2.3.cbam.ca.mlp.2                                       Conv2d                    (4, 512, 1, 1)                       16,896       16,896\n",
      "layer2.3.cbam.ca.mlp                                         Sequential                (4, 512, 1, 1)                       33,312       33,312\n",
      "layer2.3.cbam.ca                                             ChannelAttention          (4, 512, 16, 16)                     33,312       33,312\n",
      "layer2.3.cbam.sa.conv                                        Conv2d                    (4, 1, 16, 16)                           98           98\n",
      "layer2.3.cbam.sa.bn                                          BatchNorm2d               (4, 1, 16, 16)                            2            2\n",
      "layer2.3.cbam.sa                                             SpatialAttention          (4, 512, 16, 16)                        100          100\n",
      "layer2.3.cbam                                                CBAM                      (4, 512, 16, 16)                     33,412       33,412\n",
      "layer2.3                                                     BottleneckCBAM            (4, 512, 16, 16)                    313,476      313,476\n",
      "layer2                                                       Sequential                (4, 512, 16, 16)                  1,353,232    1,353,232\n",
      "layer3.0.conv1                                               Conv2d                    (4, 256, 16, 16)                    131,072      131,072\n",
      "layer3.0.bn1                                                 BatchNorm2d               (4, 256, 16, 16)                        512          512\n",
      "layer3.0.relu                                                ReLU                      (4, 1024, 8, 8)                           0            0\n",
      "layer3.0.conv2                                               Conv2d                    (4, 256, 8, 8)                      589,824      589,824\n",
      "layer3.0.bn2                                                 BatchNorm2d               (4, 256, 8, 8)                          512          512\n",
      "layer3.0.conv3                                               Conv2d                    (4, 1024, 8, 8)                     262,144      262,144\n",
      "layer3.0.bn3                                                 BatchNorm2d               (4, 1024, 8, 8)                       2,048        2,048\n",
      "layer3.0.downsample.0                                        Conv2d                    (4, 1024, 8, 8)                     524,288      524,288\n",
      "layer3.0.downsample.1                                        BatchNorm2d               (4, 1024, 8, 8)                       2,048        2,048\n",
      "layer3.0.downsample                                          Sequential                (4, 1024, 8, 8)                     526,336      526,336\n",
      "layer3.0.cbam.ca.mlp.0                                       Conv2d                    (4, 64, 1, 1)                        65,600       65,600\n",
      "layer3.0.cbam.ca.mlp.1                                       ReLU                      (4, 64, 1, 1)                             0            0\n",
      "layer3.0.cbam.ca.mlp.2                                       Conv2d                    (4, 1024, 1, 1)                      66,560       66,560\n",
      "layer3.0.cbam.ca.mlp                                         Sequential                (4, 1024, 1, 1)                     132,160      132,160\n",
      "layer3.0.cbam.ca                                             ChannelAttention          (4, 1024, 8, 8)                     132,160      132,160\n",
      "layer3.0.cbam.sa.conv                                        Conv2d                    (4, 1, 8, 8)                             98           98\n",
      "layer3.0.cbam.sa.bn                                          BatchNorm2d               (4, 1, 8, 8)                              2            2\n",
      "layer3.0.cbam.sa                                             SpatialAttention          (4, 1024, 8, 8)                         100          100\n",
      "layer3.0.cbam                                                CBAM                      (4, 1024, 8, 8)                     132,260      132,260\n",
      "layer3.0                                                     BottleneckCBAM            (4, 1024, 8, 8)                   1,644,708    1,644,708\n",
      "layer3.1.conv1                                               Conv2d                    (4, 256, 8, 8)                      262,144      262,144\n",
      "layer3.1.bn1                                                 BatchNorm2d               (4, 256, 8, 8)                          512          512\n",
      "layer3.1.relu                                                ReLU                      (4, 1024, 8, 8)                           0            0\n",
      "layer3.1.conv2                                               Conv2d                    (4, 256, 8, 8)                      589,824      589,824\n",
      "layer3.1.bn2                                                 BatchNorm2d               (4, 256, 8, 8)                          512          512\n",
      "layer3.1.conv3                                               Conv2d                    (4, 1024, 8, 8)                     262,144      262,144\n",
      "layer3.1.bn3                                                 BatchNorm2d               (4, 1024, 8, 8)                       2,048        2,048\n",
      "layer3.1.cbam.ca.mlp.0                                       Conv2d                    (4, 64, 1, 1)                        65,600       65,600\n",
      "layer3.1.cbam.ca.mlp.1                                       ReLU                      (4, 64, 1, 1)                             0            0\n",
      "layer3.1.cbam.ca.mlp.2                                       Conv2d                    (4, 1024, 1, 1)                      66,560       66,560\n",
      "layer3.1.cbam.ca.mlp                                         Sequential                (4, 1024, 1, 1)                     132,160      132,160\n",
      "layer3.1.cbam.ca                                             ChannelAttention          (4, 1024, 8, 8)                     132,160      132,160\n",
      "layer3.1.cbam.sa.conv                                        Conv2d                    (4, 1, 8, 8)                             98           98\n",
      "layer3.1.cbam.sa.bn                                          BatchNorm2d               (4, 1, 8, 8)                              2            2\n",
      "layer3.1.cbam.sa                                             SpatialAttention          (4, 1024, 8, 8)                         100          100\n",
      "layer3.1.cbam                                                CBAM                      (4, 1024, 8, 8)                     132,260      132,260\n",
      "layer3.1                                                     BottleneckCBAM            (4, 1024, 8, 8)                   1,249,444    1,249,444\n",
      "layer3.2.conv1                                               Conv2d                    (4, 256, 8, 8)                      262,144      262,144\n",
      "layer3.2.bn1                                                 BatchNorm2d               (4, 256, 8, 8)                          512          512\n",
      "layer3.2.relu                                                ReLU                      (4, 1024, 8, 8)                           0            0\n",
      "layer3.2.conv2                                               Conv2d                    (4, 256, 8, 8)                      589,824      589,824\n",
      "layer3.2.bn2                                                 BatchNorm2d               (4, 256, 8, 8)                          512          512\n",
      "layer3.2.conv3                                               Conv2d                    (4, 1024, 8, 8)                     262,144      262,144\n",
      "layer3.2.bn3                                                 BatchNorm2d               (4, 1024, 8, 8)                       2,048        2,048\n",
      "layer3.2.cbam.ca.mlp.0                                       Conv2d                    (4, 64, 1, 1)                        65,600       65,600\n",
      "layer3.2.cbam.ca.mlp.1                                       ReLU                      (4, 64, 1, 1)                             0            0\n",
      "layer3.2.cbam.ca.mlp.2                                       Conv2d                    (4, 1024, 1, 1)                      66,560       66,560\n",
      "layer3.2.cbam.ca.mlp                                         Sequential                (4, 1024, 1, 1)                     132,160      132,160\n",
      "layer3.2.cbam.ca                                             ChannelAttention          (4, 1024, 8, 8)                     132,160      132,160\n",
      "layer3.2.cbam.sa.conv                                        Conv2d                    (4, 1, 8, 8)                             98           98\n",
      "layer3.2.cbam.sa.bn                                          BatchNorm2d               (4, 1, 8, 8)                              2            2\n",
      "layer3.2.cbam.sa                                             SpatialAttention          (4, 1024, 8, 8)                         100          100\n",
      "layer3.2.cbam                                                CBAM                      (4, 1024, 8, 8)                     132,260      132,260\n",
      "layer3.2                                                     BottleneckCBAM            (4, 1024, 8, 8)                   1,249,444    1,249,444\n",
      "layer3.3.conv1                                               Conv2d                    (4, 256, 8, 8)                      262,144      262,144\n",
      "layer3.3.bn1                                                 BatchNorm2d               (4, 256, 8, 8)                          512          512\n",
      "layer3.3.relu                                                ReLU                      (4, 1024, 8, 8)                           0            0\n",
      "layer3.3.conv2                                               Conv2d                    (4, 256, 8, 8)                      589,824      589,824\n",
      "layer3.3.bn2                                                 BatchNorm2d               (4, 256, 8, 8)                          512          512\n",
      "layer3.3.conv3                                               Conv2d                    (4, 1024, 8, 8)                     262,144      262,144\n",
      "layer3.3.bn3                                                 BatchNorm2d               (4, 1024, 8, 8)                       2,048        2,048\n",
      "layer3.3.cbam.ca.mlp.0                                       Conv2d                    (4, 64, 1, 1)                        65,600       65,600\n",
      "layer3.3.cbam.ca.mlp.1                                       ReLU                      (4, 64, 1, 1)                             0            0\n",
      "layer3.3.cbam.ca.mlp.2                                       Conv2d                    (4, 1024, 1, 1)                      66,560       66,560\n",
      "layer3.3.cbam.ca.mlp                                         Sequential                (4, 1024, 1, 1)                     132,160      132,160\n",
      "layer3.3.cbam.ca                                             ChannelAttention          (4, 1024, 8, 8)                     132,160      132,160\n",
      "layer3.3.cbam.sa.conv                                        Conv2d                    (4, 1, 8, 8)                             98           98\n",
      "layer3.3.cbam.sa.bn                                          BatchNorm2d               (4, 1, 8, 8)                              2            2\n",
      "layer3.3.cbam.sa                                             SpatialAttention          (4, 1024, 8, 8)                         100          100\n",
      "layer3.3.cbam                                                CBAM                      (4, 1024, 8, 8)                     132,260      132,260\n",
      "layer3.3                                                     BottleneckCBAM            (4, 1024, 8, 8)                   1,249,444    1,249,444\n",
      "layer3.4.conv1                                               Conv2d                    (4, 256, 8, 8)                      262,144      262,144\n",
      "layer3.4.bn1                                                 BatchNorm2d               (4, 256, 8, 8)                          512          512\n",
      "layer3.4.relu                                                ReLU                      (4, 1024, 8, 8)                           0            0\n",
      "layer3.4.conv2                                               Conv2d                    (4, 256, 8, 8)                      589,824      589,824\n",
      "layer3.4.bn2                                                 BatchNorm2d               (4, 256, 8, 8)                          512          512\n",
      "layer3.4.conv3                                               Conv2d                    (4, 1024, 8, 8)                     262,144      262,144\n",
      "layer3.4.bn3                                                 BatchNorm2d               (4, 1024, 8, 8)                       2,048        2,048\n",
      "layer3.4.cbam.ca.mlp.0                                       Conv2d                    (4, 64, 1, 1)                        65,600       65,600\n",
      "layer3.4.cbam.ca.mlp.1                                       ReLU                      (4, 64, 1, 1)                             0            0\n",
      "layer3.4.cbam.ca.mlp.2                                       Conv2d                    (4, 1024, 1, 1)                      66,560       66,560\n",
      "layer3.4.cbam.ca.mlp                                         Sequential                (4, 1024, 1, 1)                     132,160      132,160\n",
      "layer3.4.cbam.ca                                             ChannelAttention          (4, 1024, 8, 8)                     132,160      132,160\n",
      "layer3.4.cbam.sa.conv                                        Conv2d                    (4, 1, 8, 8)                             98           98\n",
      "layer3.4.cbam.sa.bn                                          BatchNorm2d               (4, 1, 8, 8)                              2            2\n",
      "layer3.4.cbam.sa                                             SpatialAttention          (4, 1024, 8, 8)                         100          100\n",
      "layer3.4.cbam                                                CBAM                      (4, 1024, 8, 8)                     132,260      132,260\n",
      "layer3.4                                                     BottleneckCBAM            (4, 1024, 8, 8)                   1,249,444    1,249,444\n",
      "layer3.5.conv1                                               Conv2d                    (4, 256, 8, 8)                      262,144      262,144\n",
      "layer3.5.bn1                                                 BatchNorm2d               (4, 256, 8, 8)                          512          512\n",
      "layer3.5.relu                                                ReLU                      (4, 1024, 8, 8)                           0            0\n",
      "layer3.5.conv2                                               Conv2d                    (4, 256, 8, 8)                      589,824      589,824\n",
      "layer3.5.bn2                                                 BatchNorm2d               (4, 256, 8, 8)                          512          512\n",
      "layer3.5.conv3                                               Conv2d                    (4, 1024, 8, 8)                     262,144      262,144\n",
      "layer3.5.bn3                                                 BatchNorm2d               (4, 1024, 8, 8)                       2,048        2,048\n",
      "layer3.5.cbam.ca.mlp.0                                       Conv2d                    (4, 64, 1, 1)                        65,600       65,600\n",
      "layer3.5.cbam.ca.mlp.1                                       ReLU                      (4, 64, 1, 1)                             0            0\n",
      "layer3.5.cbam.ca.mlp.2                                       Conv2d                    (4, 1024, 1, 1)                      66,560       66,560\n",
      "layer3.5.cbam.ca.mlp                                         Sequential                (4, 1024, 1, 1)                     132,160      132,160\n",
      "layer3.5.cbam.ca                                             ChannelAttention          (4, 1024, 8, 8)                     132,160      132,160\n",
      "layer3.5.cbam.sa.conv                                        Conv2d                    (4, 1, 8, 8)                             98           98\n",
      "layer3.5.cbam.sa.bn                                          BatchNorm2d               (4, 1, 8, 8)                              2            2\n",
      "layer3.5.cbam.sa                                             SpatialAttention          (4, 1024, 8, 8)                         100          100\n",
      "layer3.5.cbam                                                CBAM                      (4, 1024, 8, 8)                     132,260      132,260\n",
      "layer3.5                                                     BottleneckCBAM            (4, 1024, 8, 8)                   1,249,444    1,249,444\n",
      "layer3                                                       Sequential                (4, 1024, 8, 8)                   7,891,928    7,891,928\n",
      "layer4.0.conv1                                               Conv2d                    (4, 512, 8, 8)                      524,288      524,288\n",
      "layer4.0.bn1                                                 BatchNorm2d               (4, 512, 8, 8)                        1,024        1,024\n",
      "layer4.0.relu                                                ReLU                      (4, 2048, 4, 4)                           0            0\n",
      "layer4.0.conv2                                               Conv2d                    (4, 512, 4, 4)                    2,359,296    2,359,296\n",
      "layer4.0.bn2                                                 BatchNorm2d               (4, 512, 4, 4)                        1,024        1,024\n",
      "layer4.0.conv3                                               Conv2d                    (4, 2048, 4, 4)                   1,048,576    1,048,576\n",
      "layer4.0.bn3                                                 BatchNorm2d               (4, 2048, 4, 4)                       4,096        4,096\n",
      "layer4.0.downsample.0                                        Conv2d                    (4, 2048, 4, 4)                   2,097,152    2,097,152\n",
      "layer4.0.downsample.1                                        BatchNorm2d               (4, 2048, 4, 4)                       4,096        4,096\n",
      "layer4.0.downsample                                          Sequential                (4, 2048, 4, 4)                   2,101,248    2,101,248\n",
      "layer4.0.cbam.ca.mlp.0                                       Conv2d                    (4, 128, 1, 1)                      262,272      262,272\n",
      "layer4.0.cbam.ca.mlp.1                                       ReLU                      (4, 128, 1, 1)                            0            0\n",
      "layer4.0.cbam.ca.mlp.2                                       Conv2d                    (4, 2048, 1, 1)                     264,192      264,192\n",
      "layer4.0.cbam.ca.mlp                                         Sequential                (4, 2048, 1, 1)                     526,464      526,464\n",
      "layer4.0.cbam.ca                                             ChannelAttention          (4, 2048, 4, 4)                     526,464      526,464\n",
      "layer4.0.cbam.sa.conv                                        Conv2d                    (4, 1, 4, 4)                             98           98\n",
      "layer4.0.cbam.sa.bn                                          BatchNorm2d               (4, 1, 4, 4)                              2            2\n",
      "layer4.0.cbam.sa                                             SpatialAttention          (4, 2048, 4, 4)                         100          100\n",
      "layer4.0.cbam                                                CBAM                      (4, 2048, 4, 4)                     526,564      526,564\n",
      "layer4.0                                                     BottleneckCBAM            (4, 2048, 4, 4)                   6,566,116    6,566,116\n",
      "layer4.1.conv1                                               Conv2d                    (4, 512, 4, 4)                    1,048,576    1,048,576\n",
      "layer4.1.bn1                                                 BatchNorm2d               (4, 512, 4, 4)                        1,024        1,024\n",
      "layer4.1.relu                                                ReLU                      (4, 2048, 4, 4)                           0            0\n",
      "layer4.1.conv2                                               Conv2d                    (4, 512, 4, 4)                    2,359,296    2,359,296\n",
      "layer4.1.bn2                                                 BatchNorm2d               (4, 512, 4, 4)                        1,024        1,024\n",
      "layer4.1.conv3                                               Conv2d                    (4, 2048, 4, 4)                   1,048,576    1,048,576\n",
      "layer4.1.bn3                                                 BatchNorm2d               (4, 2048, 4, 4)                       4,096        4,096\n",
      "layer4.1.cbam.ca.mlp.0                                       Conv2d                    (4, 128, 1, 1)                      262,272      262,272\n",
      "layer4.1.cbam.ca.mlp.1                                       ReLU                      (4, 128, 1, 1)                            0            0\n",
      "layer4.1.cbam.ca.mlp.2                                       Conv2d                    (4, 2048, 1, 1)                     264,192      264,192\n",
      "layer4.1.cbam.ca.mlp                                         Sequential                (4, 2048, 1, 1)                     526,464      526,464\n",
      "layer4.1.cbam.ca                                             ChannelAttention          (4, 2048, 4, 4)                     526,464      526,464\n",
      "layer4.1.cbam.sa.conv                                        Conv2d                    (4, 1, 4, 4)                             98           98\n",
      "layer4.1.cbam.sa.bn                                          BatchNorm2d               (4, 1, 4, 4)                              2            2\n",
      "layer4.1.cbam.sa                                             SpatialAttention          (4, 2048, 4, 4)                         100          100\n",
      "layer4.1.cbam                                                CBAM                      (4, 2048, 4, 4)                     526,564      526,564\n",
      "layer4.1                                                     BottleneckCBAM            (4, 2048, 4, 4)                   4,989,156    4,989,156\n",
      "layer4.2.conv1                                               Conv2d                    (4, 512, 4, 4)                    1,048,576    1,048,576\n",
      "layer4.2.bn1                                                 BatchNorm2d               (4, 512, 4, 4)                        1,024        1,024\n",
      "layer4.2.relu                                                ReLU                      (4, 2048, 4, 4)                           0            0\n",
      "layer4.2.conv2                                               Conv2d                    (4, 512, 4, 4)                    2,359,296    2,359,296\n",
      "layer4.2.bn2                                                 BatchNorm2d               (4, 512, 4, 4)                        1,024        1,024\n",
      "layer4.2.conv3                                               Conv2d                    (4, 2048, 4, 4)                   1,048,576    1,048,576\n",
      "layer4.2.bn3                                                 BatchNorm2d               (4, 2048, 4, 4)                       4,096        4,096\n",
      "layer4.2.cbam.ca.mlp.0                                       Conv2d                    (4, 128, 1, 1)                      262,272      262,272\n",
      "layer4.2.cbam.ca.mlp.1                                       ReLU                      (4, 128, 1, 1)                            0            0\n",
      "layer4.2.cbam.ca.mlp.2                                       Conv2d                    (4, 2048, 1, 1)                     264,192      264,192\n",
      "layer4.2.cbam.ca.mlp                                         Sequential                (4, 2048, 1, 1)                     526,464      526,464\n",
      "layer4.2.cbam.ca                                             ChannelAttention          (4, 2048, 4, 4)                     526,464      526,464\n",
      "layer4.2.cbam.sa.conv                                        Conv2d                    (4, 1, 4, 4)                             98           98\n",
      "layer4.2.cbam.sa.bn                                          BatchNorm2d               (4, 1, 4, 4)                              2            2\n",
      "layer4.2.cbam.sa                                             SpatialAttention          (4, 2048, 4, 4)                         100          100\n",
      "layer4.2.cbam                                                CBAM                      (4, 2048, 4, 4)                     526,564      526,564\n",
      "layer4.2                                                     BottleneckCBAM            (4, 2048, 4, 4)                   4,989,156    4,989,156\n",
      "layer4                                                       Sequential                (4, 2048, 4, 4)                  16,544,428   16,544,428\n",
      "avgpool                                                      AdaptiveAvgPool2d         (4, 2048, 1, 1)                           0            0\n",
      "fc                                                           Linear                    (4, 10)                              20,490       20,490\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                                                                                                                   88,488,362   88,488,362\n"
     ]
    }
   ],
   "source": [
    "# Model summary via forward hooks (works for arbitrary nn.Module)\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Example input shape (adjust to your real input)\n",
    "batch_size = 4\n",
    "in_channels = 3\n",
    "H = W = 32\n",
    "x = torch.randn(batch_size, in_channels, H, W, device=device)\n",
    "\n",
    "# Ensure `model` exists (import/build before running this cell)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "summary = OrderedDict()\n",
    "\n",
    "# Hook fn that records output shape\n",
    "def hook_fn(module, inp, out, name):\n",
    "    # try to get the shape; handle tuples/lists/None\n",
    "    try:\n",
    "        if isinstance(out, (list, tuple)):\n",
    "            out_shape = [tuple(o.shape) if hasattr(o, \"shape\") else str(type(o)) for o in out]\n",
    "        elif out is None:\n",
    "            out_shape = None\n",
    "        else:\n",
    "            out_shape = tuple(out.shape)\n",
    "    except Exception:\n",
    "        out_shape = str(type(out))\n",
    "    # count parameters\n",
    "    total_params = sum(p.numel() for p in module.parameters())\n",
    "    trainable = sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
    "    summary[name] = {\n",
    "        \"module\": module.__class__.__name__,\n",
    "        \"output_shape\": out_shape,\n",
    "        \"params\": total_params,\n",
    "        \"trainable\": trainable\n",
    "    }\n",
    "\n",
    "# Register hooks for all modules except the top-level module (we'll run model(x) anyway)\n",
    "hooks = []\n",
    "for name, module in model.named_modules():\n",
    "    # skip registering hook on the overall model itself to avoid clutter\n",
    "    if name == \"\":\n",
    "        continue\n",
    "    # register hook; use default closure to capture name\n",
    "    hooks.append(module.register_forward_hook(lambda m, inp, out, nm=name: hook_fn(m, inp, out, nm)))\n",
    "\n",
    "# Run a forward pass (hooks populate `summary`)\n",
    "with torch.no_grad():\n",
    "    out = model(x)\n",
    "\n",
    "# remove hooks\n",
    "for h in hooks:\n",
    "    h.remove()\n",
    "\n",
    "# Print nicely\n",
    "lines = []\n",
    "lines.append(f\"{'Name':60} {'Type':25} {'Output Shape':30} {'Params':12} {'Trainable':12}\")\n",
    "lines.append(\"-\"*150)\n",
    "total_params = 0\n",
    "total_trainable = 0\n",
    "for name, info in summary.items():\n",
    "    total_params += info[\"params\"]\n",
    "    total_trainable += info[\"trainable\"]\n",
    "    out_sh = info[\"output_shape\"]\n",
    "    out_sh_str = str(out_sh)\n",
    "    lines.append(f\"{name:60.60} {info['module']:25.25} {out_sh_str:30.30} {info['params']:12,d} {info['trainable']:12,d}\")\n",
    "\n",
    "lines.append(\"-\"*150)\n",
    "lines.append(f\"{'Total':60} {'':25} {'':30} {total_params:12,d} {total_trainable:12,d}\")\n",
    "\n",
    "print(\"\\n\".join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f62fc06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033674d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "679f7883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: resnet_compact Pages: 1 -->\n",
       "<svg width=\"1337pt\" height=\"61pt\"\n",
       " viewBox=\"0.00 0.00 1337.00 61.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 57)\">\n",
       "<title>resnet_compact</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-57 1333,-57 1333,4 -4,4\"/>\n",
       "<!-- input -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>input</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M86,-45.5C86,-45.5 12,-45.5 12,-45.5 6,-45.5 0,-39.5 0,-33.5 0,-33.5 0,-19.5 0,-19.5 0,-13.5 6,-7.5 12,-7.5 12,-7.5 86,-7.5 86,-7.5 92,-7.5 98,-13.5 98,-19.5 98,-19.5 98,-33.5 98,-33.5 98,-39.5 92,-45.5 86,-45.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"49\" y=\"-30.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Input</text>\n",
       "<text text-anchor=\"middle\" x=\"49\" y=\"-15.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(B, C, H, W)</text>\n",
       "</g>\n",
       "<!-- stem -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>stem</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M372,-45.5C372,-45.5 146,-45.5 146,-45.5 140,-45.5 134,-39.5 134,-33.5 134,-33.5 134,-19.5 134,-19.5 134,-13.5 140,-7.5 146,-7.5 146,-7.5 372,-7.5 372,-7.5 378,-7.5 384,-13.5 384,-19.5 384,-19.5 384,-33.5 384,-33.5 384,-39.5 378,-45.5 372,-45.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"259\" y=\"-30.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Stem</text>\n",
       "<text text-anchor=\"middle\" x=\"259\" y=\"-15.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">conv1 &#45;&gt; bn1 &#45;&gt; relu &#45;&gt; maxpool</text>\n",
       "</g>\n",
       "<!-- input&#45;&gt;stem -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>input&#45;&gt;stem</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M98.24,-26.5C106.18,-26.5 114.73,-26.5 123.6,-26.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"123.74,-30 133.74,-26.5 123.74,-23 123.74,-30\"/>\n",
       "</g>\n",
       "<!-- layer1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>layer1</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M519,-53C519,-53 432,-53 432,-53 426,-53 420,-47 420,-41 420,-41 420,-12 420,-12 420,-6 426,0 432,0 432,0 519,0 519,0 525,0 531,-6 531,-12 531,-12 531,-41 531,-41 531,-47 525,-53 519,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"475.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer1</text>\n",
       "<text text-anchor=\"middle\" x=\"475.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"475.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=64</text>\n",
       "</g>\n",
       "<!-- stem&#45;&gt;layer1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>stem&#45;&gt;layer1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M384.15,-26.5C392.88,-26.5 401.46,-26.5 409.64,-26.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"409.78,-30 419.78,-26.5 409.78,-23 409.78,-30\"/>\n",
       "</g>\n",
       "<!-- layer2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>layer2</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M666,-53C666,-53 579,-53 579,-53 573,-53 567,-47 567,-41 567,-41 567,-12 567,-12 567,-6 573,0 579,0 579,0 666,0 666,0 672,0 678,-6 678,-12 678,-12 678,-41 678,-41 678,-47 672,-53 666,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"622.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer2</text>\n",
       "<text text-anchor=\"middle\" x=\"622.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">4Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"622.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=128</text>\n",
       "</g>\n",
       "<!-- layer1&#45;&gt;layer2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>layer1&#45;&gt;layer2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M531.32,-26.5C539.53,-26.5 548.06,-26.5 556.46,-26.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"556.6,-30 566.6,-26.5 556.6,-23 556.6,-30\"/>\n",
       "</g>\n",
       "<!-- layer3 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>layer3</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M813,-53C813,-53 726,-53 726,-53 720,-53 714,-47 714,-41 714,-41 714,-12 714,-12 714,-6 720,0 726,0 726,0 813,0 813,0 819,0 825,-6 825,-12 825,-12 825,-41 825,-41 825,-47 819,-53 813,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"769.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer3</text>\n",
       "<text text-anchor=\"middle\" x=\"769.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">6Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"769.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=256</text>\n",
       "</g>\n",
       "<!-- layer2&#45;&gt;layer3 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>layer2&#45;&gt;layer3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M678.32,-26.5C686.53,-26.5 695.06,-26.5 703.46,-26.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"703.6,-30 713.6,-26.5 703.6,-23 703.6,-30\"/>\n",
       "</g>\n",
       "<!-- layer4 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>layer4</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M960,-53C960,-53 873,-53 873,-53 867,-53 861,-47 861,-41 861,-41 861,-12 861,-12 861,-6 867,0 873,0 873,0 960,0 960,0 966,0 972,-6 972,-12 972,-12 972,-41 972,-41 972,-47 966,-53 960,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"916.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer4</text>\n",
       "<text text-anchor=\"middle\" x=\"916.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"916.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=512</text>\n",
       "</g>\n",
       "<!-- layer3&#45;&gt;layer4 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>layer3&#45;&gt;layer4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M825.32,-26.5C833.53,-26.5 842.06,-26.5 850.46,-26.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"850.6,-30 860.6,-26.5 850.6,-23 850.6,-30\"/>\n",
       "</g>\n",
       "<!-- avgpool -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>avgpool</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M1111,-44.5C1111,-44.5 1020,-44.5 1020,-44.5 1014,-44.5 1008,-38.5 1008,-32.5 1008,-32.5 1008,-20.5 1008,-20.5 1008,-14.5 1014,-8.5 1020,-8.5 1020,-8.5 1111,-8.5 1111,-8.5 1117,-8.5 1123,-14.5 1123,-20.5 1123,-20.5 1123,-32.5 1123,-32.5 1123,-38.5 1117,-44.5 1111,-44.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1065.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">GlobalAvgPool</text>\n",
       "</g>\n",
       "<!-- layer4&#45;&gt;avgpool -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>layer4&#45;&gt;avgpool</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M972.24,-26.5C980.48,-26.5 989.06,-26.5 997.52,-26.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"997.75,-30 1007.75,-26.5 997.75,-23 997.75,-30\"/>\n",
       "</g>\n",
       "<!-- flatten -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>flatten</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M1212,-44.5C1212,-44.5 1171,-44.5 1171,-44.5 1165,-44.5 1159,-38.5 1159,-32.5 1159,-32.5 1159,-20.5 1159,-20.5 1159,-14.5 1165,-8.5 1171,-8.5 1171,-8.5 1212,-8.5 1212,-8.5 1218,-8.5 1224,-14.5 1224,-20.5 1224,-20.5 1224,-32.5 1224,-32.5 1224,-38.5 1218,-44.5 1212,-44.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1191.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Flatten</text>\n",
       "</g>\n",
       "<!-- avgpool&#45;&gt;flatten -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>avgpool&#45;&gt;flatten</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1123.06,-26.5C1131.68,-26.5 1140.44,-26.5 1148.68,-26.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1148.77,-30 1158.77,-26.5 1148.77,-23 1148.77,-30\"/>\n",
       "</g>\n",
       "<!-- fc -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>fc</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M1317,-45.5C1317,-45.5 1272,-45.5 1272,-45.5 1266,-45.5 1260,-39.5 1260,-33.5 1260,-33.5 1260,-19.5 1260,-19.5 1260,-13.5 1266,-7.5 1272,-7.5 1272,-7.5 1317,-7.5 1317,-7.5 1323,-7.5 1329,-13.5 1329,-19.5 1329,-19.5 1329,-33.5 1329,-33.5 1329,-39.5 1323,-45.5 1317,-45.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1294.5\" y=\"-30.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">FC</text>\n",
       "<text text-anchor=\"middle\" x=\"1294.5\" y=\"-15.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=10</text>\n",
       "</g>\n",
       "<!-- flatten&#45;&gt;fc -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>flatten&#45;&gt;fc</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1224.18,-26.5C1232.24,-26.5 1241.05,-26.5 1249.6,-26.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1249.84,-30 1259.84,-26.5 1249.84,-23 1249.84,-30\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7d28e1c1c5e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved compact diagram -> resnet50_cbam_compact.png\n"
     ]
    }
   ],
   "source": [
    "# Compact high-level DAG of model forward flow\n",
    "# Requires graphviz Python package (not the same as system dot) but dot must be on PATH for rendering inline.\n",
    "from graphviz import Digraph\n",
    "import torch\n",
    "\n",
    "def compact_model_graph(model):\n",
    "    dot = Digraph(name=\"resnet_compact\", format=\"png\")\n",
    "    dot.attr(rankdir=\"LR\", fontsize=\"10\")\n",
    "    dot.attr('node', shape='box', style='rounded,filled', fillcolor='#f7f7f7', fontname='Helvetica')\n",
    "\n",
    "    # helper to get layer info\n",
    "    def layer_info(module):\n",
    "        # count bottleneck blocks and out_channels if possible\n",
    "        n_blocks = 0\n",
    "        out_ch = None\n",
    "        for m in module.children():\n",
    "            n_blocks += 1\n",
    "            # try to find conv3 out_channels in first block\n",
    "            if out_ch is None:\n",
    "                for sub in m.modules():\n",
    "                    if isinstance(sub, torch.nn.Conv2d) and sub.kernel_size == (1,1):\n",
    "                        out_ch = sub.out_channels\n",
    "                        break\n",
    "        return n_blocks, out_ch\n",
    "\n",
    "    # top-level nodes\n",
    "    dot.node(\"input\", \"Input\\n(B, C, H, W)\")\n",
    "    dot.node(\"stem\", \"Stem\\nconv1 -> bn1 -> relu -> maxpool\")\n",
    "    # layer nodes\n",
    "    lnodes = []\n",
    "    for name, child in model.named_children():\n",
    "        if name.startswith(\"layer\"):\n",
    "            n_blocks, out_ch = layer_info(child)\n",
    "            label = f\"{name}\\n{n_blocks}Bottleneck\\nout={out_ch}\"\n",
    "            dot.node(name, label)\n",
    "            lnodes.append(name)\n",
    "    dot.node(\"avgpool\", \"GlobalAvgPool\")\n",
    "    dot.node(\"flatten\", \"Flatten\")\n",
    "    dot.node(\"fc\", f\"FC\\nout={getattr(model,'fc').out_features}\")\n",
    "\n",
    "    # edges in forward order\n",
    "    dot.edge(\"input\", \"stem\")\n",
    "    prev = \"stem\"\n",
    "    for ln in lnodes:\n",
    "        dot.edge(prev, ln)\n",
    "        prev = ln\n",
    "    dot.edge(prev, \"avgpool\")\n",
    "    dot.edge(\"avgpool\", \"flatten\")\n",
    "    dot.edge(\"flatten\", \"fc\")\n",
    "\n",
    "    return dot\n",
    "\n",
    "# usage: ensure `model` exists in scope\n",
    "model = model.to('cpu')\n",
    "dot = compact_model_graph(model)\n",
    "# render inline in notebook (or save as file)\n",
    "display(dot)   # in Jupyter this will show the compact PNG/SVG\n",
    "# or save file:\n",
    "dot.render(\"resnet50_cbam_compact\", cleanup=True)\n",
    "print(\"Saved compact diagram -> resnet50_cbam_compact.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a344026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fd76746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: resnet_cbam_compact Pages: 1 -->\n",
       "<svg width=\"1513pt\" height=\"530pt\"\n",
       " viewBox=\"0.00 0.00 1513.00 530.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 526)\">\n",
       "<title>resnet_cbam_compact</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-526 1509,-526 1509,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_layer1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M420.5,-411C420.5,-411 796.5,-411 796.5,-411 802.5,-411 808.5,-417 808.5,-423 808.5,-423 808.5,-502 808.5,-502 808.5,-508 802.5,-514 796.5,-514 796.5,-514 420.5,-514 420.5,-514 414.5,-514 408.5,-508 408.5,-502 408.5,-502 408.5,-423 408.5,-423 408.5,-417 414.5,-411 420.5,-411\"/>\n",
       "<text text-anchor=\"middle\" x=\"608.5\" y=\"-502\" font-family=\"Times,serif\" font-size=\"10.00\">layer1</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_layer2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M567.5,-300C567.5,-300 1092.5,-300 1092.5,-300 1098.5,-300 1104.5,-306 1104.5,-312 1104.5,-312 1104.5,-391 1104.5,-391 1104.5,-397 1098.5,-403 1092.5,-403 1092.5,-403 567.5,-403 567.5,-403 561.5,-403 555.5,-397 555.5,-391 555.5,-391 555.5,-312 555.5,-312 555.5,-306 561.5,-300 567.5,-300\"/>\n",
       "<text text-anchor=\"middle\" x=\"830\" y=\"-391\" font-family=\"Times,serif\" font-size=\"10.00\">layer2</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster_layer3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M714.5,-189C714.5,-189 1485,-189 1485,-189 1491,-189 1497,-195 1497,-201 1497,-201 1497,-280 1497,-280 1497,-286 1491,-292 1485,-292 1485,-292 714.5,-292 714.5,-292 708.5,-292 702.5,-286 702.5,-280 702.5,-280 702.5,-201 702.5,-201 702.5,-195 708.5,-189 714.5,-189\"/>\n",
       "<text text-anchor=\"middle\" x=\"1099.75\" y=\"-280\" font-family=\"Times,serif\" font-size=\"10.00\">layer3</text>\n",
       "</g>\n",
       "<g id=\"clust4\" class=\"cluster\">\n",
       "<title>cluster_layer4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M861.5,-78C861.5,-78 1231,-78 1231,-78 1237,-78 1243,-84 1243,-90 1243,-90 1243,-169 1243,-169 1243,-175 1237,-181 1231,-181 1231,-181 861.5,-181 861.5,-181 855.5,-181 849.5,-175 849.5,-169 849.5,-169 849.5,-90 849.5,-90 849.5,-84 855.5,-78 861.5,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"1046.25\" y=\"-169\" font-family=\"Times,serif\" font-size=\"10.00\">layer4</text>\n",
       "</g>\n",
       "<!-- input -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>input</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M72,-416C72,-416 12,-416 12,-416 6,-416 0,-410 0,-404 0,-404 0,-390 0,-390 0,-384 6,-378 12,-378 12,-378 72,-378 72,-378 78,-378 84,-384 84,-390 84,-390 84,-404 84,-404 84,-410 78,-416 72,-416\"/>\n",
       "<text text-anchor=\"middle\" x=\"42\" y=\"-400.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Input</text>\n",
       "<text text-anchor=\"middle\" x=\"42\" y=\"-385.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(B,C,H,W)</text>\n",
       "</g>\n",
       "<!-- stem -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>stem</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M358,-416C358,-416 132,-416 132,-416 126,-416 120,-410 120,-404 120,-404 120,-390 120,-390 120,-384 126,-378 132,-378 132,-378 358,-378 358,-378 364,-378 370,-384 370,-390 370,-390 370,-404 370,-404 370,-410 364,-416 358,-416\"/>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-400.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Stem</text>\n",
       "<text text-anchor=\"middle\" x=\"245\" y=\"-385.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">conv1 &#45;&gt; bn1 &#45;&gt; relu &#45;&gt; maxpool</text>\n",
       "</g>\n",
       "<!-- input&#45;&gt;stem -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>input&#45;&gt;stem</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.16,-397C92.09,-397 100.79,-397 109.9,-397\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"109.93,-400.5 119.93,-397 109.93,-393.5 109.93,-400.5\"/>\n",
       "</g>\n",
       "<!-- layer1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>layer1</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M505,-376C505,-376 418,-376 418,-376 412,-376 406,-370 406,-364 406,-364 406,-320 406,-320 406,-314 412,-308 418,-308 418,-308 505,-308 505,-308 511,-308 517,-314 517,-320 517,-320 517,-364 517,-364 517,-370 511,-376 505,-376\"/>\n",
       "<text text-anchor=\"middle\" x=\"461.5\" y=\"-360.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer1</text>\n",
       "<text text-anchor=\"middle\" x=\"461.5\" y=\"-345.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"461.5\" y=\"-330.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=64</text>\n",
       "<text text-anchor=\"middle\" x=\"461.5\" y=\"-315.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CBAM: 3/3</text>\n",
       "</g>\n",
       "<!-- stem&#45;&gt;layer1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>stem&#45;&gt;layer1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M320.12,-378C344.7,-371.69 371.86,-364.73 395.68,-358.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"396.86,-361.93 405.67,-356.06 395.12,-355.15 396.86,-361.93\"/>\n",
       "</g>\n",
       "<!-- layer1_0 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>layer1_0</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"506.5,-487 416.5,-487 416.5,-419 506.5,-419 506.5,-487\"/>\n",
       "<text text-anchor=\"middle\" x=\"461.5\" y=\"-471.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer1.0</text>\n",
       "<text text-anchor=\"middle\" x=\"461.5\" y=\"-456.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"461.5\" y=\"-441.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=64</text>\n",
       "<text text-anchor=\"middle\" x=\"461.5\" y=\"-426.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">[CBAM]</text>\n",
       "</g>\n",
       "<!-- stem&#45;&gt;layer1_0 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>stem&#45;&gt;layer1_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M318.92,-416.04C347.57,-423.52 379.87,-431.95 406.37,-438.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"405.67,-442.3 416.23,-441.44 407.44,-435.53 405.67,-442.3\"/>\n",
       "</g>\n",
       "<!-- layer2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>layer2</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M652,-265C652,-265 565,-265 565,-265 559,-265 553,-259 553,-253 553,-253 553,-209 553,-209 553,-203 559,-197 565,-197 565,-197 652,-197 652,-197 658,-197 664,-203 664,-209 664,-209 664,-253 664,-253 664,-259 658,-265 652,-265\"/>\n",
       "<text text-anchor=\"middle\" x=\"608.5\" y=\"-249.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer2</text>\n",
       "<text text-anchor=\"middle\" x=\"608.5\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">4Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"608.5\" y=\"-219.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=128</text>\n",
       "<text text-anchor=\"middle\" x=\"608.5\" y=\"-204.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CBAM: 4/4</text>\n",
       "</g>\n",
       "<!-- layer1&#45;&gt;layer2 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>layer1&#45;&gt;layer2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M507.19,-307.79C522.21,-296.29 539.11,-283.35 554.7,-271.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"556.9,-274.15 562.71,-265.29 552.64,-268.59 556.9,-274.15\"/>\n",
       "</g>\n",
       "<!-- layer2_0 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>layer2_0</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"653.5,-376 563.5,-376 563.5,-308 653.5,-308 653.5,-376\"/>\n",
       "<text text-anchor=\"middle\" x=\"608.5\" y=\"-360.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer2.0</text>\n",
       "<text text-anchor=\"middle\" x=\"608.5\" y=\"-345.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"608.5\" y=\"-330.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=128</text>\n",
       "<text text-anchor=\"middle\" x=\"608.5\" y=\"-315.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">[CBAM]</text>\n",
       "</g>\n",
       "<!-- layer1&#45;&gt;layer2_0 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>layer1&#45;&gt;layer2_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M517.32,-342C529.1,-342 541.55,-342 553.31,-342\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"553.44,-345.5 563.44,-342 553.44,-338.5 553.44,-345.5\"/>\n",
       "</g>\n",
       "<!-- layer3 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>layer3</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M799,-154C799,-154 712,-154 712,-154 706,-154 700,-148 700,-142 700,-142 700,-98 700,-98 700,-92 706,-86 712,-86 712,-86 799,-86 799,-86 805,-86 811,-92 811,-98 811,-98 811,-142 811,-142 811,-148 805,-154 799,-154\"/>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-138.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer3</text>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">6Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=256</text>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-93.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CBAM: 6/6</text>\n",
       "</g>\n",
       "<!-- layer2&#45;&gt;layer3 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>layer2&#45;&gt;layer3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M654.19,-196.79C669.21,-185.29 686.11,-172.35 701.7,-160.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"703.9,-163.15 709.71,-154.29 699.64,-157.59 703.9,-163.15\"/>\n",
       "</g>\n",
       "<!-- layer3_0 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>layer3_0</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"800.5,-265 710.5,-265 710.5,-197 800.5,-197 800.5,-265\"/>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-249.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer3.0</text>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-219.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=256</text>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-204.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">[CBAM]</text>\n",
       "</g>\n",
       "<!-- layer2&#45;&gt;layer3_0 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>layer2&#45;&gt;layer3_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M664.32,-231C676.1,-231 688.55,-231 700.31,-231\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"700.44,-234.5 710.44,-231 700.44,-227.5 700.44,-234.5\"/>\n",
       "</g>\n",
       "<!-- layer4 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>layer4</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M946,-68C946,-68 859,-68 859,-68 853,-68 847,-62 847,-56 847,-56 847,-12 847,-12 847,-6 853,0 859,0 859,0 946,0 946,0 952,0 958,-6 958,-12 958,-12 958,-56 958,-56 958,-62 952,-68 946,-68\"/>\n",
       "<text text-anchor=\"middle\" x=\"902.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer4</text>\n",
       "<text text-anchor=\"middle\" x=\"902.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"902.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=512</text>\n",
       "<text text-anchor=\"middle\" x=\"902.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">CBAM: 3/3</text>\n",
       "</g>\n",
       "<!-- layer3&#45;&gt;layer4 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>layer3&#45;&gt;layer4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M811.32,-87.49C819.98,-82.35 829,-77 837.84,-71.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"839.79,-74.67 846.6,-66.56 836.22,-68.65 839.79,-74.67\"/>\n",
       "</g>\n",
       "<!-- layer4_0 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>layer4_0</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"947.5,-154 857.5,-154 857.5,-86 947.5,-86 947.5,-154\"/>\n",
       "<text text-anchor=\"middle\" x=\"902.5\" y=\"-138.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer4.0</text>\n",
       "<text text-anchor=\"middle\" x=\"902.5\" y=\"-123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"902.5\" y=\"-108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=512</text>\n",
       "<text text-anchor=\"middle\" x=\"902.5\" y=\"-93.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">[CBAM]</text>\n",
       "</g>\n",
       "<!-- layer3&#45;&gt;layer4_0 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>layer3&#45;&gt;layer4_0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M811.32,-120C823.1,-120 835.55,-120 847.31,-120\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"847.44,-123.5 857.44,-120 847.44,-116.5 847.44,-123.5\"/>\n",
       "</g>\n",
       "<!-- avgpool -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>avgpool</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M1097,-52C1097,-52 1006,-52 1006,-52 1000,-52 994,-46 994,-40 994,-40 994,-28 994,-28 994,-22 1000,-16 1006,-16 1006,-16 1097,-16 1097,-16 1103,-16 1109,-22 1109,-28 1109,-28 1109,-40 1109,-40 1109,-46 1103,-52 1097,-52\"/>\n",
       "<text text-anchor=\"middle\" x=\"1051.5\" y=\"-30.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">GlobalAvgPool</text>\n",
       "</g>\n",
       "<!-- layer4&#45;&gt;avgpool -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>layer4&#45;&gt;avgpool</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M958.24,-34C966.48,-34 975.06,-34 983.52,-34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"983.75,-37.5 993.75,-34 983.75,-30.5 983.75,-37.5\"/>\n",
       "</g>\n",
       "<!-- flatten -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>flatten</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M1210.5,-52C1210.5,-52 1169.5,-52 1169.5,-52 1163.5,-52 1157.5,-46 1157.5,-40 1157.5,-40 1157.5,-28 1157.5,-28 1157.5,-22 1163.5,-16 1169.5,-16 1169.5,-16 1210.5,-16 1210.5,-16 1216.5,-16 1222.5,-22 1222.5,-28 1222.5,-28 1222.5,-40 1222.5,-40 1222.5,-46 1216.5,-52 1210.5,-52\"/>\n",
       "<text text-anchor=\"middle\" x=\"1190\" y=\"-30.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Flatten</text>\n",
       "</g>\n",
       "<!-- avgpool&#45;&gt;flatten -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>avgpool&#45;&gt;flatten</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1109.2,-34C1121.89,-34 1135.13,-34 1147.09,-34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1147.23,-37.5 1157.23,-34 1147.23,-30.5 1147.23,-37.5\"/>\n",
       "</g>\n",
       "<!-- fc -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>fc</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M1351,-52C1351,-52 1283,-52 1283,-52 1277,-52 1271,-46 1271,-40 1271,-40 1271,-28 1271,-28 1271,-22 1277,-16 1283,-16 1283,-16 1351,-16 1351,-16 1357,-16 1363,-22 1363,-28 1363,-28 1363,-40 1363,-40 1363,-46 1357,-52 1351,-52\"/>\n",
       "<text text-anchor=\"middle\" x=\"1317\" y=\"-30.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">FC out=10</text>\n",
       "</g>\n",
       "<!-- flatten&#45;&gt;fc -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>flatten&#45;&gt;fc</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1222.54,-34C1234.07,-34 1247.48,-34 1260.48,-34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1260.77,-37.5 1270.77,-34 1260.77,-30.5 1260.77,-37.5\"/>\n",
       "</g>\n",
       "<!-- layer1_1 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>layer1_1</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"653.5,-487 563.5,-487 563.5,-419 653.5,-419 653.5,-487\"/>\n",
       "<text text-anchor=\"middle\" x=\"608.5\" y=\"-471.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer1.1</text>\n",
       "<text text-anchor=\"middle\" x=\"608.5\" y=\"-456.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"608.5\" y=\"-441.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=64</text>\n",
       "<text text-anchor=\"middle\" x=\"608.5\" y=\"-426.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">[CBAM]</text>\n",
       "</g>\n",
       "<!-- layer1_0&#45;&gt;layer1_1 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>layer1_0&#45;&gt;layer1_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M506.79,-453C521.41,-453 537.84,-453 553.12,-453\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"553.48,-456.5 563.48,-453 553.48,-449.5 553.48,-456.5\"/>\n",
       "</g>\n",
       "<!-- layer1_2 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>layer1_2</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"800.5,-487 710.5,-487 710.5,-419 800.5,-419 800.5,-487\"/>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-471.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer1.2</text>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-456.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-441.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=64</text>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-426.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">[CBAM]</text>\n",
       "</g>\n",
       "<!-- layer1_1&#45;&gt;layer1_2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>layer1_1&#45;&gt;layer1_2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M653.79,-453C668.41,-453 684.84,-453 700.12,-453\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"700.48,-456.5 710.48,-453 700.48,-449.5 700.48,-456.5\"/>\n",
       "</g>\n",
       "<!-- layer2_1 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>layer2_1</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"800.5,-376 710.5,-376 710.5,-308 800.5,-308 800.5,-376\"/>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-360.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer2.1</text>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-345.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-330.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=128</text>\n",
       "<text text-anchor=\"middle\" x=\"755.5\" y=\"-315.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">[CBAM]</text>\n",
       "</g>\n",
       "<!-- layer2_0&#45;&gt;layer2_1 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>layer2_0&#45;&gt;layer2_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M653.79,-342C668.41,-342 684.84,-342 700.12,-342\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"700.48,-345.5 710.48,-342 700.48,-338.5 700.48,-345.5\"/>\n",
       "</g>\n",
       "<!-- layer2_2 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>layer2_2</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"947.5,-376 857.5,-376 857.5,-308 947.5,-308 947.5,-376\"/>\n",
       "<text text-anchor=\"middle\" x=\"902.5\" y=\"-360.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer2.2</text>\n",
       "<text text-anchor=\"middle\" x=\"902.5\" y=\"-345.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"902.5\" y=\"-330.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=128</text>\n",
       "<text text-anchor=\"middle\" x=\"902.5\" y=\"-315.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">[CBAM]</text>\n",
       "</g>\n",
       "<!-- layer2_1&#45;&gt;layer2_2 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>layer2_1&#45;&gt;layer2_2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M800.79,-342C815.41,-342 831.84,-342 847.12,-342\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"847.48,-345.5 857.48,-342 847.48,-338.5 847.48,-345.5\"/>\n",
       "</g>\n",
       "<!-- layer2_3 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>layer2_3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"1096.5,-376 1006.5,-376 1006.5,-308 1096.5,-308 1096.5,-376\"/>\n",
       "<text text-anchor=\"middle\" x=\"1051.5\" y=\"-360.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer2.3</text>\n",
       "<text text-anchor=\"middle\" x=\"1051.5\" y=\"-345.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"1051.5\" y=\"-330.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=128</text>\n",
       "<text text-anchor=\"middle\" x=\"1051.5\" y=\"-315.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">[CBAM]</text>\n",
       "</g>\n",
       "<!-- layer2_2&#45;&gt;layer2_3 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>layer2_2&#45;&gt;layer2_3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M947.6,-342C962.87,-342 980.15,-342 996.14,-342\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"996.43,-345.5 1006.43,-342 996.43,-338.5 996.43,-345.5\"/>\n",
       "</g>\n",
       "<!-- layer3_1 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>layer3_1</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"947.5,-265 857.5,-265 857.5,-197 947.5,-197 947.5,-265\"/>\n",
       "<text text-anchor=\"middle\" x=\"902.5\" y=\"-249.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer3.1</text>\n",
       "<text text-anchor=\"middle\" x=\"902.5\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"902.5\" y=\"-219.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=256</text>\n",
       "<text text-anchor=\"middle\" x=\"902.5\" y=\"-204.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">[CBAM]</text>\n",
       "</g>\n",
       "<!-- layer3_0&#45;&gt;layer3_1 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>layer3_0&#45;&gt;layer3_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M800.79,-231C815.41,-231 831.84,-231 847.12,-231\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"847.48,-234.5 857.48,-231 847.48,-227.5 847.48,-234.5\"/>\n",
       "</g>\n",
       "<!-- layer3_2 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>layer3_2</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"1096.5,-265 1006.5,-265 1006.5,-197 1096.5,-197 1096.5,-265\"/>\n",
       "<text text-anchor=\"middle\" x=\"1051.5\" y=\"-249.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer3.2</text>\n",
       "<text text-anchor=\"middle\" x=\"1051.5\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"1051.5\" y=\"-219.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=256</text>\n",
       "<text text-anchor=\"middle\" x=\"1051.5\" y=\"-204.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">[CBAM]</text>\n",
       "</g>\n",
       "<!-- layer3_1&#45;&gt;layer3_2 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>layer3_1&#45;&gt;layer3_2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M947.6,-231C962.87,-231 980.15,-231 996.14,-231\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"996.43,-234.5 1006.43,-231 996.43,-227.5 996.43,-234.5\"/>\n",
       "</g>\n",
       "<!-- layer3_3 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>layer3_3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"1235,-265 1145,-265 1145,-197 1235,-197 1235,-265\"/>\n",
       "<text text-anchor=\"middle\" x=\"1190\" y=\"-249.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer3.3</text>\n",
       "<text text-anchor=\"middle\" x=\"1190\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"1190\" y=\"-219.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=256</text>\n",
       "<text text-anchor=\"middle\" x=\"1190\" y=\"-204.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">[CBAM]</text>\n",
       "</g>\n",
       "<!-- layer3_2&#45;&gt;layer3_3 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>layer3_2&#45;&gt;layer3_3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1096.82,-231C1108.86,-231 1122.04,-231 1134.57,-231\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1134.9,-234.5 1144.9,-231 1134.9,-227.5 1134.9,-234.5\"/>\n",
       "</g>\n",
       "<!-- layer3_4 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>layer3_4</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"1362,-265 1272,-265 1272,-197 1362,-197 1362,-265\"/>\n",
       "<text text-anchor=\"middle\" x=\"1317\" y=\"-249.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer3.4</text>\n",
       "<text text-anchor=\"middle\" x=\"1317\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"1317\" y=\"-219.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=256</text>\n",
       "<text text-anchor=\"middle\" x=\"1317\" y=\"-204.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">[CBAM]</text>\n",
       "</g>\n",
       "<!-- layer3_3&#45;&gt;layer3_4 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>layer3_3&#45;&gt;layer3_4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1235.07,-231C1243.66,-231 1252.76,-231 1261.63,-231\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1261.91,-234.5 1271.91,-231 1261.91,-227.5 1261.91,-234.5\"/>\n",
       "</g>\n",
       "<!-- layer3_5 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>layer3_5</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"1489,-265 1399,-265 1399,-197 1489,-197 1489,-265\"/>\n",
       "<text text-anchor=\"middle\" x=\"1444\" y=\"-249.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer3.5</text>\n",
       "<text text-anchor=\"middle\" x=\"1444\" y=\"-234.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"1444\" y=\"-219.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=256</text>\n",
       "<text text-anchor=\"middle\" x=\"1444\" y=\"-204.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">[CBAM]</text>\n",
       "</g>\n",
       "<!-- layer3_4&#45;&gt;layer3_5 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>layer3_4&#45;&gt;layer3_5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1362.07,-231C1370.66,-231 1379.76,-231 1388.63,-231\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1388.91,-234.5 1398.91,-231 1388.91,-227.5 1388.91,-234.5\"/>\n",
       "</g>\n",
       "<!-- layer4_1 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>layer4_1</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"1096.5,-154 1006.5,-154 1006.5,-86 1096.5,-86 1096.5,-154\"/>\n",
       "<text text-anchor=\"middle\" x=\"1051.5\" y=\"-138.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer4.1</text>\n",
       "<text text-anchor=\"middle\" x=\"1051.5\" y=\"-123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"1051.5\" y=\"-108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=512</text>\n",
       "<text text-anchor=\"middle\" x=\"1051.5\" y=\"-93.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">[CBAM]</text>\n",
       "</g>\n",
       "<!-- layer4_0&#45;&gt;layer4_1 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>layer4_0&#45;&gt;layer4_1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M947.6,-120C962.87,-120 980.15,-120 996.14,-120\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"996.43,-123.5 1006.43,-120 996.43,-116.5 996.43,-123.5\"/>\n",
       "</g>\n",
       "<!-- layer4_2 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>layer4_2</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"1235,-154 1145,-154 1145,-86 1235,-86 1235,-154\"/>\n",
       "<text text-anchor=\"middle\" x=\"1190\" y=\"-138.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">layer4.2</text>\n",
       "<text text-anchor=\"middle\" x=\"1190\" y=\"-123.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Bottleneck</text>\n",
       "<text text-anchor=\"middle\" x=\"1190\" y=\"-108.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">out=512</text>\n",
       "<text text-anchor=\"middle\" x=\"1190\" y=\"-93.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">[CBAM]</text>\n",
       "</g>\n",
       "<!-- layer4_1&#45;&gt;layer4_2 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>layer4_1&#45;&gt;layer4_2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1096.82,-120C1108.86,-120 1122.04,-120 1134.57,-120\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1134.9,-123.5 1144.9,-120 1134.9,-116.5 1134.9,-123.5\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7d291033f460>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved -> resnet50_cbam_compact_with_cbam.png\n"
     ]
    }
   ],
   "source": [
    "# Compact graph showing Bottleneck blocks and CBAM\n",
    "from graphviz import Digraph\n",
    "import torch\n",
    "\n",
    "def compact_graph_with_cbam(model):\n",
    "    dot = Digraph(name=\"resnet_cbam_compact\", format=\"png\")\n",
    "    dot.attr(rankdir=\"LR\", fontsize=\"10\")\n",
    "    dot.attr('node', shape='box', style='rounded,filled', fillcolor='#f7f7f7', fontname='Helvetica')\n",
    "\n",
    "    dot.node(\"input\", \"Input\\n(B,C,H,W)\")\n",
    "    dot.node(\"stem\", \"Stem\\nconv1 -> bn1 -> relu -> maxpool\")\n",
    "\n",
    "    # Helper to get info per layer: number of blocks and whether block has CBAM\n",
    "    def layer_blocks_info(layer_module):\n",
    "        info = []\n",
    "        for idx, block in enumerate(layer_module.children()):\n",
    "            # detect CBAM existence on block\n",
    "            has_cbam = any(sub.__class__.__name__ == \"CBAM\" for sub in block.modules())\n",
    "            # out channels: try conv3 out_channels if present\n",
    "            out_ch = None\n",
    "            for sub in block.modules():\n",
    "                if isinstance(sub, torch.nn.Conv2d) and sub.kernel_size == (1,1):\n",
    "                    out_ch = sub.out_channels\n",
    "                    break\n",
    "            info.append((idx, has_cbam, out_ch))\n",
    "        return info\n",
    "\n",
    "    # add nodes for each layer with compact labels\n",
    "    layer_nodes = []\n",
    "    for name, child in model.named_children():\n",
    "        if name.startswith(\"layer\"):\n",
    "            blocks = layer_blocks_info(child)\n",
    "            n_blocks = len(blocks)\n",
    "            # compute annotation summarizing CBAM presence counts\n",
    "            cbam_count = sum(1 for _,has_cbam,_ in blocks if has_cbam)\n",
    "            out_ch = next((b[2] for b in blocks if b[2] is not None), None)\n",
    "            label = f\"{name}\\n{n_blocks}Bottleneck\\nout={out_ch}\\nCBAM: {cbam_count}/{n_blocks}\"\n",
    "            dot.node(name, label)\n",
    "            layer_nodes.append((name, blocks))\n",
    "\n",
    "    dot.node(\"avgpool\", \"GlobalAvgPool\")\n",
    "    dot.node(\"flatten\", \"Flatten\")\n",
    "    dot.node(\"fc\", f\"FC out={model.fc.out_features}\")\n",
    "\n",
    "    # build edges: stem -> layer1... -> avgpool -> flatten -> fc\n",
    "    dot.edge(\"input\", \"stem\")\n",
    "    prev = \"stem\"\n",
    "    for name, blocks in layer_nodes:\n",
    "        dot.edge(prev, name)\n",
    "        # Create a subgraph cluster for the layer to show block-level detail\n",
    "        with dot.subgraph(name=f\"cluster_{name}\") as c:\n",
    "            c.attr(label=name, style='rounded')\n",
    "            for idx, has_cbam, out_ch in blocks:\n",
    "                block_label = f\"{name}.{idx}\\nBottleneck\\nout={out_ch}\"\n",
    "                if has_cbam:\n",
    "                    block_label += \"\\n[CBAM]\"\n",
    "                node_name = f\"{name}_{idx}\"\n",
    "                c.node(node_name, block_label, shape='box', style='filled', fillcolor='#ffffff')\n",
    "                # connect previous to first block and chain blocks\n",
    "                if idx == 0:\n",
    "                    dot.edge(prev, node_name)\n",
    "                else:\n",
    "                    prev_block = f\"{name}_{idx-1}\"\n",
    "                    dot.edge(prev_block, node_name)\n",
    "        prev = name\n",
    "\n",
    "    dot.edge(prev, \"avgpool\")\n",
    "    dot.edge(\"avgpool\", \"flatten\")\n",
    "    dot.edge(\"flatten\", \"fc\")\n",
    "    return dot\n",
    "\n",
    "# Usage (ensure model present)\n",
    "model = model.to('cpu')\n",
    "dot = compact_graph_with_cbam(model)\n",
    "display(dot)           # show inline in notebook\n",
    "dot.render(\"resnet50_cbam_compact_with_cbam\", cleanup=True)\n",
    "print(\"Saved -> resnet50_cbam_compact_with_cbam.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f8dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08715b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d               (1, 64, 32, 32)\n",
      "BatchNorm2d          (1, 64, 32, 32)\n",
      "ReLU                 (1, 64, 32, 32)\n",
      "Conv2d               (1, 64, 32, 32)\n",
      "BatchNorm2d          (1, 64, 32, 32)\n",
      "ReLU                 (1, 64, 32, 32)\n",
      "Conv2d               (1, 64, 32, 32)\n",
      "BatchNorm2d          (1, 64, 32, 32)\n",
      "ReLU                 (1, 64, 32, 32)\n",
      "Conv2d               (1, 256, 32, 32)\n",
      "BatchNorm2d          (1, 256, 32, 32)\n",
      "Conv2d               (1, 256, 32, 32)\n",
      "BatchNorm2d          (1, 256, 32, 32)\n",
      "Conv2d               (1, 16, 1, 1)\n",
      "ReLU                 (1, 16, 1, 1)\n",
      "Conv2d               (1, 256, 1, 1)\n",
      "Conv2d               (1, 16, 1, 1)\n",
      "ReLU                 (1, 16, 1, 1)\n",
      "Conv2d               (1, 256, 1, 1)\n",
      "Conv2d               (1, 1, 32, 32)\n",
      "BatchNorm2d          (1, 1, 32, 32)\n",
      "ReLU                 (1, 256, 32, 32)\n",
      "BottleneckCBAM       (1, 256, 32, 32)\n",
      "Conv2d               (1, 64, 32, 32)\n",
      "BatchNorm2d          (1, 64, 32, 32)\n",
      "ReLU                 (1, 64, 32, 32)\n",
      "Conv2d               (1, 64, 32, 32)\n",
      "BatchNorm2d          (1, 64, 32, 32)\n",
      "ReLU                 (1, 64, 32, 32)\n",
      "Conv2d               (1, 256, 32, 32)\n",
      "BatchNorm2d          (1, 256, 32, 32)\n",
      "Conv2d               (1, 16, 1, 1)\n",
      "ReLU                 (1, 16, 1, 1)\n",
      "Conv2d               (1, 256, 1, 1)\n",
      "Conv2d               (1, 16, 1, 1)\n",
      "ReLU                 (1, 16, 1, 1)\n",
      "Conv2d               (1, 256, 1, 1)\n",
      "Conv2d               (1, 1, 32, 32)\n",
      "BatchNorm2d          (1, 1, 32, 32)\n",
      "ReLU                 (1, 256, 32, 32)\n",
      "BottleneckCBAM       (1, 256, 32, 32)\n",
      "Conv2d               (1, 64, 32, 32)\n",
      "BatchNorm2d          (1, 64, 32, 32)\n",
      "ReLU                 (1, 64, 32, 32)\n",
      "Conv2d               (1, 64, 32, 32)\n",
      "BatchNorm2d          (1, 64, 32, 32)\n",
      "ReLU                 (1, 64, 32, 32)\n",
      "Conv2d               (1, 256, 32, 32)\n",
      "BatchNorm2d          (1, 256, 32, 32)\n",
      "Conv2d               (1, 16, 1, 1)\n",
      "ReLU                 (1, 16, 1, 1)\n",
      "Conv2d               (1, 256, 1, 1)\n",
      "Conv2d               (1, 16, 1, 1)\n",
      "ReLU                 (1, 16, 1, 1)\n",
      "Conv2d               (1, 256, 1, 1)\n",
      "Conv2d               (1, 1, 32, 32)\n",
      "BatchNorm2d          (1, 1, 32, 32)\n",
      "ReLU                 (1, 256, 32, 32)\n",
      "BottleneckCBAM       (1, 256, 32, 32)\n",
      "Conv2d               (1, 128, 32, 32)\n",
      "BatchNorm2d          (1, 128, 32, 32)\n",
      "ReLU                 (1, 128, 32, 32)\n",
      "Conv2d               (1, 128, 16, 16)\n",
      "BatchNorm2d          (1, 128, 16, 16)\n",
      "ReLU                 (1, 128, 16, 16)\n",
      "Conv2d               (1, 512, 16, 16)\n",
      "BatchNorm2d          (1, 512, 16, 16)\n",
      "Conv2d               (1, 512, 16, 16)\n",
      "BatchNorm2d          (1, 512, 16, 16)\n",
      "Conv2d               (1, 32, 1, 1)\n",
      "ReLU                 (1, 32, 1, 1)\n",
      "Conv2d               (1, 512, 1, 1)\n",
      "Conv2d               (1, 32, 1, 1)\n",
      "ReLU                 (1, 32, 1, 1)\n",
      "Conv2d               (1, 512, 1, 1)\n",
      "Conv2d               (1, 1, 16, 16)\n",
      "BatchNorm2d          (1, 1, 16, 16)\n",
      "ReLU                 (1, 512, 16, 16)\n",
      "BottleneckCBAM       (1, 512, 16, 16)\n",
      "Conv2d               (1, 128, 16, 16)\n",
      "BatchNorm2d          (1, 128, 16, 16)\n",
      "ReLU                 (1, 128, 16, 16)\n",
      "Conv2d               (1, 128, 16, 16)\n",
      "BatchNorm2d          (1, 128, 16, 16)\n",
      "ReLU                 (1, 128, 16, 16)\n",
      "Conv2d               (1, 512, 16, 16)\n",
      "BatchNorm2d          (1, 512, 16, 16)\n",
      "Conv2d               (1, 32, 1, 1)\n",
      "ReLU                 (1, 32, 1, 1)\n",
      "Conv2d               (1, 512, 1, 1)\n",
      "Conv2d               (1, 32, 1, 1)\n",
      "ReLU                 (1, 32, 1, 1)\n",
      "Conv2d               (1, 512, 1, 1)\n",
      "Conv2d               (1, 1, 16, 16)\n",
      "BatchNorm2d          (1, 1, 16, 16)\n",
      "ReLU                 (1, 512, 16, 16)\n",
      "BottleneckCBAM       (1, 512, 16, 16)\n",
      "Conv2d               (1, 128, 16, 16)\n",
      "BatchNorm2d          (1, 128, 16, 16)\n",
      "ReLU                 (1, 128, 16, 16)\n",
      "Conv2d               (1, 128, 16, 16)\n",
      "BatchNorm2d          (1, 128, 16, 16)\n",
      "ReLU                 (1, 128, 16, 16)\n",
      "Conv2d               (1, 512, 16, 16)\n",
      "BatchNorm2d          (1, 512, 16, 16)\n",
      "Conv2d               (1, 32, 1, 1)\n",
      "ReLU                 (1, 32, 1, 1)\n",
      "Conv2d               (1, 512, 1, 1)\n",
      "Conv2d               (1, 32, 1, 1)\n",
      "ReLU                 (1, 32, 1, 1)\n",
      "Conv2d               (1, 512, 1, 1)\n",
      "Conv2d               (1, 1, 16, 16)\n",
      "BatchNorm2d          (1, 1, 16, 16)\n",
      "ReLU                 (1, 512, 16, 16)\n",
      "BottleneckCBAM       (1, 512, 16, 16)\n",
      "Conv2d               (1, 128, 16, 16)\n",
      "BatchNorm2d          (1, 128, 16, 16)\n",
      "ReLU                 (1, 128, 16, 16)\n",
      "Conv2d               (1, 128, 16, 16)\n",
      "BatchNorm2d          (1, 128, 16, 16)\n",
      "ReLU                 (1, 128, 16, 16)\n",
      "Conv2d               (1, 512, 16, 16)\n",
      "BatchNorm2d          (1, 512, 16, 16)\n",
      "Conv2d               (1, 32, 1, 1)\n",
      "ReLU                 (1, 32, 1, 1)\n",
      "Conv2d               (1, 512, 1, 1)\n",
      "Conv2d               (1, 32, 1, 1)\n",
      "ReLU                 (1, 32, 1, 1)\n",
      "Conv2d               (1, 512, 1, 1)\n",
      "Conv2d               (1, 1, 16, 16)\n",
      "BatchNorm2d          (1, 1, 16, 16)\n",
      "ReLU                 (1, 512, 16, 16)\n",
      "BottleneckCBAM       (1, 512, 16, 16)\n",
      "Conv2d               (1, 256, 16, 16)\n",
      "BatchNorm2d          (1, 256, 16, 16)\n",
      "ReLU                 (1, 256, 16, 16)\n",
      "Conv2d               (1, 256, 8, 8)\n",
      "BatchNorm2d          (1, 256, 8, 8)\n",
      "ReLU                 (1, 256, 8, 8)\n",
      "Conv2d               (1, 1024, 8, 8)\n",
      "BatchNorm2d          (1, 1024, 8, 8)\n",
      "Conv2d               (1, 1024, 8, 8)\n",
      "BatchNorm2d          (1, 1024, 8, 8)\n",
      "Conv2d               (1, 64, 1, 1)\n",
      "ReLU                 (1, 64, 1, 1)\n",
      "Conv2d               (1, 1024, 1, 1)\n",
      "Conv2d               (1, 64, 1, 1)\n",
      "ReLU                 (1, 64, 1, 1)\n",
      "Conv2d               (1, 1024, 1, 1)\n",
      "Conv2d               (1, 1, 8, 8)\n",
      "BatchNorm2d          (1, 1, 8, 8)\n",
      "ReLU                 (1, 1024, 8, 8)\n",
      "BottleneckCBAM       (1, 1024, 8, 8)\n",
      "Conv2d               (1, 256, 8, 8)\n",
      "BatchNorm2d          (1, 256, 8, 8)\n",
      "ReLU                 (1, 256, 8, 8)\n",
      "Conv2d               (1, 256, 8, 8)\n",
      "BatchNorm2d          (1, 256, 8, 8)\n",
      "ReLU                 (1, 256, 8, 8)\n",
      "Conv2d               (1, 1024, 8, 8)\n",
      "BatchNorm2d          (1, 1024, 8, 8)\n",
      "Conv2d               (1, 64, 1, 1)\n",
      "ReLU                 (1, 64, 1, 1)\n",
      "Conv2d               (1, 1024, 1, 1)\n",
      "Conv2d               (1, 64, 1, 1)\n",
      "ReLU                 (1, 64, 1, 1)\n",
      "Conv2d               (1, 1024, 1, 1)\n",
      "Conv2d               (1, 1, 8, 8)\n",
      "BatchNorm2d          (1, 1, 8, 8)\n",
      "ReLU                 (1, 1024, 8, 8)\n",
      "BottleneckCBAM       (1, 1024, 8, 8)\n",
      "Conv2d               (1, 256, 8, 8)\n",
      "BatchNorm2d          (1, 256, 8, 8)\n",
      "ReLU                 (1, 256, 8, 8)\n",
      "Conv2d               (1, 256, 8, 8)\n",
      "BatchNorm2d          (1, 256, 8, 8)\n",
      "ReLU                 (1, 256, 8, 8)\n",
      "Conv2d               (1, 1024, 8, 8)\n",
      "BatchNorm2d          (1, 1024, 8, 8)\n",
      "Conv2d               (1, 64, 1, 1)\n",
      "ReLU                 (1, 64, 1, 1)\n",
      "Conv2d               (1, 1024, 1, 1)\n",
      "Conv2d               (1, 64, 1, 1)\n",
      "ReLU                 (1, 64, 1, 1)\n",
      "Conv2d               (1, 1024, 1, 1)\n",
      "Conv2d               (1, 1, 8, 8)\n",
      "BatchNorm2d          (1, 1, 8, 8)\n",
      "ReLU                 (1, 1024, 8, 8)\n",
      "BottleneckCBAM       (1, 1024, 8, 8)\n",
      "Conv2d               (1, 256, 8, 8)\n",
      "BatchNorm2d          (1, 256, 8, 8)\n",
      "ReLU                 (1, 256, 8, 8)\n",
      "Conv2d               (1, 256, 8, 8)\n",
      "BatchNorm2d          (1, 256, 8, 8)\n",
      "ReLU                 (1, 256, 8, 8)\n",
      "Conv2d               (1, 1024, 8, 8)\n",
      "BatchNorm2d          (1, 1024, 8, 8)\n",
      "Conv2d               (1, 64, 1, 1)\n",
      "ReLU                 (1, 64, 1, 1)\n",
      "Conv2d               (1, 1024, 1, 1)\n",
      "Conv2d               (1, 64, 1, 1)\n",
      "ReLU                 (1, 64, 1, 1)\n",
      "Conv2d               (1, 1024, 1, 1)\n",
      "Conv2d               (1, 1, 8, 8)\n",
      "BatchNorm2d          (1, 1, 8, 8)\n",
      "ReLU                 (1, 1024, 8, 8)\n",
      "BottleneckCBAM       (1, 1024, 8, 8)\n",
      "Conv2d               (1, 256, 8, 8)\n",
      "BatchNorm2d          (1, 256, 8, 8)\n",
      "ReLU                 (1, 256, 8, 8)\n",
      "Conv2d               (1, 256, 8, 8)\n",
      "BatchNorm2d          (1, 256, 8, 8)\n",
      "ReLU                 (1, 256, 8, 8)\n",
      "Conv2d               (1, 1024, 8, 8)\n",
      "BatchNorm2d          (1, 1024, 8, 8)\n",
      "Conv2d               (1, 64, 1, 1)\n",
      "ReLU                 (1, 64, 1, 1)\n",
      "Conv2d               (1, 1024, 1, 1)\n",
      "Conv2d               (1, 64, 1, 1)\n",
      "ReLU                 (1, 64, 1, 1)\n",
      "Conv2d               (1, 1024, 1, 1)\n",
      "Conv2d               (1, 1, 8, 8)\n",
      "BatchNorm2d          (1, 1, 8, 8)\n",
      "ReLU                 (1, 1024, 8, 8)\n",
      "BottleneckCBAM       (1, 1024, 8, 8)\n",
      "Conv2d               (1, 256, 8, 8)\n",
      "BatchNorm2d          (1, 256, 8, 8)\n",
      "ReLU                 (1, 256, 8, 8)\n",
      "Conv2d               (1, 256, 8, 8)\n",
      "BatchNorm2d          (1, 256, 8, 8)\n",
      "ReLU                 (1, 256, 8, 8)\n",
      "Conv2d               (1, 1024, 8, 8)\n",
      "BatchNorm2d          (1, 1024, 8, 8)\n",
      "Conv2d               (1, 64, 1, 1)\n",
      "ReLU                 (1, 64, 1, 1)\n",
      "Conv2d               (1, 1024, 1, 1)\n",
      "Conv2d               (1, 64, 1, 1)\n",
      "ReLU                 (1, 64, 1, 1)\n",
      "Conv2d               (1, 1024, 1, 1)\n",
      "Conv2d               (1, 1, 8, 8)\n",
      "BatchNorm2d          (1, 1, 8, 8)\n",
      "ReLU                 (1, 1024, 8, 8)\n",
      "BottleneckCBAM       (1, 1024, 8, 8)\n",
      "Conv2d               (1, 512, 8, 8)\n",
      "BatchNorm2d          (1, 512, 8, 8)\n",
      "ReLU                 (1, 512, 8, 8)\n",
      "Conv2d               (1, 512, 4, 4)\n",
      "BatchNorm2d          (1, 512, 4, 4)\n",
      "ReLU                 (1, 512, 4, 4)\n",
      "Conv2d               (1, 2048, 4, 4)\n",
      "BatchNorm2d          (1, 2048, 4, 4)\n",
      "Conv2d               (1, 2048, 4, 4)\n",
      "BatchNorm2d          (1, 2048, 4, 4)\n",
      "Conv2d               (1, 128, 1, 1)\n",
      "ReLU                 (1, 128, 1, 1)\n",
      "Conv2d               (1, 2048, 1, 1)\n",
      "Conv2d               (1, 128, 1, 1)\n",
      "ReLU                 (1, 128, 1, 1)\n",
      "Conv2d               (1, 2048, 1, 1)\n",
      "Conv2d               (1, 1, 4, 4)\n",
      "BatchNorm2d          (1, 1, 4, 4)\n",
      "ReLU                 (1, 2048, 4, 4)\n",
      "BottleneckCBAM       (1, 2048, 4, 4)\n",
      "Conv2d               (1, 512, 4, 4)\n",
      "BatchNorm2d          (1, 512, 4, 4)\n",
      "ReLU                 (1, 512, 4, 4)\n",
      "Conv2d               (1, 512, 4, 4)\n",
      "BatchNorm2d          (1, 512, 4, 4)\n",
      "ReLU                 (1, 512, 4, 4)\n",
      "Conv2d               (1, 2048, 4, 4)\n",
      "BatchNorm2d          (1, 2048, 4, 4)\n",
      "Conv2d               (1, 128, 1, 1)\n",
      "ReLU                 (1, 128, 1, 1)\n",
      "Conv2d               (1, 2048, 1, 1)\n",
      "Conv2d               (1, 128, 1, 1)\n",
      "ReLU                 (1, 128, 1, 1)\n",
      "Conv2d               (1, 2048, 1, 1)\n",
      "Conv2d               (1, 1, 4, 4)\n",
      "BatchNorm2d          (1, 1, 4, 4)\n",
      "ReLU                 (1, 2048, 4, 4)\n",
      "BottleneckCBAM       (1, 2048, 4, 4)\n",
      "Conv2d               (1, 512, 4, 4)\n",
      "BatchNorm2d          (1, 512, 4, 4)\n",
      "ReLU                 (1, 512, 4, 4)\n",
      "Conv2d               (1, 512, 4, 4)\n",
      "BatchNorm2d          (1, 512, 4, 4)\n",
      "ReLU                 (1, 512, 4, 4)\n",
      "Conv2d               (1, 2048, 4, 4)\n",
      "BatchNorm2d          (1, 2048, 4, 4)\n",
      "Conv2d               (1, 128, 1, 1)\n",
      "ReLU                 (1, 128, 1, 1)\n",
      "Conv2d               (1, 2048, 1, 1)\n",
      "Conv2d               (1, 128, 1, 1)\n",
      "ReLU                 (1, 128, 1, 1)\n",
      "Conv2d               (1, 2048, 1, 1)\n",
      "Conv2d               (1, 1, 4, 4)\n",
      "BatchNorm2d          (1, 1, 4, 4)\n",
      "ReLU                 (1, 2048, 4, 4)\n",
      "BottleneckCBAM       (1, 2048, 4, 4)\n",
      "AdaptiveAvgPool2d    (1, 2048, 1, 1)\n",
      "Linear               (1, 10)\n",
      "000: conv1                                    | Conv2d               | out (1, 64, 32, 32)\n",
      "001: layer1.0.conv1                           | Conv2d               | out (1, 64, 32, 32)\n",
      "002: layer1.0.conv2                           | Conv2d               | out (1, 64, 32, 32)\n",
      "003: layer1.0.conv3                           | Conv2d               | out (1, 256, 32, 32)\n",
      "004: layer1.0.downsample.0                    | Conv2d               | out (1, 256, 32, 32)\n",
      "005: layer1.0.cbam.ca.mlp.0                   | Conv2d               | out (1, 16, 1, 1)\n",
      "006: layer1.0.cbam.ca.mlp.2                   | Conv2d               | out (1, 256, 1, 1)\n",
      "007: layer1.0.cbam.ca.mlp.0                   | Conv2d               | out (1, 16, 1, 1)\n",
      "008: layer1.0.cbam.ca.mlp.2                   | Conv2d               | out (1, 256, 1, 1)\n",
      "009: layer1.0.cbam.ca                         | ChannelAttention     | out (1, 256, 32, 32)\n",
      "010: layer1.0.cbam.sa.conv                    | Conv2d               | out (1, 1, 32, 32)\n",
      "011: layer1.0.cbam.sa                         | SpatialAttention     | out (1, 256, 32, 32)\n",
      "012: layer1.0.cbam                            | CBAM                 | out (1, 256, 32, 32)\n",
      "013: layer1.0                                 | BottleneckCBAM       | out (1, 256, 32, 32)\n",
      "014: layer1.1.conv1                           | Conv2d               | out (1, 64, 32, 32)\n",
      "015: layer1.1.conv2                           | Conv2d               | out (1, 64, 32, 32)\n",
      "016: layer1.1.conv3                           | Conv2d               | out (1, 256, 32, 32)\n",
      "017: layer1.1.cbam.ca.mlp.0                   | Conv2d               | out (1, 16, 1, 1)\n",
      "018: layer1.1.cbam.ca.mlp.2                   | Conv2d               | out (1, 256, 1, 1)\n",
      "019: layer1.1.cbam.ca.mlp.0                   | Conv2d               | out (1, 16, 1, 1)\n",
      "020: layer1.1.cbam.ca.mlp.2                   | Conv2d               | out (1, 256, 1, 1)\n",
      "021: layer1.1.cbam.ca                         | ChannelAttention     | out (1, 256, 32, 32)\n",
      "022: layer1.1.cbam.sa.conv                    | Conv2d               | out (1, 1, 32, 32)\n",
      "023: layer1.1.cbam.sa                         | SpatialAttention     | out (1, 256, 32, 32)\n",
      "024: layer1.1.cbam                            | CBAM                 | out (1, 256, 32, 32)\n",
      "025: layer1.1                                 | BottleneckCBAM       | out (1, 256, 32, 32)\n",
      "026: layer1.2.conv1                           | Conv2d               | out (1, 64, 32, 32)\n",
      "027: layer1.2.conv2                           | Conv2d               | out (1, 64, 32, 32)\n",
      "028: layer1.2.conv3                           | Conv2d               | out (1, 256, 32, 32)\n",
      "029: layer1.2.cbam.ca.mlp.0                   | Conv2d               | out (1, 16, 1, 1)\n",
      "030: layer1.2.cbam.ca.mlp.2                   | Conv2d               | out (1, 256, 1, 1)\n",
      "031: layer1.2.cbam.ca.mlp.0                   | Conv2d               | out (1, 16, 1, 1)\n",
      "032: layer1.2.cbam.ca.mlp.2                   | Conv2d               | out (1, 256, 1, 1)\n",
      "033: layer1.2.cbam.ca                         | ChannelAttention     | out (1, 256, 32, 32)\n",
      "034: layer1.2.cbam.sa.conv                    | Conv2d               | out (1, 1, 32, 32)\n",
      "035: layer1.2.cbam.sa                         | SpatialAttention     | out (1, 256, 32, 32)\n",
      "036: layer1.2.cbam                            | CBAM                 | out (1, 256, 32, 32)\n",
      "037: layer1.2                                 | BottleneckCBAM       | out (1, 256, 32, 32)\n",
      "038: layer2.0.conv1                           | Conv2d               | out (1, 128, 32, 32)\n",
      "039: layer2.0.conv2                           | Conv2d               | out (1, 128, 16, 16)\n",
      "040: layer2.0.conv3                           | Conv2d               | out (1, 512, 16, 16)\n",
      "041: layer2.0.downsample.0                    | Conv2d               | out (1, 512, 16, 16)\n",
      "042: layer2.0.cbam.ca.mlp.0                   | Conv2d               | out (1, 32, 1, 1)\n",
      "043: layer2.0.cbam.ca.mlp.2                   | Conv2d               | out (1, 512, 1, 1)\n",
      "044: layer2.0.cbam.ca.mlp.0                   | Conv2d               | out (1, 32, 1, 1)\n",
      "045: layer2.0.cbam.ca.mlp.2                   | Conv2d               | out (1, 512, 1, 1)\n",
      "046: layer2.0.cbam.ca                         | ChannelAttention     | out (1, 512, 16, 16)\n",
      "047: layer2.0.cbam.sa.conv                    | Conv2d               | out (1, 1, 16, 16)\n",
      "048: layer2.0.cbam.sa                         | SpatialAttention     | out (1, 512, 16, 16)\n",
      "049: layer2.0.cbam                            | CBAM                 | out (1, 512, 16, 16)\n",
      "050: layer2.0                                 | BottleneckCBAM       | out (1, 512, 16, 16)\n",
      "051: layer2.1.conv1                           | Conv2d               | out (1, 128, 16, 16)\n",
      "052: layer2.1.conv2                           | Conv2d               | out (1, 128, 16, 16)\n",
      "053: layer2.1.conv3                           | Conv2d               | out (1, 512, 16, 16)\n",
      "054: layer2.1.cbam.ca.mlp.0                   | Conv2d               | out (1, 32, 1, 1)\n",
      "055: layer2.1.cbam.ca.mlp.2                   | Conv2d               | out (1, 512, 1, 1)\n",
      "056: layer2.1.cbam.ca.mlp.0                   | Conv2d               | out (1, 32, 1, 1)\n",
      "057: layer2.1.cbam.ca.mlp.2                   | Conv2d               | out (1, 512, 1, 1)\n",
      "058: layer2.1.cbam.ca                         | ChannelAttention     | out (1, 512, 16, 16)\n",
      "059: layer2.1.cbam.sa.conv                    | Conv2d               | out (1, 1, 16, 16)\n",
      "060: layer2.1.cbam.sa                         | SpatialAttention     | out (1, 512, 16, 16)\n",
      "061: layer2.1.cbam                            | CBAM                 | out (1, 512, 16, 16)\n",
      "062: layer2.1                                 | BottleneckCBAM       | out (1, 512, 16, 16)\n",
      "063: layer2.2.conv1                           | Conv2d               | out (1, 128, 16, 16)\n",
      "064: layer2.2.conv2                           | Conv2d               | out (1, 128, 16, 16)\n",
      "065: layer2.2.conv3                           | Conv2d               | out (1, 512, 16, 16)\n",
      "066: layer2.2.cbam.ca.mlp.0                   | Conv2d               | out (1, 32, 1, 1)\n",
      "067: layer2.2.cbam.ca.mlp.2                   | Conv2d               | out (1, 512, 1, 1)\n",
      "068: layer2.2.cbam.ca.mlp.0                   | Conv2d               | out (1, 32, 1, 1)\n",
      "069: layer2.2.cbam.ca.mlp.2                   | Conv2d               | out (1, 512, 1, 1)\n",
      "070: layer2.2.cbam.ca                         | ChannelAttention     | out (1, 512, 16, 16)\n",
      "071: layer2.2.cbam.sa.conv                    | Conv2d               | out (1, 1, 16, 16)\n",
      "072: layer2.2.cbam.sa                         | SpatialAttention     | out (1, 512, 16, 16)\n",
      "073: layer2.2.cbam                            | CBAM                 | out (1, 512, 16, 16)\n",
      "074: layer2.2                                 | BottleneckCBAM       | out (1, 512, 16, 16)\n",
      "075: layer2.3.conv1                           | Conv2d               | out (1, 128, 16, 16)\n",
      "076: layer2.3.conv2                           | Conv2d               | out (1, 128, 16, 16)\n",
      "077: layer2.3.conv3                           | Conv2d               | out (1, 512, 16, 16)\n",
      "078: layer2.3.cbam.ca.mlp.0                   | Conv2d               | out (1, 32, 1, 1)\n",
      "079: layer2.3.cbam.ca.mlp.2                   | Conv2d               | out (1, 512, 1, 1)\n",
      "080: layer2.3.cbam.ca.mlp.0                   | Conv2d               | out (1, 32, 1, 1)\n",
      "081: layer2.3.cbam.ca.mlp.2                   | Conv2d               | out (1, 512, 1, 1)\n",
      "082: layer2.3.cbam.ca                         | ChannelAttention     | out (1, 512, 16, 16)\n",
      "083: layer2.3.cbam.sa.conv                    | Conv2d               | out (1, 1, 16, 16)\n",
      "084: layer2.3.cbam.sa                         | SpatialAttention     | out (1, 512, 16, 16)\n",
      "085: layer2.3.cbam                            | CBAM                 | out (1, 512, 16, 16)\n",
      "086: layer2.3                                 | BottleneckCBAM       | out (1, 512, 16, 16)\n",
      "087: layer3.0.conv1                           | Conv2d               | out (1, 256, 16, 16)\n",
      "088: layer3.0.conv2                           | Conv2d               | out (1, 256, 8, 8)\n",
      "089: layer3.0.conv3                           | Conv2d               | out (1, 1024, 8, 8)\n",
      "090: layer3.0.downsample.0                    | Conv2d               | out (1, 1024, 8, 8)\n",
      "091: layer3.0.cbam.ca.mlp.0                   | Conv2d               | out (1, 64, 1, 1)\n",
      "092: layer3.0.cbam.ca.mlp.2                   | Conv2d               | out (1, 1024, 1, 1)\n",
      "093: layer3.0.cbam.ca.mlp.0                   | Conv2d               | out (1, 64, 1, 1)\n",
      "094: layer3.0.cbam.ca.mlp.2                   | Conv2d               | out (1, 1024, 1, 1)\n",
      "095: layer3.0.cbam.ca                         | ChannelAttention     | out (1, 1024, 8, 8)\n",
      "096: layer3.0.cbam.sa.conv                    | Conv2d               | out (1, 1, 8, 8)\n",
      "097: layer3.0.cbam.sa                         | SpatialAttention     | out (1, 1024, 8, 8)\n",
      "098: layer3.0.cbam                            | CBAM                 | out (1, 1024, 8, 8)\n",
      "099: layer3.0                                 | BottleneckCBAM       | out (1, 1024, 8, 8)\n",
      "100: layer3.1.conv1                           | Conv2d               | out (1, 256, 8, 8)\n",
      "101: layer3.1.conv2                           | Conv2d               | out (1, 256, 8, 8)\n",
      "102: layer3.1.conv3                           | Conv2d               | out (1, 1024, 8, 8)\n",
      "103: layer3.1.cbam.ca.mlp.0                   | Conv2d               | out (1, 64, 1, 1)\n",
      "104: layer3.1.cbam.ca.mlp.2                   | Conv2d               | out (1, 1024, 1, 1)\n",
      "105: layer3.1.cbam.ca.mlp.0                   | Conv2d               | out (1, 64, 1, 1)\n",
      "106: layer3.1.cbam.ca.mlp.2                   | Conv2d               | out (1, 1024, 1, 1)\n",
      "107: layer3.1.cbam.ca                         | ChannelAttention     | out (1, 1024, 8, 8)\n",
      "108: layer3.1.cbam.sa.conv                    | Conv2d               | out (1, 1, 8, 8)\n",
      "109: layer3.1.cbam.sa                         | SpatialAttention     | out (1, 1024, 8, 8)\n",
      "110: layer3.1.cbam                            | CBAM                 | out (1, 1024, 8, 8)\n",
      "111: layer3.1                                 | BottleneckCBAM       | out (1, 1024, 8, 8)\n",
      "112: layer3.2.conv1                           | Conv2d               | out (1, 256, 8, 8)\n",
      "113: layer3.2.conv2                           | Conv2d               | out (1, 256, 8, 8)\n",
      "114: layer3.2.conv3                           | Conv2d               | out (1, 1024, 8, 8)\n",
      "115: layer3.2.cbam.ca.mlp.0                   | Conv2d               | out (1, 64, 1, 1)\n",
      "116: layer3.2.cbam.ca.mlp.2                   | Conv2d               | out (1, 1024, 1, 1)\n",
      "117: layer3.2.cbam.ca.mlp.0                   | Conv2d               | out (1, 64, 1, 1)\n",
      "118: layer3.2.cbam.ca.mlp.2                   | Conv2d               | out (1, 1024, 1, 1)\n",
      "119: layer3.2.cbam.ca                         | ChannelAttention     | out (1, 1024, 8, 8)\n",
      "120: layer3.2.cbam.sa.conv                    | Conv2d               | out (1, 1, 8, 8)\n",
      "121: layer3.2.cbam.sa                         | SpatialAttention     | out (1, 1024, 8, 8)\n",
      "122: layer3.2.cbam                            | CBAM                 | out (1, 1024, 8, 8)\n",
      "123: layer3.2                                 | BottleneckCBAM       | out (1, 1024, 8, 8)\n",
      "124: layer3.3.conv1                           | Conv2d               | out (1, 256, 8, 8)\n",
      "125: layer3.3.conv2                           | Conv2d               | out (1, 256, 8, 8)\n",
      "126: layer3.3.conv3                           | Conv2d               | out (1, 1024, 8, 8)\n",
      "127: layer3.3.cbam.ca.mlp.0                   | Conv2d               | out (1, 64, 1, 1)\n",
      "128: layer3.3.cbam.ca.mlp.2                   | Conv2d               | out (1, 1024, 1, 1)\n",
      "129: layer3.3.cbam.ca.mlp.0                   | Conv2d               | out (1, 64, 1, 1)\n",
      "130: layer3.3.cbam.ca.mlp.2                   | Conv2d               | out (1, 1024, 1, 1)\n",
      "131: layer3.3.cbam.ca                         | ChannelAttention     | out (1, 1024, 8, 8)\n",
      "132: layer3.3.cbam.sa.conv                    | Conv2d               | out (1, 1, 8, 8)\n",
      "133: layer3.3.cbam.sa                         | SpatialAttention     | out (1, 1024, 8, 8)\n",
      "134: layer3.3.cbam                            | CBAM                 | out (1, 1024, 8, 8)\n",
      "135: layer3.3                                 | BottleneckCBAM       | out (1, 1024, 8, 8)\n",
      "136: layer3.4.conv1                           | Conv2d               | out (1, 256, 8, 8)\n",
      "137: layer3.4.conv2                           | Conv2d               | out (1, 256, 8, 8)\n",
      "138: layer3.4.conv3                           | Conv2d               | out (1, 1024, 8, 8)\n",
      "139: layer3.4.cbam.ca.mlp.0                   | Conv2d               | out (1, 64, 1, 1)\n",
      "140: layer3.4.cbam.ca.mlp.2                   | Conv2d               | out (1, 1024, 1, 1)\n",
      "141: layer3.4.cbam.ca.mlp.0                   | Conv2d               | out (1, 64, 1, 1)\n",
      "142: layer3.4.cbam.ca.mlp.2                   | Conv2d               | out (1, 1024, 1, 1)\n",
      "143: layer3.4.cbam.ca                         | ChannelAttention     | out (1, 1024, 8, 8)\n",
      "144: layer3.4.cbam.sa.conv                    | Conv2d               | out (1, 1, 8, 8)\n",
      "145: layer3.4.cbam.sa                         | SpatialAttention     | out (1, 1024, 8, 8)\n",
      "146: layer3.4.cbam                            | CBAM                 | out (1, 1024, 8, 8)\n",
      "147: layer3.4                                 | BottleneckCBAM       | out (1, 1024, 8, 8)\n",
      "148: layer3.5.conv1                           | Conv2d               | out (1, 256, 8, 8)\n",
      "149: layer3.5.conv2                           | Conv2d               | out (1, 256, 8, 8)\n",
      "150: layer3.5.conv3                           | Conv2d               | out (1, 1024, 8, 8)\n",
      "151: layer3.5.cbam.ca.mlp.0                   | Conv2d               | out (1, 64, 1, 1)\n",
      "152: layer3.5.cbam.ca.mlp.2                   | Conv2d               | out (1, 1024, 1, 1)\n",
      "153: layer3.5.cbam.ca.mlp.0                   | Conv2d               | out (1, 64, 1, 1)\n",
      "154: layer3.5.cbam.ca.mlp.2                   | Conv2d               | out (1, 1024, 1, 1)\n",
      "155: layer3.5.cbam.ca                         | ChannelAttention     | out (1, 1024, 8, 8)\n",
      "156: layer3.5.cbam.sa.conv                    | Conv2d               | out (1, 1, 8, 8)\n",
      "157: layer3.5.cbam.sa                         | SpatialAttention     | out (1, 1024, 8, 8)\n",
      "158: layer3.5.cbam                            | CBAM                 | out (1, 1024, 8, 8)\n",
      "159: layer3.5                                 | BottleneckCBAM       | out (1, 1024, 8, 8)\n",
      "160: layer4.0.conv1                           | Conv2d               | out (1, 512, 8, 8)\n",
      "161: layer4.0.conv2                           | Conv2d               | out (1, 512, 4, 4)\n",
      "162: layer4.0.conv3                           | Conv2d               | out (1, 2048, 4, 4)\n",
      "163: layer4.0.downsample.0                    | Conv2d               | out (1, 2048, 4, 4)\n",
      "164: layer4.0.cbam.ca.mlp.0                   | Conv2d               | out (1, 128, 1, 1)\n",
      "165: layer4.0.cbam.ca.mlp.2                   | Conv2d               | out (1, 2048, 1, 1)\n",
      "166: layer4.0.cbam.ca.mlp.0                   | Conv2d               | out (1, 128, 1, 1)\n",
      "167: layer4.0.cbam.ca.mlp.2                   | Conv2d               | out (1, 2048, 1, 1)\n",
      "168: layer4.0.cbam.ca                         | ChannelAttention     | out (1, 2048, 4, 4)\n",
      "169: layer4.0.cbam.sa.conv                    | Conv2d               | out (1, 1, 4, 4)\n",
      "170: layer4.0.cbam.sa                         | SpatialAttention     | out (1, 2048, 4, 4)\n",
      "171: layer4.0.cbam                            | CBAM                 | out (1, 2048, 4, 4)\n",
      "172: layer4.0                                 | BottleneckCBAM       | out (1, 2048, 4, 4)\n",
      "173: layer4.1.conv1                           | Conv2d               | out (1, 512, 4, 4)\n",
      "174: layer4.1.conv2                           | Conv2d               | out (1, 512, 4, 4)\n",
      "175: layer4.1.conv3                           | Conv2d               | out (1, 2048, 4, 4)\n",
      "176: layer4.1.cbam.ca.mlp.0                   | Conv2d               | out (1, 128, 1, 1)\n",
      "177: layer4.1.cbam.ca.mlp.2                   | Conv2d               | out (1, 2048, 1, 1)\n",
      "178: layer4.1.cbam.ca.mlp.0                   | Conv2d               | out (1, 128, 1, 1)\n",
      "179: layer4.1.cbam.ca.mlp.2                   | Conv2d               | out (1, 2048, 1, 1)\n",
      "180: layer4.1.cbam.ca                         | ChannelAttention     | out (1, 2048, 4, 4)\n",
      "181: layer4.1.cbam.sa.conv                    | Conv2d               | out (1, 1, 4, 4)\n",
      "182: layer4.1.cbam.sa                         | SpatialAttention     | out (1, 2048, 4, 4)\n",
      "183: layer4.1.cbam                            | CBAM                 | out (1, 2048, 4, 4)\n",
      "184: layer4.1                                 | BottleneckCBAM       | out (1, 2048, 4, 4)\n",
      "185: layer4.2.conv1                           | Conv2d               | out (1, 512, 4, 4)\n",
      "186: layer4.2.conv2                           | Conv2d               | out (1, 512, 4, 4)\n",
      "187: layer4.2.conv3                           | Conv2d               | out (1, 2048, 4, 4)\n",
      "188: layer4.2.cbam.ca.mlp.0                   | Conv2d               | out (1, 128, 1, 1)\n",
      "189: layer4.2.cbam.ca.mlp.2                   | Conv2d               | out (1, 2048, 1, 1)\n",
      "190: layer4.2.cbam.ca.mlp.0                   | Conv2d               | out (1, 128, 1, 1)\n",
      "191: layer4.2.cbam.ca.mlp.2                   | Conv2d               | out (1, 2048, 1, 1)\n",
      "192: layer4.2.cbam.ca                         | ChannelAttention     | out (1, 2048, 4, 4)\n",
      "193: layer4.2.cbam.sa.conv                    | Conv2d               | out (1, 1, 4, 4)\n",
      "194: layer4.2.cbam.sa                         | SpatialAttention     | out (1, 2048, 4, 4)\n",
      "195: layer4.2.cbam                            | CBAM                 | out (1, 2048, 4, 4)\n",
      "196: layer4.2                                 | BottleneckCBAM       | out (1, 2048, 4, 4)\n",
      "197: avgpool                                  | AdaptiveAvgPool2d    | out (1, 2048, 1, 1)\n",
      "198: fc                                       | Linear               | out (1, 10)\n"
     ]
    }
   ],
   "source": [
    "# Execution trace (filtered to include attention blocks)\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x = torch.randn(1, 3, 32, 32, device=device)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "call_list = []\n",
    "\n",
    "def trace_hook(module, inp, out, name):\n",
    "    # Try to get shape; handle lists/tuples\n",
    "    try:\n",
    "        out_shape = tuple(out.shape) if hasattr(out, \"shape\") else str(type(out))\n",
    "    except Exception:\n",
    "        out_shape = str(type(out))\n",
    "    call_list.append((name, module.__class__.__name__, out_shape))\n",
    "\n",
    "# We'll register hooks only for module classes we care about\n",
    "interesting_classes = (\n",
    "    getattr(model, \"fc\").__class__,  # Linear\n",
    "    torch.nn.Conv2d,\n",
    "    torch.nn.AdaptiveAvgPool2d,\n",
    "    # include batchnorm if desired\n",
    "    # torch.nn.BatchNorm2d,\n",
    ")\n",
    "\n",
    "# Add CBAM-related class types by name (in case classes are local)\n",
    "# We'll detect by names for CBAM, ChannelAttention, SpatialAttention, BottleneckCBAM\n",
    "hooks = []\n",
    "for name, module in model.named_modules():\n",
    "    if name == \"\":\n",
    "        continue\n",
    "    cls = module.__class__\n",
    "    cls_name = cls.__name__\n",
    "    # choose modules to hook: conv, pool, linear, bottleneck, CBAM and attention submodules\n",
    "    if isinstance(module, interesting_classes) or cls_name in (\"BottleneckCBAM\", \"CBAM\", \"ChannelAttention\", \"SpatialAttention\"):\n",
    "        hooks.append(module.register_forward_hook(lambda m, inp, out, nm=name: trace_hook(m, inp, out, nm)))\n",
    "\n",
    "# run forward\n",
    "with torch.no_grad():\n",
    "    _ = model(x)\n",
    "\n",
    "# remove hooks\n",
    "for h in hooks:\n",
    "    h.remove()\n",
    "\n",
    "# print chronological trace\n",
    "for i, (name, cls, shape) in enumerate(call_list):\n",
    "    print(f\"{i:03d}: {name:40.40} | {cls:20.20} | out {shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb519acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = inp.to(device)  # ensure input is on the same device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92cb904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cb5a5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck class: BottleneckCBAM\n",
      "Has attribute use_cbam: True\n",
      "Has cbam module: True\n",
      "Conv2d               (1, 128, 16, 16)\n",
      "BatchNorm2d          (1, 128, 16, 16)\n",
      "ReLU                 (1, 128, 16, 16)\n",
      "Conv2d               (1, 128, 16, 16)\n",
      "BatchNorm2d          (1, 128, 16, 16)\n",
      "ReLU                 (1, 128, 16, 16)\n",
      "Conv2d               (1, 512, 16, 16)\n",
      "BatchNorm2d          (1, 512, 16, 16)\n",
      "Conv2d               (1, 32, 1, 1)\n",
      "ReLU                 (1, 32, 1, 1)\n",
      "Conv2d               (1, 512, 1, 1)\n",
      "Conv2d               (1, 32, 1, 1)\n",
      "ReLU                 (1, 32, 1, 1)\n",
      "Conv2d               (1, 512, 1, 1)\n",
      "Conv2d               (1, 1, 16, 16)\n",
      "BatchNorm2d          (1, 1, 16, 16)\n",
      "ReLU                 (1, 512, 16, 16)\n",
      "BottleneckCBAM       (1, 512, 16, 16)\n",
      "block output shape: torch.Size([1, 512, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "b = dict(model.named_modules())['layer2.1']  # BottleneckCBAM\n",
    "print(\"Bottleneck class:\", b.__class__.__name__)\n",
    "print(\"Has attribute use_cbam:\", getattr(b, \"use_cbam\", False))\n",
    "print(\"Has cbam module:\", hasattr(b, \"cbam\"))\n",
    "# run forward on a single sample and inspect shapes\n",
    "with torch.no_grad():\n",
    "    inp = torch.randn(1, 512, 16, 16)  # adapt shape to that block's expected input\n",
    "    out = b.to(\"cpu\")(inp.to(\"cpu\"))   # will run convs, residual add, cbam, relu\n",
    "    print(\"block output shape:\", out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae41b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8040ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9490d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"2291pt\" height=\"118pt\"\n",
       " viewBox=\"0.00 0.00 2291.00 117.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 113.5)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-113.5 2287,-113.5 2287,4 -4,4\"/>\n",
       "<!-- x -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M105,-76.5C105,-76.5 12,-76.5 12,-76.5 6,-76.5 0,-70.5 0,-64.5 0,-64.5 0,-50.5 0,-50.5 0,-44.5 6,-38.5 12,-38.5 12,-38.5 105,-38.5 105,-38.5 111,-38.5 117,-44.5 117,-50.5 117,-50.5 117,-64.5 117,-64.5 117,-70.5 111,-76.5 105,-76.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-61.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Input x</text>\n",
       "<text text-anchor=\"middle\" x=\"58.5\" y=\"-46.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(B, C_in, H, W)</text>\n",
       "</g>\n",
       "<!-- c1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>c1</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M324,-104.5C324,-104.5 165,-104.5 165,-104.5 159,-104.5 153,-98.5 153,-92.5 153,-92.5 153,-78.5 153,-78.5 153,-72.5 159,-66.5 165,-66.5 165,-66.5 324,-66.5 324,-66.5 330,-66.5 336,-72.5 336,-78.5 336,-78.5 336,-92.5 336,-92.5 336,-98.5 330,-104.5 324,-104.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"244.5\" y=\"-89.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">conv1</text>\n",
       "<text text-anchor=\"middle\" x=\"244.5\" y=\"-74.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">1x1 &#45;&gt; (B, C_mid, H, W)</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;c1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x&#45;&gt;c1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M117.21,-66.28C125.48,-67.54 134.19,-68.87 142.99,-70.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"142.55,-73.68 152.96,-71.72 143.6,-66.76 142.55,-73.68\"/>\n",
       "</g>\n",
       "<!-- id -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>id</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M535,-53C535,-53 392,-53 392,-53 386,-53 380,-47 380,-41 380,-41 380,-12 380,-12 380,-6 386,0 392,0 392,0 535,0 535,0 541,0 547,-6 547,-12 547,-12 547,-41 547,-41 547,-47 541,-53 535,-53\"/>\n",
       "<text text-anchor=\"middle\" x=\"463.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">identity</text>\n",
       "<text text-anchor=\"middle\" x=\"463.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(maybe downsample)</text>\n",
       "<text text-anchor=\"middle\" x=\"463.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(B, C_out, H, W)</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;id -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>x&#45;&gt;id</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M117.24,-53.06C183.06,-48 291.58,-39.65 369.4,-33.66\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"369.98,-37.13 379.69,-32.87 369.45,-30.15 369.98,-37.13\"/>\n",
       "</g>\n",
       "<!-- c2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>c2</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M543,-109.5C543,-109.5 384,-109.5 384,-109.5 378,-109.5 372,-103.5 372,-97.5 372,-97.5 372,-83.5 372,-83.5 372,-77.5 378,-71.5 384,-71.5 384,-71.5 543,-71.5 543,-71.5 549,-71.5 555,-77.5 555,-83.5 555,-83.5 555,-97.5 555,-97.5 555,-103.5 549,-109.5 543,-109.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"463.5\" y=\"-94.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">conv2</text>\n",
       "<text text-anchor=\"middle\" x=\"463.5\" y=\"-79.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3x3 &#45;&gt; (B, C_mid, H, W)</text>\n",
       "</g>\n",
       "<!-- c1&#45;&gt;c2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>c1&#45;&gt;c2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M336.27,-87.59C344.61,-87.78 353.09,-87.98 361.51,-88.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"361.67,-91.68 371.74,-88.41 361.83,-84.68 361.67,-91.68\"/>\n",
       "</g>\n",
       "<!-- c3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>c3</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M758,-104.5C758,-104.5 603,-104.5 603,-104.5 597,-104.5 591,-98.5 591,-92.5 591,-92.5 591,-78.5 591,-78.5 591,-72.5 597,-66.5 603,-66.5 603,-66.5 758,-66.5 758,-66.5 764,-66.5 770,-72.5 770,-78.5 770,-78.5 770,-92.5 770,-92.5 770,-98.5 764,-104.5 758,-104.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"680.5\" y=\"-89.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">conv3</text>\n",
       "<text text-anchor=\"middle\" x=\"680.5\" y=\"-74.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">1x1 &#45;&gt; (B, C_out, H, W)</text>\n",
       "</g>\n",
       "<!-- c2&#45;&gt;c3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>c2&#45;&gt;c3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M555.06,-88.39C563.55,-88.2 572.19,-88 580.76,-87.8\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"580.85,-91.3 590.77,-87.56 580.69,-84.3 580.85,-91.3\"/>\n",
       "</g>\n",
       "<!-- bn3 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>bn3</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M848,-98.5C848,-98.5 818,-98.5 818,-98.5 812,-98.5 806,-92.5 806,-86.5 806,-86.5 806,-74.5 806,-74.5 806,-68.5 812,-62.5 818,-62.5 818,-62.5 848,-62.5 848,-62.5 854,-62.5 860,-68.5 860,-74.5 860,-74.5 860,-86.5 860,-86.5 860,-92.5 854,-98.5 848,-98.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"833\" y=\"-76.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">bn3</text>\n",
       "</g>\n",
       "<!-- c3&#45;&gt;bn3 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>c3&#45;&gt;bn3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M770.35,-82.55C779.19,-82.25 787.77,-81.97 795.58,-81.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"795.83,-85.2 805.71,-81.37 795.59,-78.21 795.83,-85.2\"/>\n",
       "</g>\n",
       "<!-- add -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>add</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M1011,-84C1011,-84 908,-84 908,-84 902,-84 896,-78 896,-72 896,-72 896,-43 896,-43 896,-37 902,-31 908,-31 908,-31 1011,-31 1011,-31 1017,-31 1023,-37 1023,-43 1023,-43 1023,-72 1023,-72 1023,-78 1017,-84 1011,-84\"/>\n",
       "<text text-anchor=\"middle\" x=\"959.5\" y=\"-68.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Residual add</text>\n",
       "<text text-anchor=\"middle\" x=\"959.5\" y=\"-53.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(out + identity)</text>\n",
       "<text text-anchor=\"middle\" x=\"959.5\" y=\"-38.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(B, C_out, H, W)</text>\n",
       "</g>\n",
       "<!-- bn3&#45;&gt;add -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>bn3&#45;&gt;add</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M860.1,-75.68C867.8,-74.26 876.62,-72.63 885.76,-70.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"886.56,-74.35 895.76,-69.09 885.29,-67.47 886.56,-74.35\"/>\n",
       "</g>\n",
       "<!-- ca -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>ca</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M1254,-84C1254,-84 1071,-84 1071,-84 1065,-84 1059,-78 1059,-72 1059,-72 1059,-43 1059,-43 1059,-37 1065,-31 1071,-31 1071,-31 1254,-31 1254,-31 1260,-31 1266,-37 1266,-43 1266,-43 1266,-72 1266,-72 1266,-78 1260,-84 1254,-84\"/>\n",
       "<text text-anchor=\"middle\" x=\"1162.5\" y=\"-68.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">ChannelAttention</text>\n",
       "<text text-anchor=\"middle\" x=\"1162.5\" y=\"-53.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mlp on pooled avg/max</text>\n",
       "<text text-anchor=\"middle\" x=\"1162.5\" y=\"-38.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">&#45;&gt; ca_mask (B, C_out, 1, 1)</text>\n",
       "</g>\n",
       "<!-- add&#45;&gt;ca -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>add&#45;&gt;ca</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1023.27,-57.5C1031.38,-57.5 1039.88,-57.5 1048.5,-57.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1048.67,-61 1058.67,-57.5 1048.67,-54 1048.67,-61\"/>\n",
       "</g>\n",
       "<!-- mul_ca -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>mul_ca</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M1454,-76.5C1454,-76.5 1314,-76.5 1314,-76.5 1308,-76.5 1302,-70.5 1302,-64.5 1302,-64.5 1302,-50.5 1302,-50.5 1302,-44.5 1308,-38.5 1314,-38.5 1314,-38.5 1454,-38.5 1454,-38.5 1460,-38.5 1466,-44.5 1466,-50.5 1466,-50.5 1466,-64.5 1466,-64.5 1466,-70.5 1460,-76.5 1454,-76.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1384\" y=\"-61.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Multiply: F * ca_mask</text>\n",
       "<text text-anchor=\"middle\" x=\"1384\" y=\"-46.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(B, C_out, H, W)</text>\n",
       "</g>\n",
       "<!-- ca&#45;&gt;mul_ca -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>ca&#45;&gt;mul_ca</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1266.18,-57.5C1274.67,-57.5 1283.21,-57.5 1291.61,-57.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1291.76,-61 1301.76,-57.5 1291.76,-54 1291.76,-61\"/>\n",
       "</g>\n",
       "<!-- sa -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>sa</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M1723,-84C1723,-84 1514,-84 1514,-84 1508,-84 1502,-78 1502,-72 1502,-72 1502,-43 1502,-43 1502,-37 1508,-31 1514,-31 1514,-31 1723,-31 1723,-31 1729,-31 1735,-37 1735,-43 1735,-43 1735,-72 1735,-72 1735,-78 1729,-84 1723,-84\"/>\n",
       "<text text-anchor=\"middle\" x=\"1618.5\" y=\"-68.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SpatialAttention</text>\n",
       "<text text-anchor=\"middle\" x=\"1618.5\" y=\"-53.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cat(max,avg)</text>\n",
       "<text text-anchor=\"middle\" x=\"1618.5\" y=\"-38.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">conv7x7 &#45;&gt; sa_mask (B,1,H,W)</text>\n",
       "</g>\n",
       "<!-- mul_ca&#45;&gt;sa -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>mul_ca&#45;&gt;sa</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1466.32,-57.5C1474.6,-57.5 1483.14,-57.5 1491.76,-57.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1491.89,-61 1501.89,-57.5 1491.89,-54 1491.89,-61\"/>\n",
       "</g>\n",
       "<!-- mul_sa -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>mul_sa</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M1945,-76.5C1945,-76.5 1783,-76.5 1783,-76.5 1777,-76.5 1771,-70.5 1771,-64.5 1771,-64.5 1771,-50.5 1771,-50.5 1771,-44.5 1777,-38.5 1783,-38.5 1783,-38.5 1945,-38.5 1945,-38.5 1951,-38.5 1957,-44.5 1957,-50.5 1957,-50.5 1957,-64.5 1957,-64.5 1957,-70.5 1951,-76.5 1945,-76.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1864\" y=\"-61.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Multiply: F_ca * sa_mask</text>\n",
       "<text text-anchor=\"middle\" x=\"1864\" y=\"-46.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(B, C_out, H, W)</text>\n",
       "</g>\n",
       "<!-- sa&#45;&gt;mul_sa -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>sa&#45;&gt;mul_sa</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1735.19,-57.5C1743.65,-57.5 1752.15,-57.5 1760.53,-57.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1760.67,-61 1770.67,-57.5 1760.67,-54 1760.67,-61\"/>\n",
       "</g>\n",
       "<!-- relu -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>relu</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M2108,-76.5C2108,-76.5 2005,-76.5 2005,-76.5 1999,-76.5 1993,-70.5 1993,-64.5 1993,-64.5 1993,-50.5 1993,-50.5 1993,-44.5 1999,-38.5 2005,-38.5 2005,-38.5 2108,-38.5 2108,-38.5 2114,-38.5 2120,-44.5 2120,-50.5 2120,-50.5 2120,-64.5 2120,-64.5 2120,-70.5 2114,-76.5 2108,-76.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"2056.5\" y=\"-61.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">ReLU</text>\n",
       "<text text-anchor=\"middle\" x=\"2056.5\" y=\"-46.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(B, C_out, H, W)</text>\n",
       "</g>\n",
       "<!-- mul_sa&#45;&gt;relu -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>mul_sa&#45;&gt;relu</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1957.18,-57.5C1965.76,-57.5 1974.36,-57.5 1982.73,-57.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1982.79,-61 1992.79,-57.5 1982.79,-54 1982.79,-61\"/>\n",
       "</g>\n",
       "<!-- out -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>out</title>\n",
       "<path fill=\"#f7f7f7\" stroke=\"black\" d=\"M2271,-76.5C2271,-76.5 2168,-76.5 2168,-76.5 2162,-76.5 2156,-70.5 2156,-64.5 2156,-64.5 2156,-50.5 2156,-50.5 2156,-44.5 2162,-38.5 2168,-38.5 2168,-38.5 2271,-38.5 2271,-38.5 2277,-38.5 2283,-44.5 2283,-50.5 2283,-50.5 2283,-64.5 2283,-64.5 2283,-70.5 2277,-76.5 2271,-76.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"2219.5\" y=\"-61.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Output</text>\n",
       "<text text-anchor=\"middle\" x=\"2219.5\" y=\"-46.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(B, C_out, H, W)</text>\n",
       "</g>\n",
       "<!-- relu&#45;&gt;out -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>relu&#45;&gt;out</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2120.21,-57.5C2128.65,-57.5 2137.36,-57.5 2145.96,-57.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2145.96,-61 2155.96,-57.5 2145.96,-54 2145.96,-61\"/>\n",
       "</g>\n",
       "<!-- id&#45;&gt;add -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>id&#45;&gt;add</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M547.18,-31.69C641.87,-37.63 795.5,-47.27 885.79,-52.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"885.74,-56.44 895.94,-53.57 886.18,-49.45 885.74,-56.44\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7d290afb4ca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved bottleneck_cbam_single.png\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "dot = Digraph(format='png')\n",
    "dot.attr(rankdir='LR', fontsize='10')\n",
    "# set default node attributes correctly:\n",
    "dot.attr('node', shape='box', style='rounded,filled', fillcolor='#f7f7f7', fontname='Helvetica')\n",
    "\n",
    "dot.node('x', 'Input x\\n(B, C_in, H, W)')\n",
    "\n",
    "# main conv path\n",
    "dot.node('c1', 'conv1\\n1x1 -> (B, C_mid, H, W)')\n",
    "dot.node('c2', 'conv2\\n3x3 -> (B, C_mid, H, W)')\n",
    "dot.node('c3', 'conv3\\n1x1 -> (B, C_out, H, W)')\n",
    "dot.node('bn3', 'bn3')\n",
    "dot.node('add', 'Residual add\\n(out + identity)\\n(B, C_out, H, W)')\n",
    "\n",
    "# CBAM nodes\n",
    "dot.node('ca', 'ChannelAttention\\nmlp on pooled avg/max\\n-> ca_mask (B, C_out, 1, 1)')\n",
    "dot.node('mul_ca', 'Multiply: F * ca_mask\\n(B, C_out, H, W)')\n",
    "dot.node('sa', 'SpatialAttention\\ncat(max,avg)\\nconv7x7 -> sa_mask (B,1,H,W)')\n",
    "dot.node('mul_sa', 'Multiply: F_ca * sa_mask\\n(B, C_out, H, W)')\n",
    "\n",
    "dot.node('relu', 'ReLU\\n(B, C_out, H, W)')\n",
    "dot.node('out', 'Output\\n(B, C_out, H, W)')\n",
    "\n",
    "# identity path\n",
    "dot.node('id', 'identity\\n(maybe downsample)\\n(B, C_out, H, W)')\n",
    "\n",
    "# connect main path\n",
    "dot.edge('x', 'c1')\n",
    "dot.edge('c1', 'c2')\n",
    "dot.edge('c2', 'c3')\n",
    "dot.edge('c3', 'bn3')\n",
    "\n",
    "# connect residual\n",
    "dot.edge('x', 'id')\n",
    "dot.edge('bn3', 'add')\n",
    "dot.edge('id', 'add')\n",
    "\n",
    "# connect CBAM and rest\n",
    "dot.edge('add', 'ca')\n",
    "dot.edge('ca', 'mul_ca')\n",
    "dot.edge('mul_ca', 'sa')\n",
    "dot.edge('sa', 'mul_sa')\n",
    "dot.edge('mul_sa', 'relu')\n",
    "dot.edge('relu', 'out')\n",
    "\n",
    "# render & display (in Jupyter this should show inline)\n",
    "display(dot)\n",
    "dot.render('bottleneck_cbam_single', cleanup=True)\n",
    "print(\"Saved bottleneck_cbam_single.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210dc51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975becde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd2e477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn_stdp_poisson (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
