{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b596012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "409c6ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ../debug/nan_grad_epoch1_step46_model.layer1.0.conv1.weight.pth\n",
      "{'current_scale': 'float',\n",
      " 'epoch': 'int',\n",
      " 'grad_sample': {'max': 0.0, 'min': 0.0, 'shape': (100,)},\n",
      " 'inputs': {'max': 0.9921568632125854, 'min': 0.0, 'shape': (64, 3, 320, 320)},\n",
      " 'model_state': 'dict',\n",
      " 'opt_state_keys': 'list',\n",
      " 'param_name': 'str',\n",
      " 'step_in_epoch': 'int',\n",
      " 'targets': {'max': 6.0, 'min': 0.0, 'shape': (64,)},\n",
      " 'where': 'str'}\n",
      "grad_sample (first elements): [-0.0, -0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "inputs shape: (64, 3, 320, 320)\n",
      "targets unique/counts: (tensor([0, 1, 2, 3, 4, 5, 6]), tensor([ 6, 13,  5, 17,  4, 18,  1]))\n"
     ]
    }
   ],
   "source": [
    "import torch, glob, os, pprint\n",
    "\n",
    "files = sorted(glob.glob(\"../debug/nan_grad_epoch*.pth\"))\n",
    "if not files:\n",
    "    print(\"No nan_grad dump found in debug/ — list debug dir:\", os.listdir(\"debug\"))\n",
    "else:\n",
    "    path = files[-1]\n",
    "    print(\"Loading:\", path)\n",
    "    d = torch.load(path)\n",
    "    # print summary\n",
    "    pprint.pprint({k: (type(v).__name__ if not isinstance(v, torch.Tensor) else {\"shape\": tuple(v.shape),\n",
    "                                                                               \"min\": float(torch.min(v)) if v.numel() else None,\n",
    "                                                                               \"max\": float(torch.max(v)) if v.numel() else None}) for k,v in d.items()})\n",
    "    # show grad sample values (if present)\n",
    "    if \"grad_sample\" in d and hasattr(d[\"grad_sample\"], \"tolist\"):\n",
    "        print(\"grad_sample (first elements):\", d[\"grad_sample\"].view(-1)[:50].tolist())\n",
    "    if \"inputs\" in d and isinstance(d[\"inputs\"], torch.Tensor):\n",
    "        print(\"inputs shape:\", tuple(d[\"inputs\"].shape))\n",
    "    if \"targets\" in d and isinstance(d[\"targets\"], torch.Tensor):\n",
    "        print(\"targets unique/counts:\", torch.unique(d[\"targets\"], return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c13ec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump path: ../debug/nan_grad_epoch1_step46_model.layer1.0.conv1.weight.pth\n",
      "where -> <class 'str'>\n",
      "  value preview: nan_grad_after_unscale\n",
      "epoch -> <class 'int'>\n",
      "  value preview: 1\n",
      "step_in_epoch -> <class 'int'>\n",
      "  value preview: 46\n",
      "param_name -> <class 'str'>\n",
      "  value preview: model.layer1.0.conv1.weight\n",
      "current_scale -> <class 'float'>\n",
      "  value preview: 65536.0\n",
      "grad_sample -> <class 'torch.Tensor'>\n",
      "  shape (100,) dtype torch.float32\n",
      "  any NaN? False any Inf? False\n",
      "  sample: tensor([-0., -0., 0., -0., 0., 0., 0., 0., 0., -0., -0., -0., -0., -0., -0., -0., -0., -0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "inputs -> <class 'torch.Tensor'>\n",
      "  shape (64, 3, 320, 320) dtype torch.float32\n",
      "  any NaN? False any Inf? False\n",
      "  sample: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "targets -> <class 'torch.Tensor'>\n",
      "  shape (64,) dtype torch.int64\n",
      "  any NaN? False any Inf? False\n",
      "  sample: tensor([0, 6, 3, 5, 1, 3, 2, 5, 3, 3, 2, 3, 2, 4, 4, 3, 1, 3, 3, 3, 3, 5, 5, 3,\n",
      "        5, 1, 5, 3, 5, 0, 4, 5, 5, 5, 0, 5, 0, 5, 2, 5, 3, 5, 3, 1, 5, 0, 1, 1,\n",
      "        5, 5])\n",
      "model_state -> <class 'dict'>\n",
      "  value preview: {'linear.weight': tensor([[-0.0302,  0.0208, -0.0642,  0.0693,  0.1149, -0.0922,  0.1105,  0.0253,\n",
      "          0.0959,  0.0190,  0.0632, -0.0165,  0.1003,  0.0225, -0.0606,  0.0309,\n",
      "         -0.0510, -0.0123, -0.0467,  0.0772, -0.1024, -0.0587, -0.0411, -0.0778,\n",
      "          0.0161, -0.1266,  0.1144, -0.1111,  0.1009,  0.0144, -0.0471,  0.0697,\n",
      "          0.0159,  0.1025,  0.0115, -0.0452,  0.0369, -0.0\n",
      "opt_state_keys -> <class 'list'>\n",
      "  value preview: ['state', 'param_groups']\n"
     ]
    }
   ],
   "source": [
    "import torch, glob, os\n",
    "path = sorted(glob.glob(\"../debug/nan_grad_epoch*.pth\"))[-1]\n",
    "d = torch.load(path)\n",
    "print(\"Dump path:\", path)\n",
    "for k,v in d.items():\n",
    "    print(k, \"->\", type(v))\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        print(\"  shape\", tuple(v.shape), \"dtype\", v.dtype)\n",
    "        print(\"  any NaN?\", torch.isnan(v).any().item(), \"any Inf?\", torch.isinf(v).any().item())\n",
    "        # show a small slice\n",
    "        print(\"  sample:\", v.view(-1)[:50])\n",
    "    else:\n",
    "        # could be list/dict/str\n",
    "        print(\"  value preview:\", str(v)[:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff22d3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f66f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b699e5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found debug files: ['../debug/crash_final.pth', '../debug/crash_nan_grad.pth', '../debug/nan_grad_epoch1_step46_model.layer1.0.conv1.weight.pth']\n",
      "\n",
      "--- ../debug/crash_final.pth\n",
      "{'exc': {'preview': 'Non-finite grad detected in model.layer1.0.conv1.weight; '\n",
      "                    'saved debug',\n",
      "         'type': 'str'},\n",
      " 'inputs': {'any_inf': False,\n",
      "            'any_nan': False,\n",
      "            'dtype': 'torch.float32',\n",
      "            'max': 0.9921568632125854,\n",
      "            'min': 0.0,\n",
      "            'sample': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
      "            'shape': (64, 3, 320, 320),\n",
      "            'type': 'tensor'},\n",
      " 'model_state': {'preview': \"OrderedDict([('linear.weight', tensor([[-0.0302,  \"\n",
      "                            '0.0208, -0.0642,  0.0693,  0.1149, -0.0922,  '\n",
      "                            '0.1105,  0.0253,\\n'\n",
      "                            '          0.0959,  0.0190,  0.0632, -0.0165,  '\n",
      "                            '0.1003,  0.0225, -0.0606,  0.0309,\\n'\n",
      "                            '         -0.0510, -0.0123, -0.0467,  0.0772, '\n",
      "                            '-0.1024, -0.0587, -0.0411, -0.0778,\\n'\n",
      "                            '          0.0161, -0.1266,  0.1144, -0.1111,  '\n",
      "                            '0.1009,  0.0144, -0.0471,  0.0697,\\n'\n",
      "                            '          0.0159,  0.1025,  0.0115, -0.0452, ',\n",
      "                 'type': 'OrderedDict'},\n",
      " 'opt_state': {'preview': \"{'state': {0: {'step': tensor(45.), 'exp_avg': \"\n",
      "                          'tensor([[ 2.8489e-03, -9.5032e-02,  4.7816e-03, '\n",
      "                          '-6.2792e-02, -4.1929e-02,\\n'\n",
      "                          '          1.5058e-02,  1.6596e-02,  6.8563e-03, '\n",
      "                          '-5.9051e-02,  2.5784e-02,\\n'\n",
      "                          '         -1.8589e-02, -7.0987e-02, -7.0596e-02,  '\n",
      "                          '2.0062e-02, -5.2376e-03,\\n'\n",
      "                          '          1.6163e-02,  4.2750e-03, -1.7527e-02, '\n",
      "                          '-3.8042e-02,  8.8262e-03,\\n'\n",
      "                          '          2.3486e-02,  2.7017e-02,  5.7100e-02,  '\n",
      "                          '4.4114e-',\n",
      "               'type': 'dict'},\n",
      " 'targets': {'any_inf': False,\n",
      "             'any_nan': False,\n",
      "             'dtype': 'torch.int64',\n",
      "             'max': 6.0,\n",
      "             'min': 0.0,\n",
      "             'sample': [0, 6, 3, 5, 1, 3, 2, 5, 3, 3],\n",
      "             'shape': (64,),\n",
      "             'type': 'tensor'},\n",
      " 'traceback': {'preview': 'Traceback (most recent call last):\\n'\n",
      "                          '  File '\n",
      "                          '\"/home/user/abin_ref_papers/project_structure_demo/dnn_template/trainer.py\", '\n",
      "                          'line 234, in fit\\n'\n",
      "                          '    raise RuntimeError(f\"Non-finite grad detected '\n",
      "                          'in {name}; saved debug\")\\n'\n",
      "                          'RuntimeError: Non-finite grad detected in '\n",
      "                          'model.layer1.0.conv1.weight; saved debug\\n',\n",
      "               'type': 'str'}}\n",
      "\n",
      "--- ../debug/crash_nan_grad.pth\n",
      "{'grad': {'any_inf': False,\n",
      "          'any_nan': True,\n",
      "          'dtype': 'torch.float32',\n",
      "          'max': nan,\n",
      "          'min': nan,\n",
      "          'sample': [-0.0, -0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0],\n",
      "          'shape': (16, 16, 3, 3),\n",
      "          'type': 'tensor'},\n",
      " 'inputs': {'any_inf': False,\n",
      "            'any_nan': False,\n",
      "            'dtype': 'torch.float32',\n",
      "            'max': 0.9921568632125854,\n",
      "            'min': 0.0,\n",
      "            'sample': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
      "            'shape': (64, 3, 320, 320),\n",
      "            'type': 'tensor'},\n",
      " 'param': {'preview': 'model.layer1.0.conv1.weight', 'type': 'str'},\n",
      " 'targets': {'any_inf': False,\n",
      "             'any_nan': False,\n",
      "             'dtype': 'torch.int64',\n",
      "             'max': 6.0,\n",
      "             'min': 0.0,\n",
      "             'sample': [0, 6, 3, 5, 1, 3, 2, 5, 3, 3],\n",
      "             'shape': (64,),\n",
      "             'type': 'tensor'}}\n",
      "\n",
      "--- ../debug/nan_grad_epoch1_step46_model.layer1.0.conv1.weight.pth\n",
      "{'current_scale': {'preview': '65536.0', 'type': 'float'},\n",
      " 'epoch': {'preview': '1', 'type': 'int'},\n",
      " 'grad_sample': {'any_inf': False,\n",
      "                 'any_nan': False,\n",
      "                 'dtype': 'torch.float32',\n",
      "                 'max': 0.0,\n",
      "                 'min': 0.0,\n",
      "                 'sample': [-0.0,\n",
      "                            -0.0,\n",
      "                            0.0,\n",
      "                            -0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            -0.0],\n",
      "                 'shape': (100,),\n",
      "                 'type': 'tensor'},\n",
      " 'inputs': {'any_inf': False,\n",
      "            'any_nan': False,\n",
      "            'dtype': 'torch.float32',\n",
      "            'max': 0.9921568632125854,\n",
      "            'min': 0.0,\n",
      "            'sample': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
      "            'shape': (64, 3, 320, 320),\n",
      "            'type': 'tensor'},\n",
      " 'model_state': {'preview': \"{'linear.weight': tensor([[-0.0302,  0.0208, \"\n",
      "                            '-0.0642,  0.0693,  0.1149, -0.0922,  0.1105,  '\n",
      "                            '0.0253,\\n'\n",
      "                            '          0.0959,  0.0190,  0.0632, -0.0165,  '\n",
      "                            '0.1003,  0.0225, -0.0606,  0.0309,\\n'\n",
      "                            '         -0.0510, -0.0123, -0.0467,  0.0772, '\n",
      "                            '-0.1024, -0.0587, -0.0411, -0.0778,\\n'\n",
      "                            '          0.0161, -0.1266,  0.1144, -0.1111,  '\n",
      "                            '0.1009,  0.0144, -0.0471,  0.0697,\\n'\n",
      "                            '          0.0159,  0.1025,  0.0115, -0.0452,  '\n",
      "                            '0.0369, -0.0',\n",
      "                 'type': 'dict'},\n",
      " 'opt_state_keys': {'preview': \"['state', 'param_groups']\", 'type': 'list'},\n",
      " 'param_name': {'preview': 'model.layer1.0.conv1.weight', 'type': 'str'},\n",
      " 'step_in_epoch': {'preview': '46', 'type': 'int'},\n",
      " 'targets': {'any_inf': False,\n",
      "             'any_nan': False,\n",
      "             'dtype': 'torch.int64',\n",
      "             'max': 6.0,\n",
      "             'min': 0.0,\n",
      "             'sample': [0, 6, 3, 5, 1, 3, 2, 5, 3, 3],\n",
      "             'shape': (64,),\n",
      "             'type': 'tensor'},\n",
      " 'where': {'preview': 'nan_grad_after_unscale', 'type': 'str'}}\n"
     ]
    }
   ],
   "source": [
    "# debug_inspect.py\n",
    "import torch, glob, pprint, os\n",
    "\n",
    "files = sorted(glob.glob(\"../debug/*.pth\"))\n",
    "print(\"Found debug files:\", files)\n",
    "for p in files:\n",
    "    print(\"\\n---\", p)\n",
    "    d = torch.load(p, map_location=\"cpu\")\n",
    "    summary = {}\n",
    "    for k,v in d.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            summary[k] = {\n",
    "                \"type\": \"tensor\",\n",
    "                \"shape\": tuple(v.shape),\n",
    "                \"dtype\": str(v.dtype),\n",
    "                \"any_nan\": bool(torch.isnan(v).any().item()),\n",
    "                \"any_inf\": bool(torch.isinf(v).any().item()),\n",
    "                \"min\": float(torch.min(v)) if v.numel() else None,\n",
    "                \"max\": float(torch.max(v)) if v.numel() else None,\n",
    "                \"sample\": v.view(-1)[:10].tolist() if v.numel() else []\n",
    "            }\n",
    "        else:\n",
    "            # show a compact preview for non-tensors\n",
    "            try:\n",
    "                summary[k] = {\"type\": type(v).__name__, \"preview\": str(v)[:400]}\n",
    "            except Exception:\n",
    "                summary[k] = {\"type\": type(v).__name__, \"preview\": \"<unprintable>\"}\n",
    "    pprint.pprint(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69679d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b59ff4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using debug file: ../debug/nan_grad_epoch1_step46_model.layer1.0.conv1.weight.pth\n",
      "Failed loading model_state from debug file preview: Error(s) in loading state_dict for ResLTResNet32:\n",
      "\tMissing key(s) in state_dict: \"model.layer1.2.bn2.bias\", \"model.layer1.2.bn2.running_mean\", \"model.layer1.2.bn2.running_var\", \"model.layer1.3.conv1.weight\", \"model.layer1.3.bn1.weight\", \"model.layer1.3.bn1.bias\", \"model.layer1.3.bn1.running_mean\", \"model.layer1.3.bn1.running_var\", \"model.layer1.3.conv2.weight\", \"model.layer1.3.bn2.weight\", \"model.layer1.3.bn2.bias\", \"model.layer1.3.bn2.running_mean\", \"model.layer1.3.bn2.running_var\", \"model.layer1.4.conv1.weight\", \"model.layer1.4.bn1.weight\", \"model.layer1.4.bn1.bias\", \"model.layer1.4.bn1.running_mean\", \"model.layer1.4.bn1.running_var\", \"model.layer1.4.conv2.weight\", \"model.layer1.4.bn2.weight\", \"model.layer1.4.bn2.bias\", \"model.layer1.4.bn2.running_mean\", \"model.layer1.4.bn2.running_var\", \"model.layer2.0.conv1.weight\", \"model.layer2.0.bn1.weight\", \"model.layer2.0.bn1.bias\", \"model.layer2.0.bn1.running_mean\", \"model.layer2.0.bn1.running_var\", \"model.layer2.0.conv2.weight\", \"model.layer2.0.bn2.weight\", \"model.layer2.0.bn2.bias\", \"model.layer2.0.bn2.running_mean\", \"model.layer2.0.bn2.running_var\", \"model.layer2.1.conv1.weight\", \"model.layer2.1.bn1.weight\", \"model.layer2.1.bn1.bias\", \"model.layer2.1.bn1.running_mean\", \"model.layer2.1.bn1.running_var\", \"model.layer2.1.conv2.weight\", \"model.layer2.1.bn2.weight\", \"model.layer2.1.bn2.bias\", \"model.layer2.1.bn2.running_mean\", \"model.layer2.1.bn2.running_var\", \"model.layer2.2.conv1.weight\", \"model.layer2.2.bn1.weight\", \"model.layer2.2.bn1.bias\", \"model.layer2.2.bn1.running_mean\", \"model.layer2.2.bn1.running_var\", \"model.layer2.2.conv2.weight\", \"model.layer2.2.bn2.weight\", \"model.layer2.2.bn2.bias\", \"model.layer2.2.bn2.running_mean\", \"model.layer2.2.bn2.running_var\", \"model.layer2.3.conv1.weight\", \"model.layer2.3.bn1.weight\", \"model.layer2.3.bn1.bias\", \"model.layer2.3.bn1.running_mean\", \"model.layer2.3.bn1.running_var\", \"model.layer2.3.conv2.weight\", \"model.layer2.3.bn2.weight\", \"model.layer2.3.bn2.bias\", \"model.layer2.3.bn2.running_mean\", \"model.layer2.3.bn2.running_var\", \"model.layer2.4.conv1.weight\", \"model.layer2.4.bn1.weight\", \"model.layer2.4.bn1.bias\", \"model.layer2.4.bn1.running_mean\", \"model.layer2.4.bn1.running_var\", \"model.layer2.4.conv2.weight\", \"model.layer2.4.bn2.weight\", \"model.layer2.4.bn2.bias\", \"model.layer2.4.bn2.running_mean\", \"model.layer2.4.bn2.running_var\", \"model.layer3.0.conv1.weight\", \"model.layer3.0.bn1.weight\", \"model.layer3.0.bn1.bias\", \"model.layer3.0.bn1.running_mean\", \"model.layer3.0.bn1.running_var\", \"model.layer3.0.conv2.weight\", \"model.layer3.0.bn2.weight\", \"model.layer3.0.bn2.bias\", \"model.layer3.0.bn2.running_mean\", \"model.layer3.0.bn2.running_var\", \"model.layer3.1.conv1.weight\", \"model.layer3.1.bn1.weight\", \"model.layer3.1.bn1.bias\", \"model.layer3.1.bn1.running_mean\", \"model.layer3.1.bn1.running_var\", \"model.layer3.1.conv2.weight\", \"model.layer3.1.bn2.weight\", \"model.layer3.1.bn2.bias\", \"model.layer3.1.bn2.running_mean\", \"model.layer3.1.bn2.running_var\", \"model.layer3.2.conv1.weight\", \"model.layer3.2.bn1.weight\", \"model.layer3.2.bn1.bias\", \"model.layer3.2.bn1.running_mean\", \"model.layer3.2.bn1.running_var\", \"model.layer3.2.conv2.weight\", \"model.layer3.2.bn2.weight\", \"model.layer3.2.bn2.bias\", \"model.layer3.2.bn2.running_mean\", \"model.layer3.2.bn2.running_var\", \"model.layer3.3.conv1.weight\", \"model.layer3.3.bn1.weight\", \"model.layer3.3.bn1.bias\", \"model.layer3.3.bn1.running_mean\", \"model.layer3.3.bn1.running_var\", \"model.layer3.3.conv2.weight\", \"model.layer3.3.bn2.weight\", \"model.layer3.3.bn2.bias\", \"model.layer3.3.bn2.running_mean\", \"model.layer3.3.bn2.running_var\", \"model.layer3.4.conv1.weight\", \"model.layer3.4.bn1.weight\", \"model.layer3.4.bn1.bias\", \"model.layer3.4.bn1.running_mean\", \"model.layer3.4.bn1.running_var\", \"model.layer3.4.conv2.weight\", \"model.layer3.4.bn2.weight\", \"model.layer3.4.bn2.bias\", \"model.layer3.4.bn2.running_mean\", \"model.layer3.4.bn2.running_var\", \"BNH.weight\", \"BNH.bias\", \"BNH.running_mean\", \"BNH.running_var\", \"BNM.weight\", \"BNM.bias\", \"BNM.running_mean\", \"BNM.running_var\", \"BNT.weight\", \"BNT.bias\", \"BNT.running_mean\", \"BNT.running_var\". \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_396928/4038075077.py:56: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_396928/4038075077.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):  # set enabled=True if you want AMP reproduction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANOMALY TRACE ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_396928/4038075077.py\", line 59, in <module>\n",
      "    loss = loss_fn(outputs, targets)\n",
      "  File \"/home/user/abin_ref_papers/environments/snn_stdp_poisson/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home/user/abin_ref_papers/environments/snn_stdp_poisson/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/user/abin_ref_papers/project_structure_demo/dnn_template/notebooks/../losses/reslt_loss.py\", line 97, in forward\n",
      "    labelH = target_onehot[:, self.head_classes].sum(dim=1).bool()   # boolean mask\n",
      "RuntimeError: Could not infer dtype of ellipsis\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of ellipsis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):  \u001b[38;5;66;03m# set enabled=True if you want AMP reproduction\u001b[39;00m\n\u001b[1;32m     58\u001b[0m             outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m---> 59\u001b[0m             loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/abin_ref_papers/environments/snn_stdp_poisson/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/abin_ref_papers/environments/snn_stdp_poisson/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/abin_ref_papers/project_structure_demo/dnn_template/notebooks/../losses/reslt_loss.py:97\u001b[0m, in \u001b[0;36mResLTLoss.forward\u001b[0;34m(self, outputs, targets)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# proceed with original logic now that branches are finite\u001b[39;00m\n\u001b[1;32m     96\u001b[0m target_onehot \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(targets, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 97\u001b[0m labelH \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_onehot\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead_classes\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mbool()   \u001b[38;5;66;03m# boolean mask\u001b[39;00m\n\u001b[1;32m     98\u001b[0m labelM \u001b[38;5;241m=\u001b[39m target_onehot[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmedium_classes]\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mbool()\n\u001b[1;32m     99\u001b[0m labelT \u001b[38;5;241m=\u001b[39m target_onehot[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtail_classes]\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mbool()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not infer dtype of ellipsis"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# repro_offline.py — offline reproduce with detect_anomaly()\n",
    "import torch, glob, traceback\n",
    "from losses.reslt_loss import ResLTLoss  # adjust import if needed\n",
    "from models import REGISTRY as MODEL_REG   # if your project exposes a model registry\n",
    "\n",
    "# === ADAPT THESE to your project/config ===\n",
    "MODEL_KEY = \"resltresnet32\"   # model registry key used in train.py\n",
    "MODEL_ARGS = {\"num_classes\": 7, \"scale\": 1}\n",
    "LOSS_ARGS = {\"num_classes\": 7, \"head_classes\": [...], \"medium_classes\": [...], \"tail_classes\": [...], \"beta\": 0.96}\n",
    "CHECKPOINT_PATH = None  # if you have a checkpoint file, set path here (optional)\n",
    "# ==========================================\n",
    "\n",
    "# pick the latest debug file containing batch (we used nan_grad_... earlier)\n",
    "dbg_files = sorted(glob.glob(\"../debug/nan_grad_epoch*.pth\") + glob.glob(\"../debug/crash_nan_grad.pth\") + glob.glob(\"../debug/crash_final.pth\"))\n",
    "if not dbg_files:\n",
    "    raise SystemExit(\"No debug files found in debug/\")\n",
    "\n",
    "dbg = torch.load(dbg_files[-1], map_location=\"cpu\")\n",
    "print(\"Using debug file:\", dbg_files[-1])\n",
    "# Expect inputs/targets in dbg\n",
    "inputs = dbg.get(\"inputs\")\n",
    "targets = dbg.get(\"targets\")\n",
    "if inputs is None or targets is None:\n",
    "    raise SystemExit(\"Debug file does not contain inputs/targets. Use in-process reproduction.\")\n",
    "\n",
    "# build model and load checkpoint if available (or load model_state from crash_final if present)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = MODEL_REG[MODEL_KEY](**MODEL_ARGS).to(device)\n",
    "\n",
    "# If crash_final contains full state, use that (preferred)\n",
    "if \"model_state\" in dbg and isinstance(dbg[\"model_state\"], dict):\n",
    "    try:\n",
    "        model.load_state_dict(dbg[\"model_state\"])\n",
    "        print(\"Loaded model_state from debug file (crash_final preview).\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed loading model_state from debug file preview:\", e)\n",
    "\n",
    "# If you have an external checkpoint file, you can also load it now:\n",
    "if CHECKPOINT_PATH:\n",
    "    ck = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "    model.load_state_dict(ck[\"model\"])\n",
    "    print(\"Loaded checkpoint\", CHECKPOINT_PATH)\n",
    "\n",
    "model.train()\n",
    "inputs = inputs.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "# Recreate your loss exactly as in training\n",
    "loss_fn = ResLTLoss(**{k:v for k,v in LOSS_ARGS.items() if k in [\"num_classes\",\"head_classes\",\"medium_classes\",\"tail_classes\",\"beta\"]})\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "try:\n",
    "    with torch.autograd.detect_anomaly():\n",
    "        with torch.cuda.amp.autocast(enabled=False):  # set enabled=True if you want AMP reproduction\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "except Exception as e:\n",
    "    print(\"=== ANOMALY TRACE ===\")\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "else:\n",
    "    print(\"No anomaly raised for that batch (unexpected).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da860ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cd63a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repro_anomaly.py\n",
    "import torch, glob, traceback, sys, os\n",
    "from losses.reslt_loss import ResLTLoss\n",
    "from models import REGISTRY as MODEL_REG  # uses your project's model registry\n",
    "\n",
    "DEBUG_DIR = \"debug\"\n",
    "# pick the most informative debug file (prefer crash_final if it contains model_state)\n",
    "cands = sorted(glob.glob(os.path.join(DEBUG_DIR, \"crash_final.pth\")) +\n",
    "               glob.glob(os.path.join(DEBUG_DIR, \"nan_grad_epoch*.pth\")) +\n",
    "               glob.glob(os.path.join(DEBUG_DIR, \"crash_nan_grad.pth\")))\n",
    "if not cands:\n",
    "    print(\"No debug files found in debug/. Exiting.\")\n",
    "    sys.exit(1)\n",
    "dbg_path = cands[0] if os.path.basename(cands[0]) == \"crash_final.pth\" else cands[-1]\n",
    "print(\"Using debug file:\", dbg_path)\n",
    "dbg = torch.load(dbg_path, map_location=\"cpu\")\n",
    "\n",
    "# Extract inputs and targets from debug\n",
    "inputs = dbg.get(\"inputs\", None)\n",
    "targets = dbg.get(\"targets\", None)\n",
    "if inputs is None or targets is None:\n",
    "    print(\"Debug file does not contain inputs/targets. Exiting.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# === Construct model (match your train config) ===\n",
    "MODEL_KEY = \"resltresnet32\"   # change if different\n",
    "MODEL_ARGS = {\"num_classes\": 7, \"scale\": 1}\n",
    "\n",
    "model = MODEL_REG[MODEL_KEY](**MODEL_ARGS).to(device)\n",
    "\n",
    "# If crash_final saved full model_state, prefer that\n",
    "if \"model_state\" in dbg and isinstance(dbg[\"model_state\"], dict):\n",
    "    try:\n",
    "        model.load_state_dict(dbg[\"model_state\"])\n",
    "        print(\"Loaded model_state from debug file.\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to load model_state from debug file:\", e)\n",
    "\n",
    "# Move inputs/targets to device\n",
    "inputs = inputs.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "# === Recreate ResLTLoss with the same args you used ===\n",
    "loss_fn = ResLTLoss(\n",
    "    num_classes=7,\n",
    "    head_classes=[\"Very_Low\", \"Non-burnable\"],    # replace names with indices if your loss expects indices\n",
    "    medium_classes=[\"Low\", \"Moderate\"],\n",
    "    tail_classes=[\"High\", \"Very_High\", \"Water\"],\n",
    "    beta=0.96\n",
    ")\n",
    "# If your ResLTLoss expects indices instead of names, adapt above to use index lists.\n",
    "\n",
    "loss_fn = loss_fn.to(device) if hasattr(loss_fn, \"to\") else loss_fn\n",
    "\n",
    "# Run under anomaly detection. Try first WITH AMP (since crash happened with AMP enabled),\n",
    "# then WITHOUT AMP if needed.\n",
    "print(\"Running forward/backward under torch.autograd.detect_anomaly() with AMP autocast enabled.\")\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "try:\n",
    "    # Use AMP autocast same as training (device_type auto)\n",
    "    with torch.cuda.amp.autocast(enabled=True):\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "    # backward outside autocast; detect_anomaly will catch op producing NaN/Inf\n",
    "    loss.backward()\n",
    "    print(\"Backward completed without anomaly (unexpected).\")\n",
    "except Exception:\n",
    "    print(\"=== ANOMALY TRACE (AMP run) ===\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "# If AMP run didn't reveal it, try without AMP\n",
    "print(\"\\nNow trying without AMP (plain fp32) under detect_anomaly().\")\n",
    "try:\n",
    "    model.zero_grad(set_to_none=True)\n",
    "    with torch.autograd.detect_anomaly():\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "    print(\"Backward (no AMP) completed without anomaly (unexpected).\")\n",
    "except Exception:\n",
    "    print(\"=== ANOMALY TRACE (no AMP run) ===\")\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd56b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1729d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc8134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3171ddcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "890a7a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using debug file: ../debug/crash_final.pth\n",
      "head_idx, medium_idx, tail_idx: [5, 3] [1, 2] [0, 4, 6]\n",
      "Loaded model_state from debug file.\n",
      "Running detect_anomaly() on CPU with a small sub-batch (no AMP).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_398303/2367822856.py:104: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward completed without anomaly (unexpected).\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "# repro_anomaly_fixed.py\n",
    "import os, glob, torch, traceback, sys\n",
    "\n",
    "# --- project imports (assumes repo root is on PYTHONPATH like in train.py) ---\n",
    "from models import REGISTRY as MODEL_REG\n",
    "from losses.reslt_loss import ResLTLoss\n",
    "from data import REGISTRY as DATA_REG   # to get class_to_idx mapping (same as train.py)\n",
    "\n",
    "DEBUG_DIR = \"../debug\"\n",
    "# pick prefer crash_final, else the last nan_grad file\n",
    "cands = sorted(glob.glob(os.path.join(DEBUG_DIR, \"crash_final.pth\")) +\n",
    "               glob.glob(os.path.join(DEBUG_DIR, \"nan_grad_epoch*.pth\")) +\n",
    "               glob.glob(os.path.join(DEBUG_DIR, \"crash_nan_grad.pth\")))\n",
    "if not cands:\n",
    "    print(\"No debug files found in debug/. Exiting.\")\n",
    "    sys.exit(1)\n",
    "dbg_path = cands[0] if os.path.basename(cands[0]) == \"crash_final.pth\" else cands[-1]\n",
    "print(\"Using debug file:\", dbg_path)\n",
    "dbg = torch.load(dbg_path, map_location=\"cpu\")\n",
    "\n",
    "# Extract saved batch\n",
    "inputs = dbg.get(\"inputs\", None)\n",
    "targets = dbg.get(\"targets\", None)\n",
    "if inputs is None or targets is None:\n",
    "    print(\"Debug file missing inputs/targets. Exiting.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Reduce batch size to avoid OOM during repro; 8 is usually safe\n",
    "inputs = inputs[:8]\n",
    "targets = targets[:8]\n",
    "\n",
    "# --- Build dataset to map names -> indices (only if your config used names) ---\n",
    "# adapt these to the dataset key / args used in your training config\n",
    "DATA_KEY = \"firerisk\"   # same as cfg[\"dataset\"]\n",
    "DATA_DIR = \"../data/FireRisk\"\n",
    "# Use same arguments as training if needed (image_size, to_rgb, imagenet_norm)\n",
    "train_set, _ = DATA_REG[DATA_KEY](DATA_DIR, image_size=320, to_rgb=False, imagenet_norm=False)\n",
    "class_to_idx = getattr(train_set, \"class_to_idx\", None)\n",
    "if class_to_idx is None:\n",
    "    print(\"Warning: dataset has no class_to_idx. If your config used names you must provide indices.\")\n",
    "    class_to_idx = {}\n",
    "\n",
    "# The names you used in your YAML config:\n",
    "head_names   = [\"Very_Low\", \"Non-burnable\"]\n",
    "medium_names = [\"Low\", \"Moderate\"]\n",
    "tail_names   = [\"High\", \"Very_High\", \"Water\"]\n",
    "\n",
    "# Convert to indices (if names missing, try using them as indices already)\n",
    "def names_to_indices(lst):\n",
    "    if not lst:\n",
    "        return []\n",
    "    if isinstance(lst[0], str):\n",
    "        if not class_to_idx:\n",
    "            raise RuntimeError(\"class_to_idx not available; cannot map names to indices.\")\n",
    "        return [class_to_idx[n] for n in lst]\n",
    "    return list(lst)\n",
    "\n",
    "head_idx = names_to_indices(head_names)\n",
    "medium_idx = names_to_indices(medium_names)\n",
    "tail_idx = names_to_indices(tail_names)\n",
    "print(\"head_idx, medium_idx, tail_idx:\", head_idx, medium_idx, tail_idx)\n",
    "\n",
    "# --- Construct model (match your training model key and args) ---\n",
    "MODEL_KEY = \"resltresnet32\"   # change if different\n",
    "MODEL_ARGS = {\"num_classes\": 7, \"scale\": 1}\n",
    "device = \"cpu\"   # run on CPU to avoid GPU OOM; change to \"cuda\" only if you want GPU and have memory\n",
    "model = MODEL_REG[MODEL_KEY](**MODEL_ARGS).to(device)\n",
    "\n",
    "# If crash_final.pth contained full model_state, try to load it\n",
    "if \"model_state\" in dbg and isinstance(dbg[\"model_state\"], dict):\n",
    "    try:\n",
    "        model.load_state_dict(dbg[\"model_state\"])\n",
    "        print(\"Loaded model_state from debug file.\")\n",
    "    except Exception as e:\n",
    "        print(\"Warning: failed to load model_state from debug file:\", e)\n",
    "\n",
    "# Move inputs/targets to device\n",
    "inputs = inputs.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "# --- Build the ResLTLoss with integer indices (safe) ---\n",
    "loss_fn = ResLTLoss(\n",
    "    num_classes=MODEL_ARGS[\"num_classes\"],\n",
    "    head_classes=head_idx,\n",
    "    medium_classes=medium_idx,\n",
    "    tail_classes=tail_idx,\n",
    "    class_to_idx=None,\n",
    "    beta=0.96\n",
    ")\n",
    "# If ResLTLoss has a .to(), move it\n",
    "try:\n",
    "    loss_fn = loss_fn.to(device)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Run with anomaly detection (first try plain fp32 on CPU to avoid AMP/GPU memory complexity)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "print(\"Running detect_anomaly() on CPU with a small sub-batch (no AMP).\")\n",
    "try:\n",
    "    with torch.autograd.detect_anomaly():\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "    print(\"Backward completed without anomaly (unexpected).\")\n",
    "except Exception:\n",
    "    print(\"=== ANOMALY TRACE (cpu, no AMP) ===\")\n",
    "    traceback.print_exc()\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91774448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 70331\n",
       "    Root location: ../data/FireRisk/train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=320, interpolation=bilinear, max_size=None, antialias=True)\n",
       "               RandomCrop(size=(320, 320), padding=4)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc932a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b7049aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ../debug/nan_grad_epoch6_step511_model.conv1.weight.pth\n",
      "{'current_scale': {'preview': '32768.0', 'type': 'float'},\n",
      " 'epoch': {'preview': '6', 'type': 'int'},\n",
      " 'grad_sample': {'any_inf': False,\n",
      "                 'any_nan': False,\n",
      "                 'dtype': 'torch.float32',\n",
      "                 'max': -0.0,\n",
      "                 'min': -0.0,\n",
      "                 'sample_flat': [-0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 -0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 -0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 0.0,\n",
      "                                 0.0],\n",
      "                 'shape': (100,),\n",
      "                 'type': 'tensor'},\n",
      " 'inputs': {'any_inf': False,\n",
      "            'any_nan': False,\n",
      "            'dtype': 'torch.float32',\n",
      "            'max': 1.0,\n",
      "            'min': 0.0,\n",
      "            'sample_flat': [0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0],\n",
      "            'shape': (64, 3, 320, 320),\n",
      "            'type': 'tensor'},\n",
      " 'model_state': {'preview': \"{'linear.weight': tensor([[ 0.2840,  0.0630, \"\n",
      "                            '-0.1238,  0.1018,  0.1785,  0.1620,  0.1474,  '\n",
      "                            '0.2296,\\n'\n",
      "                            '          0.1545,  0.1096,  0.1343, -0.0443,  '\n",
      "                            '0.1826,  0.1387, -0.1440, -0.0446,\\n'\n",
      "                            '         -0.1426,  0.0377, -0.0702,  0.1818, '\n",
      "                            '-0.2024, -0.1412, -0.1668, -0.2158,\\n'\n",
      "                            '         -0.0374, -0.2664,  0.2499, -0.1064,  '\n",
      "                            '0.1578, -0.0704, -0.1808,  0.1988,\\n'\n",
      "                            '         -0.1116,  0.1487,  0.2515, -0.1580, '\n",
      "                            '-0.0369,  0.1',\n",
      "                 'type': 'dict'},\n",
      " 'opt_state_keys': {'preview': \"['state', 'param_groups']\", 'type': 'list'},\n",
      " 'param_name': {'preview': \"'model.conv1.weight'\", 'type': 'str'},\n",
      " 'step_in_epoch': {'preview': '511', 'type': 'int'},\n",
      " 'targets': {'any_inf': False,\n",
      "             'any_nan': False,\n",
      "             'dtype': 'torch.int64',\n",
      "             'max': 6.0,\n",
      "             'min': 0.0,\n",
      "             'sample_flat': [2,\n",
      "                             4,\n",
      "                             1,\n",
      "                             3,\n",
      "                             3,\n",
      "                             1,\n",
      "                             3,\n",
      "                             5,\n",
      "                             1,\n",
      "                             5,\n",
      "                             2,\n",
      "                             5,\n",
      "                             1,\n",
      "                             5,\n",
      "                             5,\n",
      "                             3,\n",
      "                             0,\n",
      "                             5,\n",
      "                             5,\n",
      "                             0,\n",
      "                             5,\n",
      "                             0,\n",
      "                             1,\n",
      "                             3,\n",
      "                             1,\n",
      "                             3,\n",
      "                             5,\n",
      "                             0,\n",
      "                             0,\n",
      "                             5,\n",
      "                             5,\n",
      "                             1,\n",
      "                             6,\n",
      "                             3,\n",
      "                             1,\n",
      "                             3,\n",
      "                             3,\n",
      "                             5,\n",
      "                             3,\n",
      "                             0,\n",
      "                             1,\n",
      "                             5,\n",
      "                             5,\n",
      "                             0,\n",
      "                             3,\n",
      "                             5,\n",
      "                             5,\n",
      "                             0,\n",
      "                             2,\n",
      "                             3],\n",
      "             'shape': (64,),\n",
      "             'type': 'tensor'},\n",
      " 'where': {'preview': \"'nan_grad_after_unscale'\", 'type': 'str'}}\n"
     ]
    }
   ],
   "source": [
    "# inspect_nan_debug.py\n",
    "import torch, glob, os, pprint\n",
    "p = \"../debug/nan_grad_epoch6_step511_model.conv1.weight.pth\"\n",
    "if not os.path.exists(p):\n",
    "    # fallback: pick most recent nan_grad file\n",
    "    files = sorted(glob.glob(\"../debug/nan_grad_epoch*.pth\") + glob.glob(\"../debug/crash_nan_grad.pth\") + glob.glob(\"../debug/crash_final.pth\"))\n",
    "    if not files:\n",
    "        raise SystemExit(\"No debug files found in debug/\")\n",
    "    p = files[-1]\n",
    "print(\"Loading:\", p)\n",
    "d = torch.load(p, map_location=\"cpu\")\n",
    "summary = {}\n",
    "for k,v in d.items():\n",
    "    if isinstance(v, torch.Tensor):\n",
    "        summary[k] = {\n",
    "            \"type\": \"tensor\",\n",
    "            \"shape\": tuple(v.shape),\n",
    "            \"dtype\": str(v.dtype),\n",
    "            \"any_nan\": bool(torch.isnan(v).any().item()),\n",
    "            \"any_inf\": bool(torch.isinf(v).any().item()),\n",
    "            \"min\": float(torch.min(v)) if v.numel() else None,\n",
    "            \"max\": float(torch.max(v)) if v.numel() else None,\n",
    "            \"sample_flat\": v.view(-1)[:50].tolist() if v.numel() else []\n",
    "        }\n",
    "    else:\n",
    "        summary[k] = {\"type\": type(v).__name__, \"preview\": repr(v)[:400]}\n",
    "pprint.pprint(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a108b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using debug file: ../debug/nan_grad_epoch6_step511_model.conv1.weight.pth\n",
      "Warning: failed to load model_state from debug file: Error(s) in loading state_dict for ResLTResNet32:\n",
      "\tMissing key(s) in state_dict: \"model.layer1.2.bn2.bias\", \"model.layer1.2.bn2.running_mean\", \"model.layer1.2.bn2.running_var\", \"model.layer1.3.conv1.weight\", \"model.layer1.3.bn1.weight\", \"model.layer1.3.bn1.bias\", \"model.layer1.3.bn1.running_mean\", \"model.layer1.3.bn1.running_var\", \"model.layer1.3.conv2.weight\", \"model.layer1.3.bn2.weight\", \"model.layer1.3.bn2.bias\", \"model.layer1.3.bn2.running_mean\", \"model.layer1.3.bn2.running_var\", \"model.layer1.4.conv1.weight\", \"model.layer1.4.bn1.weight\", \"model.layer1.4.bn1.bias\", \"model.layer1.4.bn1.running_mean\", \"model.layer1.4.bn1.running_var\", \"model.layer1.4.conv2.weight\", \"model.layer1.4.bn2.weight\", \"model.layer1.4.bn2.bias\", \"model.layer1.4.bn2.running_mean\", \"model.layer1.4.bn2.running_var\", \"model.layer2.0.conv1.weight\", \"model.layer2.0.bn1.weight\", \"model.layer2.0.bn1.bias\", \"model.layer2.0.bn1.running_mean\", \"model.layer2.0.bn1.running_var\", \"model.layer2.0.conv2.weight\", \"model.layer2.0.bn2.weight\", \"model.layer2.0.bn2.bias\", \"model.layer2.0.bn2.running_mean\", \"model.layer2.0.bn2.running_var\", \"model.layer2.1.conv1.weight\", \"model.layer2.1.bn1.weight\", \"model.layer2.1.bn1.bias\", \"model.layer2.1.bn1.running_mean\", \"model.layer2.1.bn1.running_var\", \"model.layer2.1.conv2.weight\", \"model.layer2.1.bn2.weight\", \"model.layer2.1.bn2.bias\", \"model.layer2.1.bn2.running_mean\", \"model.layer2.1.bn2.running_var\", \"model.layer2.2.conv1.weight\", \"model.layer2.2.bn1.weight\", \"model.layer2.2.bn1.bias\", \"model.layer2.2.bn1.running_mean\", \"model.layer2.2.bn1.running_var\", \"model.layer2.2.conv2.weight\", \"model.layer2.2.bn2.weight\", \"model.layer2.2.bn2.bias\", \"model.layer2.2.bn2.running_mean\", \"model.layer2.2.bn2.running_var\", \"model.layer2.3.conv1.weight\", \"model.layer2.3.bn1.weight\", \"model.layer2.3.bn1.bias\", \"model.layer2.3.bn1.running_mean\", \"model.layer2.3.bn1.running_var\", \"model.layer2.3.conv2.weight\", \"model.layer2.3.bn2.weight\", \"model.layer2.3.bn2.bias\", \"model.layer2.3.bn2.running_mean\", \"model.layer2.3.bn2.running_var\", \"model.layer2.4.conv1.weight\", \"model.layer2.4.bn1.weight\", \"model.layer2.4.bn1.bias\", \"model.layer2.4.bn1.running_mean\", \"model.layer2.4.bn1.running_var\", \"model.layer2.4.conv2.weight\", \"model.layer2.4.bn2.weight\", \"model.layer2.4.bn2.bias\", \"model.layer2.4.bn2.running_mean\", \"model.layer2.4.bn2.running_var\", \"model.layer3.0.conv1.weight\", \"model.layer3.0.bn1.weight\", \"model.layer3.0.bn1.bias\", \"model.layer3.0.bn1.running_mean\", \"model.layer3.0.bn1.running_var\", \"model.layer3.0.conv2.weight\", \"model.layer3.0.bn2.weight\", \"model.layer3.0.bn2.bias\", \"model.layer3.0.bn2.running_mean\", \"model.layer3.0.bn2.running_var\", \"model.layer3.1.conv1.weight\", \"model.layer3.1.bn1.weight\", \"model.layer3.1.bn1.bias\", \"model.layer3.1.bn1.running_mean\", \"model.layer3.1.bn1.running_var\", \"model.layer3.1.conv2.weight\", \"model.layer3.1.bn2.weight\", \"model.layer3.1.bn2.bias\", \"model.layer3.1.bn2.running_mean\", \"model.layer3.1.bn2.running_var\", \"model.layer3.2.conv1.weight\", \"model.layer3.2.bn1.weight\", \"model.layer3.2.bn1.bias\", \"model.layer3.2.bn1.running_mean\", \"model.layer3.2.bn1.running_var\", \"model.layer3.2.conv2.weight\", \"model.layer3.2.bn2.weight\", \"model.layer3.2.bn2.bias\", \"model.layer3.2.bn2.running_mean\", \"model.layer3.2.bn2.running_var\", \"model.layer3.3.conv1.weight\", \"model.layer3.3.bn1.weight\", \"model.layer3.3.bn1.bias\", \"model.layer3.3.bn1.running_mean\", \"model.layer3.3.bn1.running_var\", \"model.layer3.3.conv2.weight\", \"model.layer3.3.bn2.weight\", \"model.layer3.3.bn2.bias\", \"model.layer3.3.bn2.running_mean\", \"model.layer3.3.bn2.running_var\", \"model.layer3.4.conv1.weight\", \"model.layer3.4.bn1.weight\", \"model.layer3.4.bn1.bias\", \"model.layer3.4.bn1.running_mean\", \"model.layer3.4.bn1.running_var\", \"model.layer3.4.conv2.weight\", \"model.layer3.4.bn2.weight\", \"model.layer3.4.bn2.bias\", \"model.layer3.4.bn2.running_mean\", \"model.layer3.4.bn2.running_var\", \"BNH.weight\", \"BNH.bias\", \"BNH.running_mean\", \"BNH.running_var\", \"BNM.weight\", \"BNM.bias\", \"BNM.running_mean\", \"BNM.running_var\", \"BNT.weight\", \"BNT.bias\", \"BNT.running_mean\", \"BNT.running_var\". \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_398303/3450751288.py:54: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward completed without raising (on CPU). If this reproduces nothing, try AMP run on GPU with small batch and smaller init_scale.\n"
     ]
    }
   ],
   "source": [
    "# repro_nan_cpu.py\n",
    "import torch, glob, os, traceback, sys\n",
    "from models import REGISTRY as MODEL_REG\n",
    "from losses.reslt_loss import ResLTLoss\n",
    "\n",
    "# pick best debug file\n",
    "cands = sorted(glob.glob(\"../debug/crash_final.pth\") + glob.glob(\"../debug/nan_grad_epoch*.pth\") + glob.glob(\"../debug/crash_nan_grad.pth\"))\n",
    "if not cands:\n",
    "    raise SystemExit(\"No debug files in debug/\")\n",
    "dbg_path = cands[-1]\n",
    "print(\"Using debug file:\", dbg_path)\n",
    "dbg = torch.load(dbg_path, map_location=\"cpu\")\n",
    "\n",
    "inputs = dbg.get(\"inputs\")\n",
    "targets = dbg.get(\"targets\")\n",
    "if inputs is None or targets is None:\n",
    "    print(\"Debug file lacks inputs/targets. Exiting.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# reduce batch size to avoid OOM\n",
    "sub = min(8, inputs.shape[0])\n",
    "inputs = inputs[:sub]\n",
    "targets = targets[:sub]\n",
    "\n",
    "device = \"cpu\"\n",
    "# adapt model key/args to match your config\n",
    "MODEL_KEY = \"resltresnet32\"\n",
    "MODEL_ARGS = {\"num_classes\": 7, \"scale\": 1}\n",
    "model = MODEL_REG[MODEL_KEY](**MODEL_ARGS).to(device)\n",
    "\n",
    "# try to load full model state from crash_final if it's present\n",
    "if \"model_state\" in dbg and isinstance(dbg[\"model_state\"], dict):\n",
    "    try:\n",
    "        model.load_state_dict(dbg[\"model_state\"])\n",
    "        print(\"Loaded model_state from debug file.\")\n",
    "    except Exception as e:\n",
    "        print(\"Warning: failed to load model_state from debug file:\", e)\n",
    "\n",
    "# prepare loss with integer indices (map names->indices if needed)\n",
    "# replace with your dataset mapping if required\n",
    "loss_fn = ResLTLoss(num_classes=7,\n",
    "                    head_classes=[5,3], medium_classes=[1,2], tail_classes=[0,4,6],\n",
    "                    class_to_idx=None, beta=0.96)\n",
    "try:\n",
    "    loss_fn = loss_fn.to(device)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "inputs = inputs.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "try:\n",
    "    with torch.autograd.detect_anomaly():\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "except Exception:\n",
    "    print(\"=== ANOMALY TRACE ===\")\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "else:\n",
    "    print(\"Backward completed without raising (on CPU). If this reproduces nothing, try AMP run on GPU with small batch and smaller init_scale.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78305201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9092151d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using debug file: ../debug/nan_grad_epoch6_step511_model.conv1.weight.pth\n",
      "Warning: failed to load model_state from debug file: Error(s) in loading state_dict for ResLTResNet32:\n",
      "\tMissing key(s) in state_dict: \"model.layer1.2.bn2.bias\", \"model.layer1.2.bn2.running_mean\", \"model.layer1.2.bn2.running_var\", \"model.layer1.3.conv1.weight\", \"model.layer1.3.bn1.weight\", \"model.layer1.3.bn1.bias\", \"model.layer1.3.bn1.running_mean\", \"model.layer1.3.bn1.running_var\", \"model.layer1.3.conv2.weight\", \"model.layer1.3.bn2.weight\", \"model.layer1.3.bn2.bias\", \"model.layer1.3.bn2.running_mean\", \"model.layer1.3.bn2.running_var\", \"model.layer1.4.conv1.weight\", \"model.layer1.4.bn1.weight\", \"model.layer1.4.bn1.bias\", \"model.layer1.4.bn1.running_mean\", \"model.layer1.4.bn1.running_var\", \"model.layer1.4.conv2.weight\", \"model.layer1.4.bn2.weight\", \"model.layer1.4.bn2.bias\", \"model.layer1.4.bn2.running_mean\", \"model.layer1.4.bn2.running_var\", \"model.layer2.0.conv1.weight\", \"model.layer2.0.bn1.weight\", \"model.layer2.0.bn1.bias\", \"model.layer2.0.bn1.running_mean\", \"model.layer2.0.bn1.running_var\", \"model.layer2.0.conv2.weight\", \"model.layer2.0.bn2.weight\", \"model.layer2.0.bn2.bias\", \"model.layer2.0.bn2.running_mean\", \"model.layer2.0.bn2.running_var\", \"model.layer2.1.conv1.weight\", \"model.layer2.1.bn1.weight\", \"model.layer2.1.bn1.bias\", \"model.layer2.1.bn1.running_mean\", \"model.layer2.1.bn1.running_var\", \"model.layer2.1.conv2.weight\", \"model.layer2.1.bn2.weight\", \"model.layer2.1.bn2.bias\", \"model.layer2.1.bn2.running_mean\", \"model.layer2.1.bn2.running_var\", \"model.layer2.2.conv1.weight\", \"model.layer2.2.bn1.weight\", \"model.layer2.2.bn1.bias\", \"model.layer2.2.bn1.running_mean\", \"model.layer2.2.bn1.running_var\", \"model.layer2.2.conv2.weight\", \"model.layer2.2.bn2.weight\", \"model.layer2.2.bn2.bias\", \"model.layer2.2.bn2.running_mean\", \"model.layer2.2.bn2.running_var\", \"model.layer2.3.conv1.weight\", \"model.layer2.3.bn1.weight\", \"model.layer2.3.bn1.bias\", \"model.layer2.3.bn1.running_mean\", \"model.layer2.3.bn1.running_var\", \"model.layer2.3.conv2.weight\", \"model.layer2.3.bn2.weight\", \"model.layer2.3.bn2.bias\", \"model.layer2.3.bn2.running_mean\", \"model.layer2.3.bn2.running_var\", \"model.layer2.4.conv1.weight\", \"model.layer2.4.bn1.weight\", \"model.layer2.4.bn1.bias\", \"model.layer2.4.bn1.running_mean\", \"model.layer2.4.bn1.running_var\", \"model.layer2.4.conv2.weight\", \"model.layer2.4.bn2.weight\", \"model.layer2.4.bn2.bias\", \"model.layer2.4.bn2.running_mean\", \"model.layer2.4.bn2.running_var\", \"model.layer3.0.conv1.weight\", \"model.layer3.0.bn1.weight\", \"model.layer3.0.bn1.bias\", \"model.layer3.0.bn1.running_mean\", \"model.layer3.0.bn1.running_var\", \"model.layer3.0.conv2.weight\", \"model.layer3.0.bn2.weight\", \"model.layer3.0.bn2.bias\", \"model.layer3.0.bn2.running_mean\", \"model.layer3.0.bn2.running_var\", \"model.layer3.1.conv1.weight\", \"model.layer3.1.bn1.weight\", \"model.layer3.1.bn1.bias\", \"model.layer3.1.bn1.running_mean\", \"model.layer3.1.bn1.running_var\", \"model.layer3.1.conv2.weight\", \"model.layer3.1.bn2.weight\", \"model.layer3.1.bn2.bias\", \"model.layer3.1.bn2.running_mean\", \"model.layer3.1.bn2.running_var\", \"model.layer3.2.conv1.weight\", \"model.layer3.2.bn1.weight\", \"model.layer3.2.bn1.bias\", \"model.layer3.2.bn1.running_mean\", \"model.layer3.2.bn1.running_var\", \"model.layer3.2.conv2.weight\", \"model.layer3.2.bn2.weight\", \"model.layer3.2.bn2.bias\", \"model.layer3.2.bn2.running_mean\", \"model.layer3.2.bn2.running_var\", \"model.layer3.3.conv1.weight\", \"model.layer3.3.bn1.weight\", \"model.layer3.3.bn1.bias\", \"model.layer3.3.bn1.running_mean\", \"model.layer3.3.bn1.running_var\", \"model.layer3.3.conv2.weight\", \"model.layer3.3.bn2.weight\", \"model.layer3.3.bn2.bias\", \"model.layer3.3.bn2.running_mean\", \"model.layer3.3.bn2.running_var\", \"model.layer3.4.conv1.weight\", \"model.layer3.4.bn1.weight\", \"model.layer3.4.bn1.bias\", \"model.layer3.4.bn1.running_mean\", \"model.layer3.4.bn1.running_var\", \"model.layer3.4.conv2.weight\", \"model.layer3.4.bn2.weight\", \"model.layer3.4.bn2.bias\", \"model.layer3.4.bn2.running_mean\", \"model.layer3.4.bn2.running_var\", \"BNH.weight\", \"BNH.bias\", \"BNH.running_mean\", \"BNH.running_var\", \"BNM.weight\", \"BNM.bias\", \"BNM.running_mean\", \"BNM.running_var\", \"BNT.weight\", \"BNT.bias\", \"BNT.running_mean\", \"BNT.running_var\". \n",
      "Running AMP/DetectAnomaly repro on GPU with small init_scale ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_398303/3971436028.py:50: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=True, init_scale=2**8)\n",
      "/tmp/ipykernel_398303/3971436028.py:56: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_398303/3971436028.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward completed without anomaly (unexpected).\n"
     ]
    }
   ],
   "source": [
    "# repro_amp_gpu.py\n",
    "import os, glob, sys, traceback, torch\n",
    "from models import REGISTRY as MODEL_REG\n",
    "from losses.reslt_loss import ResLTLoss\n",
    "\n",
    "DEBUG_DIR = \"../debug\"\n",
    "# pick the most recent useful debug file\n",
    "cands = sorted(glob.glob(os.path.join(DEBUG_DIR, \"crash_final.pth\")) +\n",
    "               glob.glob(os.path.join(DEBUG_DIR, \"nan_grad_epoch*.pth\")) +\n",
    "               glob.glob(os.path.join(DEBUG_DIR, \"crash_nan_grad.pth\")))\n",
    "if not cands:\n",
    "    print(\"No debug files found in debug/. Exiting.\")\n",
    "    sys.exit(1)\n",
    "dbg_path = cands[-1]\n",
    "print(\"Using debug file:\", dbg_path)\n",
    "dbg = torch.load(dbg_path, map_location=\"cpu\")\n",
    "\n",
    "inputs = dbg.get(\"inputs\")\n",
    "targets = dbg.get(\"targets\")\n",
    "if inputs is None or targets is None:\n",
    "    print(\"Debug file missing inputs/targets. Exiting.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# reduce sub-batch to avoid OOM\n",
    "sub = min(4, inputs.shape[0])\n",
    "inputs = inputs[:sub].cuda()\n",
    "targets = targets[:sub].cuda()\n",
    "\n",
    "# model config (match your train config)\n",
    "MODEL_KEY = \"resltresnet32\"\n",
    "MODEL_ARGS = {\"num_classes\": 7, \"scale\": 1}\n",
    "model = MODEL_REG[MODEL_KEY](**MODEL_ARGS).cuda()\n",
    "\n",
    "# try to load model_state if the crash_final contained it\n",
    "if \"model_state\" in dbg and isinstance(dbg[\"model_state\"], dict):\n",
    "    try:\n",
    "        model.load_state_dict(dbg[\"model_state\"])\n",
    "        print(\"Loaded model_state from debug file (partial/full).\")\n",
    "    except Exception as e:\n",
    "        print(\"Warning: failed to load model_state from debug file:\", e)\n",
    "\n",
    "# Build loss with integer indices (use mapping you used in train)\n",
    "loss_fn = ResLTLoss(num_classes=7, head_classes=[5,3], medium_classes=[1,2], tail_classes=[0,4,6], class_to_idx=None, beta=0.96)\n",
    "try:\n",
    "    loss_fn = loss_fn.cuda()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Use a conservative init_scale to avoid spurious overflow while still using AMP\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=True, init_scale=2**8)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "print(\"Running AMP/DetectAnomaly repro on GPU with small init_scale ...\")\n",
    "try:\n",
    "    # detect_anomaly should wrap the backward region\n",
    "    with torch.autograd.detect_anomaly():\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "        # scaled backward (like training)\n",
    "        scaler.scale(loss).backward()\n",
    "    print(\"Backward completed without anomaly (unexpected).\")\n",
    "except Exception:\n",
    "    print(\"=== ANOMALY TRACE (AMP GPU run) ===\")\n",
    "    traceback.print_exc()\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f97e5f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model_state (partial) into model with strict=False\n",
      "BN: ('model.bn1', (16,), 0.022550377994775772, 0.0035867849364876747, 0.10274787247180939)\n",
      "BN: ('model.layer1.0.bn1', (16,), 1.3074198961257935, 0.48375412821769714, 3.54730224609375)\n",
      "BN: ('model.layer1.0.bn2', (16,), 1.0431103706359863, 0.4706116318702698, 1.965854525566101)\n",
      "BN: ('model.layer1.1.bn1', (16,), 2.874728202819824, 1.4460272789001465, 5.051095008850098)\n",
      "BN: ('model.layer1.1.bn2', (16,), 0.9074885845184326, 0.3552698791027069, 2.0965664386749268)\n",
      "BN: ('model.layer1.2.bn1', (16,), 3.8629841804504395, 2.138880968093872, 6.481569766998291)\n",
      "BN: ('model.layer1.2.bn2', (16,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer1.3.bn1', (16,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer1.3.bn2', (16,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer1.4.bn1', (16,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer1.4.bn2', (16,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer2.0.bn1', (32,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer2.0.bn2', (32,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer2.1.bn1', (32,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer2.1.bn2', (32,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer2.2.bn1', (32,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer2.2.bn2', (32,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer2.3.bn1', (32,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer2.3.bn2', (32,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer2.4.bn1', (32,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer2.4.bn2', (32,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer3.0.bn1', (64,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer3.0.bn2', (64,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer3.1.bn1', (64,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer3.1.bn2', (64,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer3.2.bn1', (64,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer3.2.bn2', (64,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer3.3.bn1', (64,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer3.3.bn2', (64,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer3.4.bn1', (64,), 1.0, 1.0, 1.0)\n",
      "BN: ('model.layer3.4.bn2', (64,), 1.0, 1.0, 1.0)\n",
      "BN: ('BNH', (64,), 1.0, 1.0, 1.0)\n",
      "BN: ('BNM', (64,), 1.0, 1.0, 1.0)\n",
      "BN: ('BNT', (64,), 1.0, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "# inspect_bn_stats.py\n",
    "import torch, glob, os, sys\n",
    "from models import REGISTRY as MODEL_REG\n",
    "\n",
    "DBG = sorted(glob.glob(\"../debug/crash_final.pth\") + glob.glob(\"../debug/nan_grad_epoch*.pth\"))\n",
    "if not DBG:\n",
    "    print(\"No debug files\")\n",
    "    sys.exit(1)\n",
    "dbg = torch.load(DBG[-1], map_location=\"cpu\")\n",
    "\n",
    "MODEL_KEY = \"resltresnet32\"\n",
    "MODEL_ARGS = {\"num_classes\": 7, \"scale\": 1}\n",
    "model = MODEL_REG[MODEL_KEY](**MODEL_ARGS)\n",
    "\n",
    "# try to load model_state if present\n",
    "if \"model_state\" in dbg and isinstance(dbg[\"model_state\"], dict):\n",
    "    try:\n",
    "        model.load_state_dict(dbg[\"model_state\"], strict=False)\n",
    "        print(\"Loaded model_state (partial) into model with strict=False\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to load model_state:\", e)\n",
    "\n",
    "bn_info = []\n",
    "for name, m in model.named_modules():\n",
    "    if hasattr(m, \"running_mean\") and hasattr(m, \"running_var\"):\n",
    "        rm = m.running_mean.detach().cpu().numpy() if m.running_mean is not None else None\n",
    "        rv = m.running_var.detach().cpu().numpy() if m.running_var is not None else None\n",
    "        bn_info.append((name, rm.shape if rm is not None else None, float(rv.mean()) if rv is not None else None,\n",
    "                        float(rv.min()) if rv is not None else None,\n",
    "                        float(rv.max()) if rv is not None else None))\n",
    "for row in bn_info:\n",
    "    print(\"BN:\", row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484b8b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn_stdp_poisson (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
