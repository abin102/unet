# --------------------------------------------------------
# Fine-tune ResNet-50 (torchvision) on CIFAR-10
# --------------------------------------------------------
exp_name: "cifar10_resnet32_3_experts"
seed: 42
output_dir: "runs/uger/cifar_resnet_experts"

# long tailed version , no pretrianing since weights are not available
# -------------------------
# dataset / dataloader
# -------------------------
dataset: "cifar10"
data_dir: "./data"
batch_size: 128
num_workers: 8
pin_memory: true
persistent_workers: true

image_size: 32
to_rgb: false
imagenet_norm: true          # keep true since using pretrained ImageNet weights

# data_args:
#   imb_factor: 1.0
#   class_balance: false

# -------------------------
# model
# -------------------------

model: "plug_and_play_expert"
model_args:
  backbone: "resnet32_backbone"         # <-- use the backbone factory by name
  backbone_args: {}                     # optional; leave empty or pass args for backbone
  probe_input_size: [1, 3, 32, 32]
  feature_layer: "layer3"
  adapter_channels: 256
  expert_dims: 256
  thresholds: [0.33, 0.66]
  num_classes: 10

# -------------------------
# loss
# -------------------------
loss: "ce"
loss_args: {}

# -------------------------
# metrics & evaluation
# -------------------------
metrics:
  - "acc"

# -------------------------
# optimizer / scheduler
# -------------------------
optim: "sgd"
optim_args:
  lr: 0.01
  momentum: 0.9
  weight_decay: 1e-4

scheduler: "cosine"
scheduler_args:
  T_max: 200
  eta_min: 0.0

# -------------------------
# training runtime
# -------------------------
epochs: 200
amp: false                   # disable mixed precision for stable fine-tuning
grad_clip: 5.0

# freeze backbone for initial epochs, then unfreeze and fine-tune full model
# freeze_backbone_epochs: 5     # number of epochs to freeze backbone
# unfreeze_reduce_lr: 1.0       # multiply LR by this when unfreezing (<=1.0 typical)
# head_only_lr: 0.01            # (for record-keeping; used if head-only LR implemented later)

log_interval: 100
val_interval: 1

# -------------------------
# early stopping
# -------------------------
early_stop:
  patience: 30
  monitor: "val/acc"
  mode: "max"

# -------------------------
# checkpointing
# -------------------------
checkpoint:
  save_best_only: true
  monitor: "val/acc"
  mode: "max"
  save_interval_epochs: 1

# -------------------------
# diagnostics
# -------------------------
diagnostics:
  log_W_histogram: false
  save_attention_maps: false

# reproducibility
deterministic: true
